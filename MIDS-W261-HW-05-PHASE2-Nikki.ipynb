{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale\n",
    "__Course Lead:__ Dr James G. Shanahan (__email__ Jimi via  James.Shanahan _AT_ gmail.com)\n",
    "\n",
    "## Assignment - HW5\n",
    "\n",
    "\n",
    "---\n",
    "__Name:__  Carlos Castro   \n",
    "__Class:__ MIDS w261 (Section 2, e.g., Fall 2016 Group 1)     \n",
    "__Email:__  carlosscastro@iSchool.Berkeley.edu     \n",
    "__Week:__   5\n",
    "\n",
    "__Due Time:__ 2 Phases. \n",
    "\n",
    "* __HW5 Phase 1__ \n",
    "This can be done on a local machine (with a unit test on the cloud such as AltaScale's PaaS or on AWS) and is due Tuesday, Week 6 by 8AM (West coast time). It will primarily focus on building a unit/systems and for pairwise similarity calculations pipeline (for stripe documents)\n",
    "\n",
    "* __HW5 Phase 2__ \n",
    "This will require the AltaScale cluster and will be due Tuesday, Week 7 by 8AM (West coast time). \n",
    "The focus of  HW5 Phase 2  will be to scale up the unit/systems tests to the Google 5 gram corpus. This will be a group exercise \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.13 | packaged by conda-forge | (default, May  2 2017, 12:48:11) \\n[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a name=\"TOC\"></a> \n",
    "\n",
    "1.  [HW Instructions](#1)   \n",
    "2.  [HW References](#2)\n",
    "3.  [HW Problems](#3)   \n",
    "       \n",
    "    5.4.  [HW5.4](#5.4)    \n",
    "    5.5.  [HW5.5](#5.5)    \n",
    "    5.6.  [HW5.6](#5.6)    \n",
    "    5.7.  [HW5.7](#5.7)    \n",
    "    5.8.  [HW5.8](#5.8)    \n",
    "    5.9.  [HW5.9](#5.9)    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "# 1 Instructions\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "MIDS UC Berkeley, Machine Learning at Scale   \n",
    "DATSCIW261 ASSIGNMENT #5\n",
    "\n",
    "Version 2017-9-2 \n",
    "\n",
    "\n",
    "### IMPORTANT\n",
    "\n",
    "This homework must be completed in the cloud \n",
    "\n",
    "### === INSTRUCTIONS for SUBMISSIONS ===   \n",
    "Follow the instructions for submissions carefully.\n",
    "\n",
    "Each student has a `HW-<user>` repository for all assignments.   \n",
    "\n",
    "Click this link to enable you to create a github repo within the MIDS261 Classroom:   \n",
    "https://classroom.github.com/assignment-invitations/3b1d6c8e58351209f9dd865537111ff8   \n",
    "and follow the instructions to create a HW repo.\n",
    "\n",
    "Push the following to your HW github repo into the master branch:\n",
    "* Your local HW5 directory. Your repo file structure should look like this:\n",
    "\n",
    "```\n",
    "HW-<user>\n",
    "    --HW3\n",
    "       |__MIDS-W261-HW-03-<Student_id>.ipynb\n",
    "       |__MIDS-W261-HW-03-<Student_id>.pdf\n",
    "       |__some other hw3 file\n",
    "    --HW4\n",
    "       |__MIDS-W261-HW-04-<Student_id>.ipynb\n",
    "       |__MIDS-W261-HW-04-<Student_id>.pdf\n",
    "       |__some other hw4 file\n",
    "    etc..\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\">\n",
    "# 2 Useful References\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "* See async and live lectures for this week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\">\n",
    "# 3 HW Problems\n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5.4\"></a> \n",
    "# PHASE 2\n",
    "----------\n",
    "\n",
    "# HW 5.4   \n",
    "## Full-scale experiment on Google N-gram data on the CLOUD\n",
    "__ Once you are happy with your test results __ proceed to generating  your results on the Google n-grams dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.4.0  <a name=\"5.4.0\"></a> Run systems tests on the CLOUD  (PHASE 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Repeat HW5.3.0 (using the same small data sources that were used in HW5.3.0) on ** the cloud** (e.g., AltaScale / AWS/ SoftLayer/ Azure). Make sure all tests give correct results! Good luck out there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting buildStripes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildStripes.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import itertools\n",
    "import collections\n",
    "import logging\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class MRbuildStripes(MRJob):\n",
    "  \n",
    "    #START SUDENT CODE531_STRIPES\n",
    "  \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    #def mapper_init(self):\n",
    "    #    return self.start_time = time.time()\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "\n",
    "        words = splits[0].lower().split()\n",
    "        count = splits[1]\n",
    "\n",
    "        H = {}\n",
    "        for subset in itertools.combinations(sorted(set(words)), 2):\n",
    "            \n",
    "            # Process combinations in sorted order, i.e. \"hello\",\"tomorrow\"\n",
    "            if subset[0] not in H.keys():\n",
    "                H[subset[0]] = {}\n",
    "                H[subset[0]][subset[1]] = count \n",
    "            elif subset[1] not in H[subset[0]]:\n",
    "                H[subset[0]][subset[1]] = count\n",
    "            else:\n",
    "                H[subset[0]][subset[1]] += count\n",
    "\n",
    "            # Obtain combinations in reverse order, to consider them both ways\n",
    "            # TODO: Should refactor this and the block above, shameless copy-paste\n",
    "            if subset[1] not in H.keys():\n",
    "                H[subset[1]] = {}\n",
    "                H[subset[1]][subset[0]] = count \n",
    "            elif subset[0] not in H[subset[1]]:\n",
    "                H[subset[1]][subset[0]] = count\n",
    "            else:\n",
    "                H[subset[1]][subset[0]] += count\n",
    "        for key in H.keys():\n",
    "            #print \"%s\\t%s\" % (key, json.dumps(H[key]))\n",
    "            yield key, H[key]\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        \n",
    "        counter = {}\n",
    "\n",
    "        for value in values:\n",
    "            \n",
    "            for k, v in value.iteritems():\n",
    "                if k in counter:\n",
    "                    counter[k] += int(v)\n",
    "                else:\n",
    "                    counter[k] = int(v)\n",
    "        \n",
    "        yield key, counter\n",
    "        \n",
    "    \n",
    "    def steps(self):\n",
    "        return [\n",
    "\n",
    "            MRStep(#mapper_init=self.mapper_init\n",
    "                   #,\n",
    "                   mapper=self.mapper\n",
    "                   ,\n",
    "                   reducer=self.reducer\n",
    "                  )\n",
    "            ]\n",
    "  #END SUDENT CODE531_STRIPES\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    MRbuildStripes.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"\n",
    "    Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting invertedIndex.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile invertedIndex.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "\n",
    "class MRinvertedIndex(MRJob):\n",
    "    \n",
    "    #START SUDENT CODE531_INV_INDEX\n",
    "  \n",
    "    def mapper(self, _, line):\n",
    "        key, stripeJson = line.strip().split('\\t')\n",
    "        key = key.strip(\"\\\"\")\n",
    "        stripe = json.loads(stripeJson)\n",
    "        \n",
    "        for k, v in stripe.iteritems():\n",
    "            yield k, [key, len(stripe)]\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "\n",
    "        table = {}\n",
    "        for value in values:\n",
    "            table[value[0]] = value[1]\n",
    "            \n",
    "        yield key, table\n",
    "        \n",
    "    #END SUDENT CODE531_INV_INDEX\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    MRinvertedIndex.run() \n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"\n",
    "    Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting similarity.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile similarity.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "#import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class MRsimilarity(MRJob):\n",
    "  \n",
    "    #START SUDENT CODE531_SIMILARITY\n",
    "\n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        key, valuesJson = line.strip().split('\\t')\n",
    "        key = key.strip(\"\\\"\")\n",
    "        values = json.loads(valuesJson)\n",
    "\n",
    "        for pair in itertools.combinations(sorted(set(values)), 2):\n",
    "            yield pair, [values[pair[0]], values[pair[1]]]\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        intersection = 0\n",
    "        count1 = None\n",
    "        count2 = None\n",
    "        \n",
    "        cosine = 0.0\n",
    "        \n",
    "        # Iterate through the values\n",
    "        for value in values:\n",
    "            # Jaccard, get counts for the intersection, and for each set\n",
    "            intersection += 1\n",
    "            if count1 == None:\n",
    "                count1 = value[0]\n",
    "                count2 = value[1]\n",
    "        \n",
    "            # Cosine\n",
    "            a = 1 / math.sqrt(value[0])\n",
    "            b = 1 / math.sqrt(value[1])\n",
    "            cosine += a * b\n",
    "            \n",
    "        jaccard = float(intersection) / float(count1 + count2 - intersection)\n",
    "        \n",
    "        overlap_coefficient = float(intersection) / min(count1, count2)\n",
    "        \n",
    "        dice_coefficient = float(2 * intersection) / (count1 + count2)\n",
    "        \n",
    "        average = (cosine + jaccard + overlap_coefficient + dice_coefficient) / 4.0\n",
    "        \n",
    "        yield average, [key[0] + ' - ' + key[1], cosine, jaccard, overlap_coefficient, dice_coefficient]\n",
    "            \n",
    "    #END SUDENT CODE531_SIMILARITY\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    MRsimilarity.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"\n",
    "    Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n",
    "A BILL FOR ESTABLISHING RELIGIOUS\t59\t59\t54\n",
    "A Biography of General George\t92\t90\t74\n",
    "A Case Study in Government\t102\t102\t78\n",
    "A Case Study of Female\t447\t447\t327\n",
    "A Case Study of Limited\t55\t55\t43\n",
    "A Child's Christmas in Wales\t1099\t1061\t866\n",
    "A Circumstantial Narrative of the\t62\t62\t50\n",
    "A City by the Sea\t62\t60\t49\n",
    "A Collection of Fairy Tales\t123\t117\t80\n",
    "A Collection of Forms of\t116\t103\t82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting atlas-boon-systems-test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile atlas-boon-systems-test.txt\n",
    "atlas boon\t50\t50\t50\n",
    "boon cava dipped\t10\t10\t10\n",
    "atlas dipped\t15\t15\t15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build stripes for mini-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `systems_test_stripes_1': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/buildStripes.nhaas.20170618.162257.554662\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170618.162257.554662/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob4721740052318486343.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1405\n",
      "  Submitted application application_1493936954640_1405\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1405/\n",
      "  Running job: job_1493936954640_1405\n",
      "  Job job_1493936954640_1405 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1405 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170618.162257.554662/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2118\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1042\n",
      "\t\tFILE: Number of bytes written=400890\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1007\n",
      "\t\tHDFS: Number of bytes written=2118\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=71078400\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=60006400\n",
      "\t\tTotal time spent by all map tasks (ms)=46275\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=138825\n",
      "\t\tTotal time spent by all reduce tasks (ms)=23440\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=117200\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=46275\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=23440\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2840\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=95\n",
      "\t\tInput split bytes=444\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=3024\n",
      "\t\tMap output materialized bytes=1047\n",
      "\t\tMap output records=49\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1897041920\n",
      "\t\tReduce input groups=49\n",
      "\t\tReduce input records=49\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=1047\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=98\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7775764480\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170618.162257.554662/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170618.162257.554662...\n",
      "Removing temp directory /tmp/buildStripes.nhaas.20170618.162257.554662...\n",
      "WARNING:root:\n",
      "    Elapsed time: 93.7769079208 seconds\n",
      "    In minutes: 1.56294846535 mins\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Make Stripes from ngrams for systems test 1\n",
    "###########################################################################\n",
    "\n",
    "!hdfs dfs -rm -r systems_test_stripes_1\n",
    "!python buildStripes.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > systems_test_stripes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\"\t{\"limited\":55,\"female\":447,\"general\":92,\"sea\":62,\"in\":1201,\"religious\":59,\"george\":92,\"biography\":92,\"city\":62,\"for\":59,\"tales\":123,\"child's\":1099,\"forms\":116,\"wales\":1099,\"christmas\":1099,\"government\":102,\"collection\":239,\"by\":62,\"case\":604,\"circumstantial\":62,\"fairy\":123,\"of\":895,\"study\":604,\"bill\":59,\"establishing\":59,\"narrative\":62,\"the\":124}\r\n",
      "\"bill\"\t{\"a\":59,\"religious\":59,\"for\":59,\"establishing\":59}\r\n",
      "\"biography\"\t{\"a\":92,\"of\":92,\"george\":92,\"general\":92}\r\n",
      "\"by\"\t{\"a\":62,\"city\":62,\"the\":62,\"sea\":62}\r\n",
      "\"case\"\t{\"a\":604,\"limited\":55,\"government\":102,\"of\":502,\"study\":604,\"female\":447,\"in\":102}\r\n",
      "\"child's\"\t{\"a\":1099,\"wales\":1099,\"christmas\":1099,\"in\":1099}\r\n",
      "\"christmas\"\t{\"a\":1099,\"wales\":1099,\"in\":1099,\"child's\":1099}\r\n",
      "\"circumstantial\"\t{\"a\":62,\"of\":62,\"the\":62,\"narrative\":62}\r\n",
      "\"city\"\t{\"a\":62,\"the\":62,\"by\":62,\"sea\":62}\r\n",
      "\"collection\"\t{\"a\":239,\"forms\":116,\"fairy\":123,\"tales\":123,\"of\":239}\r\n",
      "\"establishing\"\t{\"a\":59,\"bill\":59,\"religious\":59,\"for\":59}\r\n",
      "\"fairy\"\t{\"a\":123,\"of\":123,\"tales\":123,\"collection\":123}\r\n",
      "\"female\"\t{\"a\":447,\"case\":447,\"study\":447,\"of\":447}\r\n",
      "\"for\"\t{\"a\":59,\"bill\":59,\"religious\":59,\"establishing\":59}\r\n",
      "\"forms\"\t{\"a\":116,\"of\":116,\"collection\":116}\r\n",
      "\"general\"\t{\"a\":92,\"of\":92,\"george\":92,\"biography\":92}\r\n",
      "\"george\"\t{\"a\":92,\"of\":92,\"biography\":92,\"general\":92}\r\n",
      "\"government\"\t{\"a\":102,\"case\":102,\"study\":102,\"in\":102}\r\n",
      "\"in\"\t{\"a\":1201,\"case\":102,\"government\":102,\"study\":102,\"child's\":1099,\"wales\":1099,\"christmas\":1099}\r\n",
      "\"limited\"\t{\"a\":55,\"case\":55,\"study\":55,\"of\":55}\r\n",
      "\"narrative\"\t{\"a\":62,\"of\":62,\"the\":62,\"circumstantial\":62}\r\n",
      "\"of\"\t{\"a\":895,\"case\":502,\"circumstantial\":62,\"george\":92,\"limited\":55,\"tales\":123,\"collection\":239,\"the\":62,\"forms\":116,\"female\":447,\"narrative\":62,\"fairy\":123,\"general\":92,\"study\":502,\"biography\":92}\r\n",
      "\"religious\"\t{\"a\":59,\"bill\":59,\"for\":59,\"establishing\":59}\r\n",
      "\"sea\"\t{\"a\":62,\"city\":62,\"the\":62,\"by\":62}\r\n",
      "\"study\"\t{\"a\":604,\"case\":604,\"limited\":55,\"government\":102,\"of\":502,\"female\":447,\"in\":102}\r\n",
      "\"tales\"\t{\"a\":123,\"of\":123,\"fairy\":123,\"collection\":123}\r\n",
      "\"the\"\t{\"a\":124,\"city\":62,\"circumstantial\":62,\"of\":62,\"sea\":62,\"narrative\":62,\"by\":62}\r\n",
      "\"wales\"\t{\"a\":1099,\"in\":1099,\"christmas\":1099,\"child's\":1099}\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `systems_test_stripes_2': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/buildStripes.nhaas.20170618.162632.304386\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170618.162632.304386/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob1959466903096550768.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1407\n",
      "  Submitted application application_1493936954640_1407\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1407/\n",
      "  Running job: job_1493936954640_1407\n",
      "  Job job_1493936954640_1407 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1407 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170618.162632.304386/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=101\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=147\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=137\n",
      "\t\tFILE: Number of bytes written=398998\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=471\n",
      "\t\tHDFS: Number of bytes written=147\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12796416\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=21544960\n",
      "\t\tTotal time spent by all map tasks (ms)=8331\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=24993\n",
      "\t\tTotal time spent by all reduce tasks (ms)=8416\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=42080\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=8331\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=8416\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2920\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=68\n",
      "\t\tInput split bytes=370\n",
      "\t\tMap input records=3\n",
      "\t\tMap output bytes=204\n",
      "\t\tMap output materialized bytes=171\n",
      "\t\tMap output records=7\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1905586176\n",
      "\t\tReduce input groups=7\n",
      "\t\tReduce input records=7\n",
      "\t\tReduce output records=4\n",
      "\t\tReduce shuffle bytes=171\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=14\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7747153920\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170618.162632.304386/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170618.162632.304386...\n",
      "Removing temp directory /tmp/buildStripes.nhaas.20170618.162632.304386...\n",
      "WARNING:root:\n",
      "    Elapsed time: 59.9711410999 seconds\n",
      "    In minutes: 0.999519018332 mins\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Make Stripes from ngrams for systems test 2\n",
    "###########################################################################\n",
    "\n",
    "!hdfs dfs -rm -r systems_test_stripes_2\n",
    "!python buildStripes.py -r hadoop atlas-boon-systems-test.txt \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > systems_test_stripes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"atlas\"\t{\"dipped\":15,\"boon\":50}\r\n",
      "\"boon\"\t{\"atlas\":50,\"dipped\":10,\"cava\":10}\r\n",
      "\"cava\"\t{\"dipped\":10,\"boon\":10}\r\n",
      "\"dipped\"\t{\"atlas\":15,\"boon\":10,\"cava\":10}\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"DocA\"\t{\"X\":20, \"Y\":30, \"Z\":5}\r\n",
      "\"DocB\"\t{\"X\":100, \"Y\":20}\r\n",
      "\"DocC\"\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\r\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Stripes for systems test 3 (given, no need to build stripes)\n",
    "########################################################################\n",
    "\n",
    "with open(\"systems_test_stripes_3\", \"w\") as f:\n",
    "    f.writelines([\n",
    "        '\"DocA\"\\t{\"X\":20, \"Y\":30, \"Z\":5}\\n',\n",
    "        '\"DocB\"\\t{\"X\":100, \"Y\":20}\\n',  \n",
    "        '\"DocC\"\\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\\n'\n",
    "    ])\n",
    "!cat systems_test_stripes_3  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted indices for mini-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.nhaas.20170618.164238.884360\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164238.884360/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob7219551985860849750.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1408\n",
      "  Submitted application application_1493936954640_1408\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1408/\n",
      "  Running job: job_1493936954640_1408\n",
      "  Job job_1493936954640_1408 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1408 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164238.884360/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3177\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1904\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1386\n",
      "\t\tFILE: Number of bytes written=400238\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3539\n",
      "\t\tHDFS: Number of bytes written=1904\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12805632\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=21744640\n",
      "\t\tTotal time spent by all map tasks (ms)=8337\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=25011\n",
      "\t\tTotal time spent by all reduce tasks (ms)=8494\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=42470\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=8337\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=8494\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2410\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=63\n",
      "\t\tInput split bytes=362\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=3150\n",
      "\t\tMap output materialized bytes=1581\n",
      "\t\tMap output records=158\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1906683904\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=158\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=1581\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=316\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7728132096\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164238.884360/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164238.884360...\n",
      "Removing temp directory /tmp/invertedIndex.nhaas.20170618.164238.884360...\n",
      "WARNING:root:\n",
      "    Elapsed time: 58.9230360985 seconds\n",
      "    In minutes: 0.982050601641 mins\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r hadoop systems_test_stripes_1 \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > systems_test_index_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.nhaas.20170618.164713.969579\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164713.969579/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob3504195369550009402.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1409\n",
      "  Submitted application application_1493936954640_1409\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1409/\n",
      "  Running job: job_1493936954640_1409\n",
      "  Job job_1493936954640_1409 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1409 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164713.969579/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=221\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=137\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=141\n",
      "\t\tFILE: Number of bytes written=397604\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=583\n",
      "\t\tHDFS: Number of bytes written=137\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=13728768\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=22384640\n",
      "\t\tTotal time spent by all map tasks (ms)=8938\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=26814\n",
      "\t\tTotal time spent by all reduce tasks (ms)=8744\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=43720\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=8938\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=8744\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2690\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=153\n",
      "\t\tInput split bytes=362\n",
      "\t\tMap input records=4\n",
      "\t\tMap output bytes=196\n",
      "\t\tMap output materialized bytes=183\n",
      "\t\tMap output records=10\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1904967680\n",
      "\t\tReduce input groups=4\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=4\n",
      "\t\tReduce shuffle bytes=183\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=20\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7743733760\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164713.969579/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164713.969579...\n",
      "Removing temp directory /tmp/invertedIndex.nhaas.20170618.164713.969579...\n",
      "WARNING:root:\n",
      "    Elapsed time: 60.2896530628 seconds\n",
      "    In minutes: 1.00482755105 mins\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r hadoop systems_test_stripes_2 \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > systems_test_index_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.nhaas.20170618.164856.448013\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164856.448013/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2029286395784001168.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1410\n",
      "  Submitted application application_1493936954640_1410\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1410/\n",
      "  Running job: job_1493936954640_1410\n",
      "  Job job_1493936954640_1410 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1410_m_000001_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@2f6e6eb5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1410_m_000000_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@2f6e6eb5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1410_m_000001_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c471b93 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1410 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164856.448013/output\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=140\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=111\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=92\n",
      "\t\tFILE: Number of bytes written=397488\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=502\n",
      "\t\tHDFS: Number of bytes written=111\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=3\n",
      "\t\tLaunched map tasks=5\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=3\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=20805120\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=11927040\n",
      "\t\tTotal time spent by all map tasks (ms)=13545\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=40635\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4659\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=23295\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=13545\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4659\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2730\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=71\n",
      "\t\tInput split bytes=362\n",
      "\t\tMap input records=3\n",
      "\t\tMap output bytes=135\n",
      "\t\tMap output materialized bytes=125\n",
      "\t\tMap output records=9\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1900924928\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce input records=9\n",
      "\t\tReduce output records=5\n",
      "\t\tReduce shuffle bytes=125\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=18\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7762333696\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164856.448013/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170618.164856.448013...\n",
      "Removing temp directory /tmp/invertedIndex.nhaas.20170618.164856.448013...\n",
      "WARNING:root:\n",
      "    Elapsed time: 62.0599889755 seconds\n",
      "    In minutes: 1.03433314959 mins\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r hadoop systems_test_stripes_3 \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > systems_test_index_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  1  - Inverted Index\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "             \"a\" |          bill 4 |     biography 4 |            by 4\n",
      "          \"bill\" |            a 27 |  establishing 4 |           for 4\n",
      "     \"biography\" |            a 27 |       general 4 |        george 4\n",
      "            \"by\" |            a 27 |          city 4 |           sea 4\n",
      "          \"case\" |            a 27 |        female 4 |    government 4\n",
      "       \"child's\" |            a 27 |     christmas 4 |            in 7\n",
      "     \"christmas\" |            a 27 |       child's 4 |            in 7\n",
      "\"circumstantial\" |            a 27 |     narrative 4 |           of 15\n",
      "          \"city\" |            a 27 |            by 4 |           sea 4\n",
      "    \"collection\" |            a 27 |         fairy 4 |         forms 3\n",
      "  \"establishing\" |            a 27 |          bill 4 |           for 4\n",
      "         \"fairy\" |            a 27 |    collection 5 |           of 15\n",
      "        \"female\" |            a 27 |          case 7 |           of 15\n",
      "           \"for\" |            a 27 |          bill 4 |  establishing 4\n",
      "         \"forms\" |            a 27 |    collection 5 |           of 15\n",
      "       \"general\" |            a 27 |     biography 4 |        george 4\n",
      "        \"george\" |            a 27 |     biography 4 |       general 4\n",
      "    \"government\" |            a 27 |          case 7 |            in 7\n",
      "            \"in\" |            a 27 |          case 7 |       child's 4\n",
      "       \"limited\" |            a 27 |          case 7 |           of 15\n",
      "     \"narrative\" |            a 27 |circumstantial 4 |           of 15\n",
      "            \"of\" |            a 27 |     biography 4 |          case 7\n",
      "     \"religious\" |            a 27 |          bill 4 |  establishing 4\n",
      "           \"sea\" |            a 27 |            by 4 |          city 4\n",
      "         \"study\" |            a 27 |          case 7 |        female 4\n",
      "         \"tales\" |            a 27 |    collection 5 |         fairy 4\n",
      "           \"the\" |            a 27 |            by 4 |circumstantial 4\n",
      "         \"wales\" |            a 27 |       child's 4 |     christmas 4\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  2  - Inverted Index\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "         \"atlas\" |          boon 3 |        dipped 3 |                \n",
      "          \"boon\" |         atlas 2 |          cava 2 |        dipped 3\n",
      "          \"cava\" |          boon 3 |        dipped 3 |                \n",
      "        \"dipped\" |         atlas 2 |          boon 3 |          cava 2\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  3  - Inverted Index\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "             \"M\" |          DocC 4 |                 |                \n",
      "             \"N\" |          DocC 4 |                 |                \n",
      "             \"X\" |          DocA 3 |          DocB 2 |                \n",
      "             \"Y\" |          DocA 3 |          DocB 2 |          DocC 4\n",
      "             \"Z\" |          DocA 3 |          DocC 4 |                \n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Pretty print systems tests for generating Inverted Index\n",
    "##########################################################\n",
    "import json\n",
    "\n",
    "for i in range(1,4):\n",
    "    print \"—\"*100\n",
    "    print \"Systems test \",i,\" - Inverted Index\"\n",
    "    print \"—\"*100  \n",
    "    with open(\"systems_test_index_\"+str(i),\"r\") as f:\n",
    "        lines = sorted(f.readlines())\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            word, doc_list = line.split(\"\\t\")\n",
    "            doc_dict = json.loads(doc_list)\n",
    "            stripe=[]\n",
    "            for doc in doc_dict:\n",
    "                stripe.append([doc, doc_dict[doc]])\n",
    "            stripe=sorted(stripe)\n",
    "            stripe.extend([[\"\",\"\"] for _ in xrange(3 - len(stripe))])\n",
    "\n",
    "            print \"{0:>16} |{1:>16} |{2:>16} |{3:>16}\".format(\n",
    "              (word), stripe[0][0]+\" \"+str(stripe[0][1]), stripe[1][0]+\" \"+str(stripe[1][1]), stripe[2][0]+\" \"+str(stripe[2][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities for mini-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/similarity.nhaas.20170618.165052.663924\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165052.663924/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob5931891536745767876.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1411\n",
      "  Submitted application application_1493936954640_1411\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1411/\n",
      "  Running job: job_1493936954640_1411\n",
      "  Job job_1493936954640_1411 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1411 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165052.663924/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2856\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=25050\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3654\n",
      "\t\tFILE: Number of bytes written=407058\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3206\n",
      "\t\tHDFS: Number of bytes written=25050\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=13248000\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=11169280\n",
      "\t\tTotal time spent by all map tasks (ms)=8625\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=25875\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4363\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=21815\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=8625\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4363\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3000\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=126\n",
      "\t\tInput split bytes=350\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=17893\n",
      "\t\tMap output materialized bytes=4825\n",
      "\t\tMap output records=673\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1899433984\n",
      "\t\tReduce input groups=378\n",
      "\t\tReduce input records=673\n",
      "\t\tReduce output records=378\n",
      "\t\tReduce shuffle bytes=4825\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1346\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7749488640\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165052.663924/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165052.663924...\n",
      "Removing temp directory /tmp/similarity.nhaas.20170618.165052.663924...\n",
      "WARNING:root:\n",
      "    Elapsed time: 55.7111759186 seconds\n",
      "    In minutes: 0.928519598643 mins\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_1 \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > systems_test_similarities_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/similarity.nhaas.20170618.165322.102219\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165322.102219/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob6727828718612215201.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1412\n",
      "  Submitted application application_1493936954640_1412\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1412/\n",
      "  Running job: job_1493936954640_1412\n",
      "  Job job_1493936954640_1412 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1412 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165322.102219/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=206\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=330\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=122\n",
      "\t\tFILE: Number of bytes written=398881\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=556\n",
      "\t\tHDFS: Number of bytes written=330\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12644352\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=11865600\n",
      "\t\tTotal time spent by all map tasks (ms)=8232\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=24696\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4635\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=23175\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=8232\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4635\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2900\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=96\n",
      "\t\tInput split bytes=350\n",
      "\t\tMap input records=4\n",
      "\t\tMap output bytes=196\n",
      "\t\tMap output materialized bytes=180\n",
      "\t\tMap output records=8\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1893617664\n",
      "\t\tReduce input groups=6\n",
      "\t\tReduce input records=8\n",
      "\t\tReduce output records=6\n",
      "\t\tReduce shuffle bytes=180\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=16\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7729893376\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165322.102219/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165322.102219...\n",
      "Removing temp directory /tmp/similarity.nhaas.20170618.165322.102219...\n",
      "WARNING:root:\n",
      "    Elapsed time: 55.9099228382 seconds\n",
      "    In minutes: 0.931832047304 mins\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_2 \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > systems_test_similarities_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/similarity.nhaas.20170618.165446.659280\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165446.659280/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob782874646851847932.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1413\n",
      "  Submitted application application_1493936954640_1413\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1413/\n",
      "  Running job: job_1493936954640_1413\n",
      "  Job job_1493936954640_1413 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1413 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165446.659280/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=167\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=197\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=74\n",
      "\t\tFILE: Number of bytes written=398756\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=517\n",
      "\t\tHDFS: Number of bytes written=197\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12393984\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=11745280\n",
      "\t\tTotal time spent by all map tasks (ms)=8069\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=24207\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4588\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=22940\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=8069\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4588\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2690\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=100\n",
      "\t\tInput split bytes=350\n",
      "\t\tMap input records=5\n",
      "\t\tMap output bytes=115\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tMap output records=5\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1901064192\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=10\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7755304960\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165446.659280/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170618.165446.659280...\n",
      "Removing temp directory /tmp/similarity.nhaas.20170618.165446.659280...\n",
      "WARNING:root:\n",
      "    Elapsed time: 55.0429039001 seconds\n",
      "    In minutes: 0.917381731669 mins\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_3\\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > systems_test_similarities_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  1  - Similarity measures\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "        average |           pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       0.334842 |       a - bill |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |  a - biography |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |         a - by |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.465201 |       a - case |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.334842 |    a - child's |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |  a - christmas |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |a - circumstantial |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |       a - city |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.384281 | a - collection |       0.344265 |       0.142857 |       0.800000 |       0.250000\n",
      "       0.334842 |a - establishing |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |      a - fairy |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |     a - female |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |        a - for |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.273413 |      a - forms |       0.222222 |       0.071429 |       0.666667 |       0.133333\n",
      "       0.334842 |    a - general |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |     a - george |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 | a - government |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.465201 |         a - in |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.334842 |    a - limited |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |  a - narrative |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.698916 |         a - of |       0.695666 |       0.500000 |       0.933333 |       0.666667\n",
      "       0.334842 |  a - religious |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |        a - sea |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.465201 |      a - study |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.334842 |      a - tales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.465201 |        a - the |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.334842 |      a - wales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.223214 |bill - biography |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      bill - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |    bill - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 | bill - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |bill - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |bill - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |    bill - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.205207 |bill - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.712500 |bill - establishing |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |   bill - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  bill - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.712500 |     bill - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.268597 |   bill - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 | bill - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  bill - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |bill - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |      bill - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 | bill - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |bill - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 |      bill - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.712500 |bill - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |     bill - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |   bill - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |   bill - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |     bill - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |   bill - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 | biography - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |biography - case |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |biography - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |biography - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |biography - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |biography - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.419343 |biography - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.223214 |biography - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |biography - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |biography - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |biography - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.553861 |biography - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.712500 |biography - general |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |biography - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |biography - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 | biography - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |biography - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |biography - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 | biography - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |biography - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |biography - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |biography - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.458333 |biography - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |biography - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |biography - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |      by - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |   by - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 | by - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |by - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.712500 |      by - city |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.205207 |by - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.223214 |by - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     by - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |    by - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       by - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.268597 |     by - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 |   by - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |    by - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |by - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |        by - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |   by - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 | by - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.271593 |        by - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "       0.223214 | by - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.712500 |       by - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.180200 |     by - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |     by - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |       by - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |     by - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 | case - child's |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |case - christmas |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |case - circumstantial |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.180200 |    case - city |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.317849 |case - collection |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.180200 |case - establishing |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.365956 |   case - fairy |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.559350 |  case - female |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.180200 |     case - for |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.438276 |   case - forms |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.365956 | case - general |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |  case - george |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.559350 |case - government |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.389610 |      case - in |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "       0.559350 | case - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.365956 |case - narrative |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.386912 |      case - of |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "       0.180200 |case - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |     case - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.830357 |   case - study |       0.857143 |       0.750000 |       0.857143 |       0.857143\n",
      "       0.365956 |   case - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.255952 |     case - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "       0.365956 |   case - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.712500 |child's - christmas |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |child's - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 | child's - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.205207 |child's - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.223214 |child's - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |child's - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |child's - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  child's - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.268597 |child's - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 |child's - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |child's - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |child's - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.559350 |   child's - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |child's - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |child's - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 |   child's - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.223214 |child's - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  child's - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |child's - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |child's - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |  child's - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.712500 |child's - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |christmas - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.205207 |christmas - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.223214 |christmas - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.268597 |christmas - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 |christmas - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |christmas - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.559350 | christmas - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |christmas - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 | christmas - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.223214 |christmas - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |christmas - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |christmas - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |christmas - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.712500 |christmas - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.458333 |circumstantial - city |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.419343 |circumstantial - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.223214 |circumstantial - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |circumstantial - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |circumstantial - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |circumstantial - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.553861 |circumstantial - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.458333 |circumstantial - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |circumstantial - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |circumstantial - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |circumstantial - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |circumstantial - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.712500 |circumstantial - narrative |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.410147 |circumstantial - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |circumstantial - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |circumstantial - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |circumstantial - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.458333 |circumstantial - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.559350 |circumstantial - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |circumstantial - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.205207 |city - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.223214 |city - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   city - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  city - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     city - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.268597 |   city - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 | city - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  city - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |city - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |      city - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 | city - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |city - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.271593 |      city - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "       0.223214 |city - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.712500 |     city - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.180200 |   city - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |   city - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |     city - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |   city - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.205207 |collection - establishing |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.646872 |collection - fairy |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "       0.419343 |collection - female |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.205207 |collection - for |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.504099 |collection - forms |       0.516398 |       0.333333 |       0.666667 |       0.500000\n",
      "       0.419343 |collection - general |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |collection - george |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.205207 |collection - government |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.156652 |collection - in |       0.169031 |       0.090909 |       0.200000 |       0.166667\n",
      "       0.419343 |collection - limited |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |collection - narrative |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.477970 |collection - of |       0.461880 |       0.250000 |       0.800000 |       0.400000\n",
      "       0.205207 |collection - religious |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |collection - sea |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.317849 |collection - study |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.646872 |collection - tales |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "       0.317849 |collection - the |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.205207 |collection - wales |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.223214 |establishing - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |establishing - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.712500 |establishing - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.268597 |establishing - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 |establishing - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |establishing - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |establishing - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |establishing - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |establishing - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |establishing - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 |establishing - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.712500 |establishing - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |establishing - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |establishing - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |establishing - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |establishing - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |establishing - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 | fairy - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |    fairy - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.868292 |  fairy - forms |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "       0.458333 |fairy - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 | fairy - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |fairy - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |     fairy - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |fairy - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |fairy - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 |     fairy - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |fairy - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |    fairy - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |  fairy - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.712500 |  fairy - tales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.365956 |    fairy - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |  fairy - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   female - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.553861 | female - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.458333 |female - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |female - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.712500 |female - government |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.559350 |    female - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       1.000000 |female - limited |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       0.458333 |female - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 |    female - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |female - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   female - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 | female - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.458333 | female - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |   female - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 | female - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.268597 |    for - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 |  for - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   for - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |for - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |       for - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |  for - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |for - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 |       for - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.712500 |for - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |      for - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |    for - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |    for - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |      for - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |    for - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.553861 |forms - general |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 | forms - george |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.268597 |forms - government |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.215666 |     forms - in |       0.218218 |       0.111111 |       0.333333 |       0.200000\n",
      "       0.553861 |forms - limited |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 |forms - narrative |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.328008 |     forms - of |       0.298142 |       0.125000 |       0.666667 |       0.222222\n",
      "       0.268597 |forms - religious |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |    forms - sea |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.438276 |  forms - study |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.868292 |  forms - tales |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "       0.438276 |    forms - the |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.268597 |  forms - wales |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.712500 |general - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |general - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |   general - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |general - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |general - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 |   general - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |general - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  general - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |general - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.458333 |general - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |  general - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |general - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |george - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |    george - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |george - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |george - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 |    george - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |george - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   george - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 | george - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.458333 | george - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |   george - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 | george - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |government - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.712500 |government - limited |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |government - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.410147 |government - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |government - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |government - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |government - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |government - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |government - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |government - wales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.559350 |   in - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.180200 | in - narrative |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.287991 |        in - of |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "       0.180200 | in - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |       in - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.389610 |     in - study |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "       0.180200 |     in - tales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.126374 |       in - the |       0.142857 |       0.076923 |       0.142857 |       0.142857\n",
      "       0.559350 |     in - wales |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.458333 |limited - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 |   limited - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |limited - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  limited - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |limited - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.458333 |limited - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |  limited - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |limited - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.410147 | narrative - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |narrative - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |narrative - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |narrative - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.458333 |narrative - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.559350 |narrative - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |narrative - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 | of - religious |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.271593 |       of - sea |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "       0.386912 |     of - study |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "       0.410147 |     of - tales |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.287991 |       of - the |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "       0.134980 |     of - wales |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.223214 |religious - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |religious - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |religious - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |religious - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |religious - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |    sea - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |    sea - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |      sea - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |    sea - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |  study - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.255952 |    study - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "       0.365956 |  study - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |    tales - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |  tales - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |    the - wales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  2  - Similarity measures\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "        average |           pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       0.389562 |   atlas - boon |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       1.000000 |   atlas - cava |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       0.389562 | atlas - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       0.389562 |    boon - cava |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       0.625000 |  boon - dipped |       0.666667 |       0.500000 |       0.666667 |       0.666667\n",
      "       0.389562 |  cava - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Systems test  3  - Similarity measures\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "        average |           pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       0.820791 |    DocA - DocB |       0.816497 |       0.666667 |       1.000000 |       0.800000\n",
      "       0.553861 |    DocA - DocC |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.346722 |    DocB - DocC |       0.353553 |       0.200000 |       0.500000 |       0.333333\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Pretty print systems tests\n",
    "############################################\n",
    "\n",
    "import json\n",
    "for i in range(1,4):\n",
    "  print '—'*110\n",
    "  print \"Systems test \",i,\" - Similarity measures\"\n",
    "  print '—'*110\n",
    "  print \"{0:>15} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "          \"average\", \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\")\n",
    "  print '-'*110\n",
    "\n",
    "  with open(\"systems_test_similarities_\"+str(i),\"r\") as f:\n",
    "      lines = f.readlines()\n",
    "      for line in lines:\n",
    "          line = line.strip()\n",
    "          avg,stripe = line.split(\"\\t\")\n",
    "          stripe = json.loads(stripe)\n",
    "\n",
    "          print \"{0:>15f} |{1:>15} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "              float(avg), stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.4.1 <a name=\"5.4.1\"></a>Full-scale experiment: EDA of Google n-grams dataset (PHASE 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Do some EDA on this dataset using mrjob, e.g., \n",
    "\n",
    "- A. Longest 5-gram (number of characters)\n",
    "- B. Top 10 most frequent words (please use the count information), i.e., unigrams\n",
    "- C. 20 Most/Least densely appearing words (count/pages_count) sorted in decreasing order of relative frequency \n",
    "- D. Distribution of 5-gram sizes (character length).  E.g., count (using the count field) up how many times a 5-gram of 50 characters shows up. Plot the data graphically using a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - A. Longest 5-gram (number of characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing longest5gram.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile longest5gram.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import logging\n",
    "import time\n",
    "\n",
    "class longest5gram(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.A\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(longest5gram, self).__init__(args)\n",
    "        self.max_count = 0\n",
    "        self.max_grams = []\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        # Split line\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        words = splits[0].lower().split()\n",
    "        \n",
    "        char_count = 0\n",
    "        \n",
    "        # Count characters\n",
    "        for word in words:\n",
    "            char_count += len(word)\n",
    "        \n",
    "        # Optimization: we track the max count local to the current mapper instance. If records\n",
    "        # have higher count than the max, we output them and update the max. We don't yield\n",
    "        # records that are smaller than the local max. \n",
    "        # Even some non-max records are passed on, the good thing about this is that it is extremely memory efficient\n",
    "        # in that it uses constant memory.\n",
    "        if char_count > self.max_count:\n",
    "            self.max_count = char_count\n",
    "            yield (words), char_count\n",
    "        elif char_count == self.max_count:\n",
    "            yield (words), char_count\n",
    "            \n",
    "    \n",
    "    def combiner(self, ngram, char_counts):\n",
    "        current_max = max(char_counts)\n",
    "        \n",
    "        # Optimization: we track the max count local to the current combiner instance. If records\n",
    "        # have higher count than the max, we output them and update the max. We don't yield\n",
    "        # records that are smaller than the local max, drastically reducing work on shuffling and sorting\n",
    "        # Even some non-max or local max records are passed on, the good thing about this is that it is extremely \n",
    "        # memory efficient in that it uses constant memory (just 1 integer :)\n",
    "        if current_max > self.max_count:\n",
    "            self.max_count = current_max\n",
    "            yield ngram, current_max\n",
    "        elif current_max == self.max_count:\n",
    "            yield ngram, current_max\n",
    "    \n",
    "    def reducer(self, ngram, char_counts):\n",
    "            \n",
    "        current_count = max(char_counts)\n",
    "\n",
    "        # Track in max_grams the n-grams with the max count of words\n",
    "        if current_count > self.max_count:\n",
    "            self.max_count = current_count\n",
    "            self.max_grams = [(current_count, ngram)]\n",
    "        elif current_count == self.max_count:\n",
    "            self.max_grams.append((current_count, ngram))\n",
    "\n",
    "    def reducer_final(self):\n",
    "        # Once\n",
    "        for gram in self.max_grams:\n",
    "            yield gram[0], gram[1]\n",
    "\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        # We need 1 reducer for this approach. However the optimizations in the mappers and combiners\n",
    "        # help us ensure that a small percentage of records get to the reducer\n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'1',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k2,2nr',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(jobconf=custom_jobconf,\n",
    "                    mapper=self.mapper,\n",
    "                    reducer=self.reducer,\n",
    "                    combiner = self.combiner,\n",
    "                    reducer_final = self.reducer_final\n",
    "                      )\n",
    "                 ]\n",
    "\n",
    "    # END STUDENT CODE 5.4.1.A\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    longest5gram.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"\n",
    "    Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `systems_test_stripes_5.4.1.a_1': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/longest5gram.nhaas.20170618.165613.015152\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170618.165613.015152/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob5309807761283756123.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1414\n",
      "  Submitted application application_1493936954640_1414\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1414/\n",
      "  Running job: job_1493936954640_1414\n",
      "  Job job_1493936954640_1414 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1414 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170618.165613.015152/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=98\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=157\n",
      "\t\tFILE: Number of bytes written=401401\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1007\n",
      "\t\tHDFS: Number of bytes written=98\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=14415360\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=12070400\n",
      "\t\tTotal time spent by all map tasks (ms)=9385\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=28155\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4715\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=23575\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=9385\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4715\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2870\n",
      "\t\tCombine input records=3\n",
      "\t\tCombine output records=3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=129\n",
      "\t\tInput split bytes=444\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=142\n",
      "\t\tMap output materialized bytes=173\n",
      "\t\tMap output records=3\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1902891008\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=3\n",
      "\t\tReduce output records=2\n",
      "\t\tReduce shuffle bytes=173\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=6\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7755943936\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170618.165613.015152/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170618.165613.015152...\n",
      "Removing temp directory /tmp/longest5gram.nhaas.20170618.165613.015152...\n",
      "WARNING:root:\n",
      "    Elapsed time: 57.6624941826 seconds\n",
      "    In minutes: 0.96104156971 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r systems_test_stripes_5.4.1.a_1\n",
    "!python longest5gram.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > systems_test_stripes_5.4.1.a_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\t[\"a\",\"bill\",\"for\",\"establishing\",\"religious\"]\r\n",
      "29\t[\"a\",\"circumstantial\",\"narrative\",\"of\",\"the\"]\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_5.4.1.a_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `full_stripes_5.4.1.a': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/longest5gram.nhaas.20170618.165741.358516\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170618.165741.358516/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob5108579592082131520.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1493936954640_1415\n",
      "  Submitted application application_1493936954640_1415\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1415/\n",
      "  Running job: job_1493936954640_1415\n",
      "  Job job_1493936954640_1415 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1415_m_000044_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@493134d1 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000045_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000062_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "   map 20% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1415_m_000057_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000054_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000055_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000056_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000059_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000050_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000048_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000051_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000063_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000069_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "   map 0% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1415_m_000060_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000052_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000049_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000058_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000064_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000046_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000065_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000053_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000072_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000067_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000061_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000068_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000081_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000079_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000083_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000087_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000047_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000078_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000076_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000073_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000082_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000086_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000077_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000074_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000075_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000085_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000084_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000066_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000080_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000071_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000070_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58c856a5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000157_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@4afcdc83 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000158_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5402b0f5 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000172_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000162_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task Id : attempt_1493936954640_1415_m_000164_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000044_1001, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000167_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000168_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000173_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000169_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000161_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000159_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000178_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000180_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000163_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000171_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000170_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000160_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000179_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000174_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000175_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000166_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000176_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000177_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000165_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@237601bd rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000181_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@34cc867b rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000186_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@37d9f8c8 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000184_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@37d9f8c8 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000187_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@37d9f8c8 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000185_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@37d9f8c8 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000182_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@37d9f8c8 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1415_m_000183_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@37d9f8c8 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 56% reduce 0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   map 58% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1415 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170618.165741.358516/output\n",
      "Counters: 52\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=352\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=37010\n",
      "\t\tFILE: Number of bytes written=25619948\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156101116\n",
      "\t\tHDFS: Number of bytes written=352\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=76\n",
      "\t\tKilled map tasks=2\n",
      "\t\tLaunched map tasks=268\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=79\n",
      "\t\tRack-local map tasks=189\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10995574272\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=12823040\n",
      "\t\tTotal time spent by all map tasks (ms)=7158577\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=21475731\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5009\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=25045\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=7158577\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5009\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=631410\n",
      "\t\tCombine input records=2699\n",
      "\t\tCombine output records=1108\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=31307\n",
      "\t\tInput split bytes=32000\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=161994\n",
      "\t\tMap output materialized bytes=63404\n",
      "\t\tMap output records=2699\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=154040647680\n",
      "\t\tReduce input groups=1108\n",
      "\t\tReduce input records=1108\n",
      "\t\tReduce output records=2\n",
      "\t\tReduce shuffle bytes=63404\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=2216\n",
      "\t\tTotal committed heap usage (bytes)=299931533312\n",
      "\t\tVirtual memory (bytes) snapshot=421258887168\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170618.165741.358516/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170618.165741.358516...\n",
      "Removing temp directory /tmp/longest5gram.nhaas.20170618.165741.358516...\n",
      "WARNING:root:\n",
      "    Elapsed time: 115.008906126 seconds\n",
      "    In minutes: 1.9168151021 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r full_stripes_5.4.1.a\n",
    "!python longest5gram.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > full_stripes_5.4.1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\t[\"roplezimpredastrodonbraslpklson\",\"yhroaclmparcheyxmmioudavesaurus\",\"piofpilocowersuruasogetsesnegcp\",\"tyravopsifengoquapialloboskenuo\",\"owinfuyaiokenecksasxhyilpoynuat\"]\r\n",
      "155\t[\"aiopjumrxuyvaslyhypsibemapodikr\",\"ufrydiuuolbigasuaurusrexlisnaye\",\"rnoondqsrunsubunougrabberyairtc\",\"utahraptoredileipmilbdummyuveri\",\"syevrahvelocyallosauruslinrotsr\"]\r\n"
     ]
    }
   ],
   "source": [
    "!cat full_stripes_5.4.1.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Stats: \n",
    "## example: \n",
    "## Longest 5grams MR stats\n",
    "\n",
    "    ec2_instance_type: m3.xlarge\n",
    "    num_ec2_instances: 15\n",
    "\n",
    "__Step 1:__  \n",
    "\n",
    "    RUNNING for 107.0s ~= 2 minutes  \n",
    "    Reduce tasks = 16 \n",
    "    \n",
    "__Step 2:__   \n",
    "\n",
    "    RUNNING for 108.8s ~= 2 minutes\n",
    "    Reduce tasks = 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - B. Top 10 most frequent words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mostFrequentWords.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostFrequentWords.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import logging\n",
    "import time\n",
    "\n",
    "class mostFrequentWords(MRJob):\n",
    "\n",
    "    # START STUDENT CODE 5.4.1.B\n",
    "            \n",
    "    MRJob.SORT_VALUES = True\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        # Split line\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        words = splits[0].lower().split()\n",
    "        count = int(splits[1])\n",
    "        \n",
    "        for word in words:\n",
    "            yield word, count\n",
    "            \n",
    "    \n",
    "    def combiner(self, word, counts):\n",
    "        total = sum(count for count in counts)\n",
    "        yield word, total\n",
    "    \n",
    "    def reducer(self, word, counts):\n",
    "        total = sum(count for count in counts)\n",
    "        yield total, word\n",
    "    \n",
    "    def max_reducer(self, count, words):\n",
    "        for word in words:\n",
    "            yield word, count\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'2',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1,1nr',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(mapper=self.mapper,\n",
    "                    reducer=self.reducer,\n",
    "                    combiner = self.combiner),\n",
    "                MRStep(jobconf=custom_jobconf,\n",
    "                       reducer=self.max_reducer)\n",
    "                 ]\n",
    "\n",
    "    # END STUDENT CODE 5.4.1.B\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    mostFrequentWords.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"\n",
    "    Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `systems_test_stripes_5.4.1.b_1': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/mostFrequentWords.nhaas.20170618.170424.354941\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170618.170424.354941/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob8813930603485221055.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1416\n",
      "  Submitted application application_1493936954640_1416\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1416/\n",
      "  Running job: job_1493936954640_1416\n",
      "  Job job_1493936954640_1416 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1416 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170618.170424.354941/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=357\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=430\n",
      "\t\tFILE: Number of bytes written=401162\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1017\n",
      "\t\tHDFS: Number of bytes written=357\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=14796288\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=12234240\n",
      "\t\tTotal time spent by all map tasks (ms)=9633\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=28899\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4779\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=23895\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=9633\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4779\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2860\n",
      "\t\tCombine input records=50\n",
      "\t\tCombine output records=31\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=120\n",
      "\t\tInput split bytes=454\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=602\n",
      "\t\tMap output materialized bytes=458\n",
      "\t\tMap output records=50\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1910140928\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=31\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=458\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=62\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7765319680\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob7437954060517034284.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1417\n",
      "  Submitted application application_1493936954640_1417\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1417/\n",
      "  Running job: job_1493936954640_1417\n",
      "  Job job_1493936954640_1417 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1417 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170618.170424.354941/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=536\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=357\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=396\n",
      "\t\tFILE: Number of bytes written=400504\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=904\n",
      "\t\tHDFS: Number of bytes written=357\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10847232\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=21035520\n",
      "\t\tTotal time spent by all map tasks (ms)=7062\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=21186\n",
      "\t\tTotal time spent by all reduce tasks (ms)=8217\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=41085\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=7062\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=8217\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2650\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=125\n",
      "\t\tInput split bytes=368\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=385\n",
      "\t\tMap output materialized bytes=437\n",
      "\t\tMap output records=28\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1907986432\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=28\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=437\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=56\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7775019008\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170618.170424.354941/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170618.170424.354941...\n",
      "Removing temp directory /tmp/mostFrequentWords.nhaas.20170618.170424.354941...\n",
      "WARNING:root:\n",
      "    Elapsed time: 93.5063180923 seconds\n",
      "    In minutes: 1.55843863487 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r systems_test_stripes_5.4.1.b_1\n",
    "!python mostFrequentWords.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > systems_test_stripes_5.4.1.b_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\"\t2217\r\n",
      "\"in\"\t1201\r\n",
      "\"wales\"\t1099\r\n",
      "\"christmas\"\t1099\r\n",
      "\"child's\"\t1099\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 systems_test_stripes_5.4.1.b_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `full_mostFrequentWords_5.4.1.b': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/mostFrequentWords.nhaas.20170618.170830.700538\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170618.170830.700538/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob1375799101070895404.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1493936954640_1418\n",
      "  Submitted application application_1493936954640_1418\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1418/\n",
      "  Running job: job_1493936954640_1418\n",
      "  Job job_1493936954640_1418 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1418_m_000088_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@6d8adab1 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000090_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000098_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000089_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000093_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000107_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000118_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000116_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000102_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000120_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000091_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000126_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000104_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000100_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000124_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000113_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000097_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000095_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000115_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000111_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000109_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000119_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000106_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000121_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000101_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000117_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000099_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000112_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000092_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000094_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000114_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000103_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000110_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000096_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000105_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000108_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000122_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000127_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000129_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000123_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000157_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@55d58637 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000131_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000125_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000128_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000130_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3c19fa24 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000088_1001, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000158_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000164_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1418_m_000159_1000, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task Id : attempt_1493936954640_1418_m_000161_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000165_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "   map 1% reduce 0%\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000160_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000162_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000185_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000178_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000167_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000176_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000168_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000163_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000187_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000174_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "   map 2% reduce 0%\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000181_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000184_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000183_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000172_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000182_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000170_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000180_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000169_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000173_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000175_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000171_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000166_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000179_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000177_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "  Task Id : attempt_1493936954640_1418_m_000186_1000, Status : FAILED\r\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7c458cbe rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\r\n",
      "\r\n",
      "   map 3% reduce 0%\r\n",
      "   map 4% reduce 0%\r\n",
      "   map 5% reduce 0%\r\n",
      "   map 6% reduce 0%\r\n",
      "   map 7% reduce 0%\r\n",
      "   map 8% reduce 0%\r\n",
      "   map 9% reduce 0%\r\n",
      "   map 10% reduce 0%\r\n",
      "   map 11% reduce 0%\r\n",
      "   map 12% reduce 0%\r\n",
      "   map 13% reduce 0%\r\n",
      "   map 15% reduce 0%\r\n",
      "   map 16% reduce 0%\r\n",
      "   map 17% reduce 0%\r\n",
      "   map 19% reduce 0%\r\n",
      "   map 21% reduce 0%\r\n",
      "   map 22% reduce 0%\r\n",
      "   map 24% reduce 0%\r\n",
      "   map 26% reduce 0%\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 89% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 66%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1418 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170618.170830.700538/step-output/0000\n",
      "Counters: 52\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4158739\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=39015541\n",
      "\t\tFILE: Number of bytes written=138284058\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156101116\n",
      "\t\tHDFS: Number of bytes written=4158739\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=76\n",
      "\t\tKilled map tasks=2\n",
      "\t\tLaunched map tasks=268\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=80\n",
      "\t\tRack-local map tasks=188\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=21864963072\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=74662400\n",
      "\t\tTotal time spent by all map tasks (ms)=14235002\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=42705006\n",
      "\t\tTotal time spent by all reduce tasks (ms)=29165\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=145825\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=14235002\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=29165\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=5145000\n",
      "\t\tCombine input records=293411330\n",
      "\t\tCombine output records=6822745\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=79778\n",
      "\t\tInput split bytes=32000\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=3430141090\n",
      "\t\tMap output materialized bytes=73800744\n",
      "\t\tMap output records=293411330\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=154709381120\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=6822745\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=73800744\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=13645490\n",
      "\t\tTotal committed heap usage (bytes)=299992875008\n",
      "\t\tVirtual memory (bytes) snapshot=421233700864\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob7981004281968876636.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1419\n",
      "  Submitted application application_1493936954640_1419\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1419/\n",
      "  Running job: job_1493936954640_1419\n",
      "  Job job_1493936954640_1419 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1419 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170618.170830.700538/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=4176522\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4158739\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2953963\n",
      "\t\tFILE: Number of bytes written=6322894\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4176890\n",
      "\t\tHDFS: Number of bytes written=4158739\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=21866496\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=16578560\n",
      "\t\tTotal time spent by all map tasks (ms)=14236\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=42708\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6476\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=32380\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=14236\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6476\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=8880\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=160\n",
      "\t\tInput split bytes=368\n",
      "\t\tMap input records=269339\n",
      "\t\tMap output bytes=4428078\n",
      "\t\tMap output materialized bytes=2969260\n",
      "\t\tMap output records=269339\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1956212736\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=269339\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=2969260\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=538678\n",
      "\t\tTotal committed heap usage (bytes)=5280104448\n",
      "\t\tVirtual memory (bytes) snapshot=7775670272\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170618.170830.700538/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170618.170830.700538...\n",
      "Removing temp directory /tmp/mostFrequentWords.nhaas.20170618.170830.700538...\n",
      "WARNING:root:\n",
      "    Elapsed time: 244.35631609 seconds\n",
      "    In minutes: 4.07260526816 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r full_mostFrequentWords_5.4.1.b\n",
    "!python mostFrequentWords.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > full_mostFrequentWords_5.4.1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"the\"\t5490815394\r\n",
      "\"of\"\t3698583299\r\n",
      "\"to\"\t2227866570\r\n",
      "\"in\"\t1421312776\r\n",
      "\"a\"\t1361123022\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 full_mostFrequentWords_5.4.1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent words MR stats\n",
    "    \n",
    "    ec2_instance_type: m3.xlarge\n",
    "    num_ec2_instances: 15\n",
    "    \n",
    "__Step 1:__   \n",
    "\n",
    "    RUNNING for 590.7s ~= 10 minutes   \n",
    "    Launched map tasks=191  \n",
    "    Launched reduce tasks=57   \n",
    "\n",
    "__Step 2:__  \n",
    "\n",
    "    RUNNING for 76.6s   \n",
    "    Launched map tasks=110\n",
    "    Launched reduce tasks=16  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - C. 20 Most/Least densely appearing words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mostLeastDenseWords.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostLeastDenseWords.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import re\n",
    "import numpy as np\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class mostLeastDenseWords(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.C\n",
    "           \n",
    "    MRJob.SORT_VALUES = True\n",
    "        \n",
    "    def __init__(self, args):\n",
    "        super(mostLeastDenseWords, self).__init__(args)\n",
    "        self.total_word_count = None\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        # Split line\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        words = splits[0].lower().split()\n",
    "        count = int(splits[1])\n",
    "        \n",
    "        for word in words:\n",
    "            yield \"*\", count\n",
    "            yield word, count\n",
    "            \n",
    "    \n",
    "    def combiner(self, word, counts):\n",
    "        total = sum(count for count in counts)\n",
    "        yield word, total\n",
    "    \n",
    "    def reducer(self, word, counts):\n",
    "    \n",
    "        total = sum(count for count in counts)\n",
    "        \n",
    "        if word == \"*\":\n",
    "            self.total_word_count = total\n",
    "        else:\n",
    "            yield float(total) / float(self.total_word_count), word\n",
    "    \n",
    "    def max_reducer(self, count, words):\n",
    "        for word in words:\n",
    "            yield word, count\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'2',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-g -k1,1nr',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(\n",
    "                    mapper=self.mapper,\n",
    "                    reducer=self.reducer,\n",
    "                    combiner = self.combiner),\n",
    "                MRStep(jobconf=custom_jobconf,\n",
    "                       reducer=self.max_reducer)\n",
    "                 ]\n",
    "    \n",
    "    # END STUDENT CODE 5.4.1.C\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    mostLeastDenseWords.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"\n",
    "    Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `systems_test_stripes_5.4.1.c_1': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/mostLeastDenseWords.nhaas.20170618.171547.604068\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170618.171547.604068/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2929380256893476821.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1420\n",
      "  Submitted application application_1493936954640_1420\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1420/\n",
      "  Running job: job_1493936954640_1420\n",
      "  Job job_1493936954640_1420 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1420_r_000000_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@4184d1e9 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1420 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170618.171547.604068/step-output/0000\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=604\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=447\n",
      "\t\tFILE: Number of bytes written=401285\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1021\n",
      "\t\tHDFS: Number of bytes written=604\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tFailed reduce tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=2\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16180224\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=25041920\n",
      "\t\tTotal time spent by all map tasks (ms)=10534\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=31602\n",
      "\t\tTotal time spent by all reduce tasks (ms)=9782\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=48910\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10534\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=9782\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2870\n",
      "\t\tCombine input records=100\n",
      "\t\tCombine output records=33\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=120\n",
      "\t\tInput split bytes=458\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=1032\n",
      "\t\tMap output materialized bytes=477\n",
      "\t\tMap output records=100\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1904459776\n",
      "\t\tReduce input groups=29\n",
      "\t\tReduce input records=33\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=477\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=66\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7744655360\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob605964521648834550.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1421\n",
      "  Submitted application application_1493936954640_1421\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1421/\n",
      "  Running job: job_1493936954640_1421\n",
      "  Job job_1493936954640_1421 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1421_m_000001_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@6530ea1d rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1421_m_000000_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@6530ea1d rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1421 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170618.171547.604068/output\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=906\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=604\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=523\n",
      "\t\tFILE: Number of bytes written=400897\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1278\n",
      "\t\tHDFS: Number of bytes written=604\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=2\n",
      "\t\tLaunched map tasks=4\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=24592896\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=12702720\n",
      "\t\tTotal time spent by all map tasks (ms)=16011\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=48033\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4962\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=24810\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=16011\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4962\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2660\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=105\n",
      "\t\tInput split bytes=372\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=632\n",
      "\t\tMap output materialized bytes=613\n",
      "\t\tMap output records=28\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1890983936\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=28\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=613\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=56\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7742083072\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170618.171547.604068/output...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170618.171547.604068...\n",
      "Removing temp directory /tmp/mostLeastDenseWords.nhaas.20170618.171547.604068...\n",
      "WARNING:root:\n",
      "    Elapsed time: 103.258630037 seconds\n",
      "    In minutes: 1.72097716729 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r systems_test_stripes_5.4.1.c_1\n",
    "!python mostLeastDenseWords.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > systems_test_stripes_5.4.1.c_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\"\t0.2\r\n",
      "\"in\"\t0.1083446098\r\n",
      "\"wales\"\t0.099142986\r\n",
      "\"christmas\"\t0.099142986\r\n",
      "\"child's\"\t0.099142986\r\n",
      "\"of\"\t0.0912043302\r\n",
      "\"study\"\t0.0544880469\r\n",
      "\"case\"\t0.0544880469\r\n",
      "\"female\"\t0.0403247632\r\n",
      "\"collection\"\t0.0215606676\r\n",
      "\"the\"\t0.0111862878\r\n",
      "\"tales\"\t0.0110960758\r\n",
      "\"fairy\"\t0.0110960758\r\n",
      "\"forms\"\t0.0104645918\r\n",
      "\"government\"\t0.0092016238\r\n",
      "\"george\"\t0.0082995038\r\n",
      "\"general\"\t0.0082995038\r\n",
      "\"biography\"\t0.0082995038\r\n",
      "\"city\"\t0.0055931439\r\n",
      "\"circumstantial\"\t0.0055931439\r\n",
      "\"by\"\t0.0055931439\r\n",
      "\"sea\"\t0.0055931439\r\n",
      "\"narrative\"\t0.0055931439\r\n",
      "\"religious\"\t0.0053225079\r\n",
      "\"establishing\"\t0.0053225079\r\n",
      "\"for\"\t0.0053225079\r\n",
      "\"bill\"\t0.0053225079\r\n",
      "\"limited\"\t0.0049616599\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_5.4.1.c_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `full_mostLeastDenseWords_5.4.1.c': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/mostLeastDenseWords.nhaas.20170618.171753.888215\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170618.171753.888215/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob4255331465057885969.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1493936954640_1422\n",
      "  Submitted application application_1493936954640_1422\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1422/\n",
      "  Running job: job_1493936954640_1422\n",
      "  Job job_1493936954640_1422 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1422_m_000007_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@21abe39c rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000000_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@21abe39c rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000006_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@21abe39c rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000002_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@21abe39c rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000005_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@21abe39c rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000009_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@21abe39c rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000008_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@21abe39c rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000004_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@21abe39c rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000001_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@21abe39c rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000003_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@21abe39c rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000014_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000029_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000023_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000015_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7f5df38e rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000038_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000012_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000019_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000010_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7f5df38e rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000039_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000021_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000017_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000028_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000013_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000034_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000031_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000041_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000018_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000043_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000027_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000042_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000032_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000030_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000016_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000011_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000036_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000025_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000026_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000033_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000040_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000035_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000037_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000024_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000022_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000020_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5624cd45 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000165_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@744804c3 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000159_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@744804c3 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000161_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@744804c3 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000162_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@744804c3 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000160_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@744804c3 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task Id : attempt_1493936954640_1422_m_000164_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@744804c3 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000158_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@744804c3 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000157_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@744804c3 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000166_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@744804c3 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1422_m_000163_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@744804c3 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 80% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 86% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 94% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 66%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1422 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170618.171753.888215/step-output/0000\n",
      "Counters: 52\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=6511551\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=39018054\n",
      "\t\tFILE: Number of bytes written=138295101\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156101116\n",
      "\t\tHDFS: Number of bytes written=6511551\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=54\n",
      "\t\tKilled map tasks=3\n",
      "\t\tLaunched map tasks=247\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=58\n",
      "\t\tRack-local map tasks=189\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=32578830336\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=73157120\n",
      "\t\tTotal time spent by all map tasks (ms)=21210176\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=63630528\n",
      "\t\tTotal time spent by all reduce tasks (ms)=28577\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=142885\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=21210176\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=28577\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=9055760\n",
      "\t\tCombine input records=586822660\n",
      "\t\tCombine output records=6822933\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=124334\n",
      "\t\tInput split bytes=32000\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=5878243690\n",
      "\t\tMap output materialized bytes=73804117\n",
      "\t\tMap output records=586822660\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=154960642048\n",
      "\t\tReduce input groups=269340\n",
      "\t\tReduce input records=6822933\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=73804117\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=13645866\n",
      "\t\tTotal committed heap usage (bytes)=298135846912\n",
      "\t\tVirtual memory (bytes) snapshot=421066342400\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob6138854185158350659.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1423\n",
      "  Submitted application application_1493936954640_1423\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1423/\n",
      "  Running job: job_1493936954640_1423\n",
      "  Job job_1493936954640_1423 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1423_r_000000_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@6ff6fe07 rejected from java.util.concurrent.ThreadPoolExecutor@32a6cf5b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 30]\n",
      "\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1423 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170618.171753.888215/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=6532576\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=6511551\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3064653\n",
      "\t\tFILE: Number of bytes written=6538821\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=6532948\n",
      "\t\tHDFS: Number of bytes written=6511551\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tFailed reduce tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=2\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=13479936\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=25825280\n",
      "\t\tTotal time spent by all map tasks (ms)=8776\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=26328\n",
      "\t\tTotal time spent by all reduce tasks (ms)=10088\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=50440\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=8776\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=10088\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=8390\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=156\n",
      "\t\tInput split bytes=372\n",
      "\t\tMap input records=269339\n",
      "\t\tMap output bytes=6780890\n",
      "\t\tMap output materialized bytes=3074404\n",
      "\t\tMap output records=269339\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1958060032\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=269339\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=3074404\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=538678\n",
      "\t\tTotal committed heap usage (bytes)=5203034112\n",
      "\t\tVirtual memory (bytes) snapshot=7776456704\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170618.171753.888215/output...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170618.171753.888215...\n",
      "Removing temp directory /tmp/mostLeastDenseWords.nhaas.20170618.171753.888215...\n",
      "WARNING:root:\n",
      "    Elapsed time: 328.766737938 seconds\n",
      "    In minutes: 5.4794456323 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r full_mostLeastDenseWords_5.4.1.c\n",
    "!python mostLeastDenseWords.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > full_mostLeastDenseWords_5.4.1.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=192\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Highest frequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"the\"\t0.1108347829\r\n",
      "\"of\"\t0.0746577052\r\n",
      "\"to\"\t0.0449705718\r\n",
      "\"in\"\t0.0286898906\r\n",
      "\"a\"\t0.0274749311\r\n",
      "\"and\"\t0.0232047813\r\n",
      "\"that\"\t0.0162073544\r\n",
      "\"is\"\t0.0153072361\r\n",
      "\"be\"\t0.0139018888\r\n",
      "\"as\"\t0.0099346975\r\n",
      "\"it\"\t0.00983431\r\n",
      "\"was\"\t0.0094945978\r\n",
      "\"for\"\t0.0093389722\r\n",
      "\"not\"\t0.0080856977\r\n",
      "\"with\"\t0.0075914555\r\n",
      "\"on\"\t0.0072231848\r\n",
      "\"by\"\t0.0070078767\r\n",
      "\"he\"\t0.0064625413\r\n",
      "\"have\"\t0.0064079076\r\n",
      "\"which\"\t0.0056949527\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 full_mostLeastDenseWords_5.4.1.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowest frequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"instillest\"\t0.0000000008\r\n",
      "\"glycasme\"\t0.0000000008\r\n",
      "\"dantonists\"\t0.0000000008\r\n",
      "\"jurisfirma\"\t0.0000000008\r\n",
      "\"danton's\"\t0.0000000008\r\n",
      "\"glur\"\t0.0000000008\r\n",
      "\"alcayaga\"\t0.0000000008\r\n",
      "\"istedetfor\"\t0.0000000008\r\n",
      "\"frugall\"\t0.0000000008\r\n",
      "\"fixin's\"\t0.0000000008\r\n",
      "\"alcarria\"\t0.0000000008\r\n",
      "\"highheeled\"\t0.0000000008\r\n",
      "\"insterburg\"\t0.0000000008\r\n",
      "\"fixin\"\t0.0000000008\r\n",
      "\"farallones\"\t0.0000000008\r\n",
      "\"juro\"\t0.0000000008\r\n",
      "\"fructum\"\t0.0000000008\r\n",
      "\"arroquhar\"\t0.0000000008\r\n",
      "\"frsenum\"\t0.0000000008\r\n",
      "\"glumdalia\"\t0.0000000008\r\n"
     ]
    }
   ],
   "source": [
    "!tail -20 full_mostLeastDenseWords_5.4.1.c\n",
    "#TODO revert order probably"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word density MR stats\n",
    "\n",
    "    ec2_instance_type: m3.xlarge\n",
    "    num_ec2_instances: 15\n",
    "    \n",
    "__Step 1:__ \n",
    "\n",
    "    RUNNING for 649.2s  ~= 10 minutes      \n",
    "    Launched map tasks=190   \n",
    "    Launched reduce tasks=57     \n",
    "\n",
    "__Step 2:__  \n",
    "\n",
    "    RUNNING for 74.4s  ~= 1 minute    \n",
    "    Launched map tasks=110   \n",
    "    Launched reduce tasks=20   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - D. Distribution of 5-gram sizes (character length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing distribution.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile distribution.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class distribution(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.D\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        # Split line\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        words = splits[0].lower().split()\n",
    "        \n",
    "        char_count = 0\n",
    "        \n",
    "        # Count characters\n",
    "        for word in words:\n",
    "            char_count += len(word)\n",
    "        \n",
    "        yield char_count, 1\n",
    "            \n",
    "    \n",
    "    def combiner(self, ngram_size, counts):\n",
    "        yield ngram_size, sum(count for count in counts)\n",
    "    \n",
    "    def reducer(self, ngram_size, counts):\n",
    "        yield ngram_size, sum(count for count in counts)\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'2',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1,1n',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(\n",
    "                    jobconf=custom_jobconf,\n",
    "                    mapper=self.mapper,\n",
    "                    reducer=self.reducer,\n",
    "                    combiner = self.combiner)\n",
    "        ]\n",
    "\n",
    "    # END STUDENT CODE 5.4.1.D\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    distribution.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"\n",
    "    Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `5.3distributions_test/part-00000': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/distribution.nhaas.20170618.172716.269022\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170618.172716.269022/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob1466857232757517040.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1493936954640_1424\n",
      "  Submitted application application_1493936954640_1424\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1424/\n",
      "  Running job: job_1493936954640_1424\n",
      "  Job job_1493936954640_1424 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1424 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170618.172716.269022/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=45\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=68\n",
      "\t\tFILE: Number of bytes written=401224\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1007\n",
      "\t\tHDFS: Number of bytes written=45\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=14922240\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=11604480\n",
      "\t\tTotal time spent by all map tasks (ms)=9715\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=29145\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4533\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=22665\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=9715\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4533\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2870\n",
      "\t\tCombine input records=10\n",
      "\t\tCombine output records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=115\n",
      "\t\tInput split bytes=444\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=60\n",
      "\t\tMap output materialized bytes=88\n",
      "\t\tMap output records=10\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1906745344\n",
      "\t\tReduce input groups=9\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=9\n",
      "\t\tReduce shuffle bytes=88\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=20\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7748718592\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170618.172716.269022/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170618.172716.269022...\n",
      "Removing temp directory /tmp/distribution.nhaas.20170618.172716.269022...\n",
      "WARNING:root:\n",
      "    Elapsed time: 56.7429659367 seconds\n",
      "    In minutes: 0.945716098944 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r 5.3distributions_test/part-00000\n",
    "!python distribution.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt \\\n",
    "    --python-bin=./my_env/bin/python \\\n",
    "    --archive=\"hdfs:///user/nhaas/virtualenv/my_env.zip#my_env\" \\\n",
    "    > 5.3distributions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\t1\r\n",
      "18\t1\r\n",
      "19\t1\r\n",
      "20\t1\r\n",
      "22\t1\r\n",
      "23\t1\r\n",
      "24\t1\r\n",
      "25\t1\r\n",
      "29\t2\r\n"
     ]
    }
   ],
   "source": [
    "!cat 5.3distributions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Histogram 10-line test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named matplotlib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-3296fd122292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-104>\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/IPython/core/magics/pylab.pyc\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   2935\u001b[0m         \"\"\"\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[0;34m(gui, gui_select)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named matplotlib"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "results_A = []\n",
    "for line in open(\"5.3distributions_test\").readlines():\n",
    "    line = line.strip()\n",
    "    X,Y = line.split(\"\\t\")\n",
    "    results_A.append([int(X),int(Y)])\n",
    "\n",
    "items = (np.array(results_A)[::-1].T)\n",
    "fig = pl.figure(figsize=(17,7))\n",
    "ax = pl.subplot(111)\n",
    "width=0.8\n",
    "ax.bar(range(len(items[0])), items[1], width=width)\n",
    "ax.set_xticks(np.arange(len(items[0])) + width/2)\n",
    "ax.set_xticklabels(items[0], rotation=90)\n",
    "ax.invert_xaxis()\n",
    "\n",
    "\n",
    "pl.title(\"Distributions of 5 Gram lengths in 10-line test\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `full_distribution_5.4.1.d': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/distribution.carlosscastro.20170616.213758.820515\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/carlosscastro/tmp/mrjob/distribution.carlosscastro.20170616.213758.820515/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob5620451318296715760.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1493936954640_1045\n",
      "  Submitted application application_1493936954640_1045\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1493936954640_1045/\n",
      "  Running job: job_1493936954640_1045\n",
      "  Job job_1493936954640_1045 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000047_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@749722d3 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000046_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@749722d3 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000043_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@749722d3 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000130_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5b8e343a rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000045_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@749722d3 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000042_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@749722d3 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000135_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@5b8e343a rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000132_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000131_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@515818f7 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000047_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@62a44a48 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000153_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000137_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@515818f7 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000147_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000134_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000159_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@62a44a48 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000136_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000142_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000149_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000148_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000145_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000144_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000138_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000151_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000143_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000154_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000046_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@62a44a48 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000140_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000139_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000152_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000158_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@62a44a48 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000133_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000141_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000146_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000150_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@13fb4cc4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000043_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@50ef41c4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000042_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@9bcfc1d rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000130_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@51260a23 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000045_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@51260a23 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000064_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000059_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000051_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000048_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000044_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@306a153d rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000068_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000071_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000049_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000061_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000066_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "   map 1% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000057_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000070_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000062_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000072_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000055_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000063_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000076_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000067_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000065_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000053_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "   map 0% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000060_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000069_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000056_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000079_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000075_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000054_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000073_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000077_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000084_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000058_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000050_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000082_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000085_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000081_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000080_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000083_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000052_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000132_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@1f9d5d13 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000078_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000074_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@23e12fb5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "   map 2% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000157_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@793c7075 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000155_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@793c7075 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000137_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@46fcd14a rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000153_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@46fcd14a rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000156_0, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@793c7075 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000159_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@46fcd14a rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000135_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@793c7075 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000047_2, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@46fcd14a rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000131_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3320e74f rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000147_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@24b7c0a1 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "   map 1% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000149_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@4a51c7c9 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000134_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@46fcd14a rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000136_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@78ff8f5c rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000142_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@41b7526a rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000148_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@1505e8a5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000144_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@91a05cf rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000145_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@15a91d rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000154_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7227e606 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000138_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@336c5c69 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000143_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@75540b99 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "   map 0% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000140_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@6a59928e rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000046_2, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@468670ca rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000151_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@e4f9d2d rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000141_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@19eea85a rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000158_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@4cd83d44 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000139_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@57212aa0 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000133_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@4cd83d44 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000150_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58706055 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000152_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@61346078 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "   map 1% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000043_2, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@55136d6 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000045_2, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@2fda38d9 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000146_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@77e75f4c rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000130_2, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@6cd49c0a rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000064_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@201f7773 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000042_2, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@77215031 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000051_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@591fdd rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000048_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7811e582 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000059_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@c80afed rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000044_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@62c8c8be rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000068_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@62c8c8be rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000049_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@2d6fb660 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000066_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@169d15d8 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000071_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@4b713ac4 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000057_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@169d15d8 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "   map 2% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000062_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@1c6dee3d rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000072_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@119872b7 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000061_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3b208ef4 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000063_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3a8249ca rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000070_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7aaa2411 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000076_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@4dd8ef74 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "   map 3% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000055_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@4166633e rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000065_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7ac83866 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000067_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@66de41c8 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000053_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@43e992d0 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000069_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@683dff12 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "   map 4% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000060_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7524f506 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000054_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@11456e43 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000056_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@7303e577 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000075_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@222f06ba rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000079_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@6450a163 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000058_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@1f1476bd rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000084_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@1bd5cec5 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "   map 5% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000050_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@4483468c rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000082_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@22e6713e rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000077_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@522ea7b rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000073_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@522ea7b rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "   map 6% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000085_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@4a7e4ed2 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000081_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@3bbe67a0 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000080_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@2ff39a4 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "   map 7% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000052_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@33287a2e rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000083_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@f918975 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000132_2, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@61d5f775 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "   map 8% reduce 0%\n",
      "  Task Id : attempt_1493936954640_1045_m_000074_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@58b8abab rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000155_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@77880f5b rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000078_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@51027a7 rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000156_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@6d500ec6 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000157_1, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@56394d40 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000153_2, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@6d500ec6 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "  Task Id : attempt_1493936954640_1045_m_000137_2, Status : FAILED\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@26d1c5de rejected from java.util.concurrent.ThreadPoolExecutor@5a2a86cf[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 630]\n",
      "\n",
      "   map 10% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1493936954640_1045 failed with state FAILED due to: Task failed task_1493936954640_1045_m_000047\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "  Job not successful!\n",
      "  Streaming Command Failed!\n",
      "Counters: 17\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=160\n",
      "\t\tKilled map tasks=187\n",
      "\t\tKilled reduce tasks=1\n",
      "\t\tLaunched map tasks=250\n",
      "\t\tOther local map tasks=90\n",
      "\t\tRack-local map tasks=160\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=6435975168\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=0\n",
      "\t\tTotal time spent by all map tasks (ms)=4190088\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=12570264\n",
      "\t\tTotal time spent by all reduce tasks (ms)=0\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=4190088\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "Scanning logs for probable cause of failure...\n",
      "Probable cause of failure:\n",
      "\n",
      "Task java.util.concurrent.ExecutorCompletionService$QueueingFuture@6d500ec6 rejected from java.util.concurrent.ThreadPoolExecutor@28d3db65[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 744]\n",
      "\n",
      "Step 1 of 1 failed: Command '['/opt/hadoop/bin/hadoop', 'jar', '/opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar', '-files', 'hdfs:///user/carlosscastro/tmp/mrjob/distribution.carlosscastro.20170616.213758.820515/files/distribution.py#distribution.py,hdfs:///user/carlosscastro/tmp/mrjob/distribution.carlosscastro.20170616.213758.820515/files/setup-wrapper.sh#setup-wrapper.sh', '-archives', 'hdfs:///user/carlosscastro/tmp/mrjob/distribution.carlosscastro.20170616.213758.820515/files/mrjob.tar.gz#mrjob.tar.gz', '-D', u'mapred.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator', '-D', u'mapred.reduce.tasks=1', '-D', u'mapred.text.key.comparator.options=-k1,1n', '-D', 'mapred.text.key.partitioner.options=-k1,1', '-D', u'mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator', '-D', u'mapreduce.job.reduces=1', '-D', u'mapreduce.partition.keycomparator.options=-k1,1n', '-D', 'mapreduce.partition.keypartitioner.options=-k1,1', '-D', u'stream.num.map.output.key.fields=2', '-partitioner', 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner', '-input', 'hdfs:///user/cendylin/filtered-5Grams/', '-output', 'hdfs:///user/carlosscastro/tmp/mrjob/distribution.carlosscastro.20170616.213758.820515/output', '-mapper', 'sh -ex setup-wrapper.sh python distribution.py --step-num=0 --mapper', '-combiner', 'sh -ex setup-wrapper.sh python distribution.py --step-num=0 --combiner', '-reducer', 'sh -ex setup-wrapper.sh python distribution.py --step-num=0 --reducer']' returned non-zero exit status 256\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r full_distribution_5.4.1.d\n",
    "!python distribution.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > full_distribution_5.4.1.d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### something here that cats out from the previous directory the mapper and reducer tasks\n",
    "### or, we can declare them and call them as args then print out the args\n",
    "### in this case:\n",
    "### Launched map tasks=2\n",
    "### Launched reduce tasks=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution MRJob stats\n",
    "\n",
    "__Step 1:__ \n",
    "\n",
    "    RUNNING for 157.8s ~= 2.6 minutes  \n",
    "    Launched map tasks=191  \n",
    "    Launched reduce tasks=16   \n",
    "    \n",
    "__Step 2:__  \n",
    "\n",
    "    RUNNING for 115.0s ~= 2 minutes   \n",
    "    Launched map tasks=139\n",
    "\tLaunched reduce tasks=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/oAAAG1CAYAAABJd48xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6645470850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "results_A = []\n",
    "for line in open(\"full_distribution_5.4.1.d\").readlines():\n",
    "    line = line.strip()\n",
    "    X,Y = line.split(\"\\t\")\n",
    "    results_A.append([int(X),int(Y)])\n",
    "\n",
    "items = (np.array(results_A)[::-1].T)\n",
    "fig = pl.figure(figsize=(17,7))\n",
    "ax = pl.subplot(111)\n",
    "width=0.8\n",
    "ax.bar(range(len(items[0])), items[1], width=width)\n",
    "ax.set_xticks(np.arange(len(items[0])) + width/2)\n",
    "ax.set_xticklabels(items[0], rotation=90)\n",
    "ax.invert_xaxis()\n",
    "\n",
    "\n",
    "pl.title(\"Distributions of 5 Gram lengths\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO revert order of counts in chart\n",
    "### NH - done, used ax.invert_xaxis()\n",
    "### http://matplotlib.org/devdocs/api/_as_gen/matplotlib.axes.Axes.invert_xaxis.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.4.2 <a name=\"5.4.2\"></a>OPTIONAL Question: log-log plots (PHASE 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Plot the log-log plot of the frequency distributuion of unigrams. Does it follow power law distribution?\n",
    "\n",
    "For more background see:\n",
    "- https://en.wikipedia.org/wiki/Log%E2%80%93log_plot\n",
    "- https://en.wikipedia.org/wiki/Power_law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.5  <a name=\"5.5\"></a> Synonym detection over 2Gig of Data with extra Preprocessing steps (HW5.3 plus some preprocessing)   (Phase 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "For the remainder of this assignment please feel free to eliminate stop words from your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">There is also a corpus of stopwords, that is, high-frequency words like \"the\", \"to\" and \"also\" that we sometimes want to filter out of a document before further processing. Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts. Python's nltk comes with a prebuilt list of stopwords (see below). Using this stopword list filter out these tokens from your analysis and rerun the experiments in 5.5 and disucuss the results of using a stopword list and without using a stopword list.\n",
    "\n",
    "> from nltk.corpus import stopwords\n",
    " stopwords.words('english')\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: A large subset of the Google n-grams dataset as was described above\n",
    "\n",
    "For each HW 5.4 -5.5.1 Please unit test and system test your code with respect \n",
    "to SYSTEMS TEST DATASET and show the results. \n",
    "Please compute the expected answer by hand and show your hand calculations for the \n",
    "SYSTEMS TEST DATASET. Then show the results you get with your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment we will focus on developing methods for detecting synonyms, using the Google 5-grams dataset. At a high level:\n",
    "\n",
    "\n",
    "1. remove stopwords\n",
    "2. get 10,0000 most frequent\n",
    "3. get 1000 (9001-10000) features\n",
    "3. build stripes\n",
    "\n",
    "To accomplish this you must script two main tasks using MRJob:\n",
    "\n",
    "\n",
    "__TASK (1)__ Build stripes for the most frequent 10,000 words using cooccurence information based on\n",
    "the words ranked from 9001,-10,000 as a basis/vocabulary (drop stopword-like terms),\n",
    "and output to a file in your bucket on s3 (bigram analysis, though the words are non-contiguous).\n",
    "\n",
    "\n",
    "__TASK (2)__ Using two (symmetric) comparison methods of your choice \n",
    "(e.g., correlations, distances, similarities), pairwise compare \n",
    "all stripes (vectors), and output to a file in your bucket on s3.\n",
    "\n",
    "#### Design notes for TASK (1)\n",
    "For this task you will be able to modify the pattern we used in HW 3.2\n",
    "(feel free to use the solution as reference). To total the word counts \n",
    "across the 5-grams, output the support from the mappers using the total \n",
    "order inversion pattern:\n",
    "\n",
    "<*word,count>\n",
    "\n",
    "to ensure that the support arrives before the cooccurrences.\n",
    "\n",
    "In addition to ensuring the determination of the total word counts,\n",
    "the mapper must also output co-occurrence counts for the pairs of\n",
    "words inside of each 5-gram. Treat these words as a basket,\n",
    "as we have in HW 3, but count all stripes or pairs in both orders,\n",
    "i.e., count both orderings: (word1,word2), and (word2,word1), to preserve\n",
    "symmetry in our output for TASK (2).\n",
    "\n",
    "#### Design notes for _TASK (2)_\n",
    "For this task you will have to determine a method of comparison.\n",
    "Here are a few that you might consider:\n",
    "\n",
    "- Jaccard\n",
    "- Cosine similarity\n",
    "- Spearman correlation\n",
    "- Euclidean distance\n",
    "- Taxicab (Manhattan) distance\n",
    "- Shortest path graph distance (a graph, because our data is symmetric!)\n",
    "- Pearson correlation\n",
    "- Kendall correlation\n",
    "\n",
    "However, be cautioned that some comparison methods are more difficult to\n",
    "parallelize than others, and do not perform more associations than is necessary, \n",
    "since your choice of association will be symmetric.\n",
    "\n",
    "Please use the inverted index (discussed in live session #5) based pattern to compute the pairwise (term-by-term) similarity matrix. \n",
    "\n",
    "Please report the size of the cluster used and the amount of time it takes to run for the index construction task and for the synonym calculation task. How many pairs need to be processed (HINT: use the posting list length to calculate directly)? Report your  Cluster configuration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example MR stats: (report times!)\n",
    "    took ~11 minutes on 5 m3.xlarge nodes\n",
    "    Data-local map tasks=188\n",
    "\tLaunched map tasks=190\n",
    "\tLaunched reduce tasks=15\n",
    "\tOther local map tasks=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT CODE 5.5\n",
    "# ADD OR REMOVE CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Frequency ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting frequencies5_5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile frequencies5_5.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class frequencies(MRJob):\n",
    "\n",
    "    # START STUDENT CODE 5.4.1.B\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "        \n",
    "    def __init__(self, args):\n",
    "        super(frequencies, self).__init__(args)\n",
    "        #self.min_rank = 9001\n",
    "        #self.max_rank = 10000 \n",
    "        self.current_rank = 0\n",
    "\n",
    "    def configure_options(self): \n",
    "        super(frequencies, self).configure_options() \n",
    "        self.add_passthrough_option('--min_rank', dest='min_rank', type='int', default=9001) \n",
    "        self.add_passthrough_option('--max_rank', dest='max_rank', type='int', default=10000) \n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        # Split line\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        words = splits[0].lower().split()\n",
    "        count = int(splits[1])\n",
    "        \n",
    "        for word in words:\n",
    "            yield word, count\n",
    "            \n",
    "    \n",
    "    def combiner(self, word, counts):\n",
    "        total = sum(count for count in counts)\n",
    "        yield word, total\n",
    "    \n",
    "    def reducer(self, word, counts):\n",
    "        total = sum(count for count in counts)\n",
    "        yield total, word\n",
    "    \n",
    "    def max_reducer(self, count, words):\n",
    "        \n",
    "        # Words come in frequency descending order here\n",
    "        # Only yield the words that are within the min and max frequency ranking desired\n",
    "        \n",
    "        for word in words:\n",
    "            self.current_rank += 1\n",
    "            \n",
    "            if self.current_rank >= self.options.min_rank and self.current_rank <= self.options.max_rank:\n",
    "                yield word, count\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'2',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1,1nr',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(mapper=self.mapper,\n",
    "                    reducer=self.reducer,\n",
    "                    combiner = self.combiner),\n",
    "                MRStep(jobconf=custom_jobconf,\n",
    "                       reducer=self.max_reducer)\n",
    "                 ]\n",
    "\n",
    "    # END STUDENT CODE 5.4.1.B\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    frequencies.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency ranking on 10-line test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `frequencies_test5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/frequencies5_5.root.20170617.064611.795960\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.064611.795960/files/...\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob6501946044622006350.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0017\n",
      "  Submitted application application_1497651454196_0017\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0017/\n",
      "  Running job: job_1497651454196_0017\n",
      "  Job job_1497651454196_0017 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0017 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.064611.795960/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=357\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=450\n",
      "\t\tFILE: Number of bytes written=357716\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=999\n",
      "\t\tHDFS: Number of bytes written=357\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=5978112\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2454528\n",
      "\t\tTotal time spent by all map tasks (ms)=5838\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=5838\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2397\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2397\n",
      "\t\tTotal vcore-seconds taken by all map tasks=5838\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2397\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1310\n",
      "\t\tCombine input records=50\n",
      "\t\tCombine output records=31\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=59\n",
      "\t\tInput split bytes=436\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=602\n",
      "\t\tMap output materialized bytes=456\n",
      "\t\tMap output records=50\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=711380992\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=31\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=456\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=62\n",
      "\t\tTotal committed heap usage (bytes)=681050112\n",
      "\t\tVirtual memory (bytes) snapshot=4082651136\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  mapred.output.key.comparator.class is deprecated. Instead, use mapreduce.job.output.key.comparator.class\n",
      "  mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "  mapred.text.key.comparator.options is deprecated. Instead, use mapreduce.partition.keycomparator.options\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob7656495397508618994.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0018\n",
      "  Submitted application application_1497651454196_0018\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0018/\n",
      "  Running job: job_1497651454196_0018\n",
      "  Job job_1497651454196_0018 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0018 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.064611.795960/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=536\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=40\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=447\n",
      "\t\tFILE: Number of bytes written=357092\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=884\n",
      "\t\tHDFS: Number of bytes written=40\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=5491712\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2336768\n",
      "\t\tTotal time spent by all map tasks (ms)=5363\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=5363\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2282\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2282\n",
      "\t\tTotal vcore-seconds taken by all map tasks=5363\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2282\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1170\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=67\n",
      "\t\tInput split bytes=348\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=385\n",
      "\t\tMap output materialized bytes=453\n",
      "\t\tMap output records=28\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=742617088\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=28\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=453\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=56\n",
      "\t\tTotal committed heap usage (bytes)=718798848\n",
      "\t\tVirtual memory (bytes) snapshot=4123873280\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.064611.795960/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.064611.795960...\n",
      "Removing temp directory /tmp/frequencies5_5.root.20170617.064611.795960...\n",
      "WARNING:root:Elapsed time: 50.3576421738 seconds\n",
      "    In minutes: 0.839294036229 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r frequencies_test5.5\n",
    "!python frequencies5_5.py --min_rank 2 --max_rank 4 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt > frequencies_test5.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"in\"\t1201\r\n",
      "\"wales\"\t1099\r\n",
      "\"christmas\"\t1099\r\n"
     ]
    }
   ],
   "source": [
    "!cat frequencies_test5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency ranking on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `frequencies5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/frequencies5_5.root.20170617.064704.573509\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.064704.573509/files/...\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob7441672275223634582.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0019\n",
      "  Submitted application application_1497651454196_0019\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0019/\n",
      "  Running job: job_1497651454196_0019\n",
      "  Job job_1497651454196_0019 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0019 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.064704.573509/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=11448710\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=538130\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=901704\n",
      "\t\tFILE: Number of bytes written=2159945\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=11449116\n",
      "\t\tHDFS: Number of bytes written=538130\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=29306880\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=3351552\n",
      "\t\tTotal time spent by all map tasks (ms)=28620\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=28620\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3273\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3273\n",
      "\t\tTotal vcore-seconds taken by all map tasks=28620\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=3273\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=14300\n",
      "\t\tCombine input records=1558070\n",
      "\t\tCombine output records=54102\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=95\n",
      "\t\tInput split bytes=406\n",
      "\t\tMap input records=311614\n",
      "\t\tMap output bytes=18210060\n",
      "\t\tMap output materialized bytes=901710\n",
      "\t\tMap output records=1558070\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=810401792\n",
      "\t\tReduce input groups=36353\n",
      "\t\tReduce input records=54102\n",
      "\t\tReduce output records=36353\n",
      "\t\tReduce shuffle bytes=901710\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=108204\n",
      "\t\tTotal committed heap usage (bytes)=912261120\n",
      "\t\tVirtual memory (bytes) snapshot=4093898752\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  mapred.output.key.comparator.class is deprecated. Instead, use mapreduce.job.output.key.comparator.class\n",
      "  mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "  mapred.text.key.comparator.options is deprecated. Instead, use mapreduce.partition.keycomparator.options\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob1232551452874026121.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0020\n",
      "  Submitted application application_1497651454196_0020\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0020/\n",
      "  Running job: job_1497651454196_0020\n",
      "  Job job_1497651454196_0020 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0020 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.064704.573509/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=542226\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=14825\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=647195\n",
      "\t\tFILE: Number of bytes written=1650498\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=542574\n",
      "\t\tHDFS: Number of bytes written=14825\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=6884352\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2805760\n",
      "\t\tTotal time spent by all map tasks (ms)=6723\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=6723\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2740\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2740\n",
      "\t\tTotal vcore-seconds taken by all map tasks=6723\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2740\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2750\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=83\n",
      "\t\tInput split bytes=348\n",
      "\t\tMap input records=36353\n",
      "\t\tMap output bytes=574483\n",
      "\t\tMap output materialized bytes=647201\n",
      "\t\tMap output records=36353\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=782143488\n",
      "\t\tReduce input groups=36353\n",
      "\t\tReduce input records=36353\n",
      "\t\tReduce output records=1000\n",
      "\t\tReduce shuffle bytes=647201\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=72706\n",
      "\t\tTotal committed heap usage (bytes)=826277888\n",
      "\t\tVirtual memory (bytes) snapshot=4092366848\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.064704.573509/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.064704.573509...\n",
      "Removing temp directory /tmp/frequencies5_5.root.20170617.064704.573509...\n",
      "WARNING:root:Elapsed time: 64.1946570873 seconds\n",
      "    In minutes: 1.06991095146 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python frequencies5_5.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"susceptibility\"\t878\r\n",
      "\"stooges\"\t878\r\n",
      "\"tribunals\"\t877\r\n",
      "\"parable\"\t877\r\n",
      "\"sanctuary\"\t877\r\n",
      "\"coupling\"\t876\r\n",
      "\"generic\"\t876\r\n",
      "\"collagen\"\t876\r\n",
      "\"clubs\"\t875\r\n",
      "\"fulness\"\t875\r\n",
      "\"se\"\t875\r\n",
      "\"pine\"\t875\r\n",
      "\"shelves\"\t874\r\n",
      "\"pigs\"\t874\r\n",
      "\"procuring\"\t874\r\n",
      "\"masterly\"\t874\r\n",
      "\"homogeneity\"\t874\r\n",
      "\"brigadier\"\t873\r\n",
      "\"humanities\"\t873\r\n",
      "\"mammalian\"\t873\r\n",
      "\"prolongation\"\t872\r\n",
      "\"rightly\"\t872\r\n",
      "\"instability\"\t872\r\n",
      "\"concerts\"\t871\r\n",
      "\"extracted\"\t871\r\n",
      "\"taylor\"\t871\r\n",
      "\"likeness\"\t871\r\n",
      "\"lee\"\t870\r\n",
      "\"tens\"\t870\r\n",
      "\"accepts\"\t870\r\n",
      "\"believers\"\t869\r\n",
      "\"deceive\"\t869\r\n",
      "\"exit\"\t869\r\n",
      "\"shipment\"\t869\r\n",
      "\"salient\"\t869\r\n",
      "\"lesbian\"\t869\r\n",
      "\"ragged\"\t868\r\n",
      "\"treachery\"\t868\r\n",
      "\"donor\"\t868\r\n",
      "\"au\"\t868\r\n",
      "\"guy\"\t868\r\n",
      "\"antique\"\t868\r\n",
      "\"asset\"\t868\r\n",
      "\"affective\"\t867\r\n",
      "\"cart\"\t867\r\n",
      "\"joys\"\t867\r\n",
      "\"arrives\"\t867\r\n",
      "\"rumor\"\t867\r\n",
      "\"specifics\"\t867\r\n",
      "\"nacional\"\t867\r\n",
      "\"surveys\"\t866\r\n",
      "\"label\"\t866\r\n",
      "\"momentous\"\t866\r\n",
      "\"preventive\"\t866\r\n",
      "\"eu\"\t866\r\n",
      "\"hampshire\"\t866\r\n",
      "\"disagree\"\t866\r\n",
      "\"fairy\"\t865\r\n",
      "\"commence\"\t865\r\n",
      "\"attaining\"\t865\r\n",
      "\"troublesome\"\t865\r\n",
      "\"weakened\"\t865\r\n",
      "\"taxed\"\t864\r\n",
      "\"rectus\"\t864\r\n",
      "\"cashier\"\t864\r\n",
      "\"driver\"\t864\r\n",
      "\"acceptor\"\t864\r\n",
      "\"juliet\"\t864\r\n",
      "\"compliment\"\t863\r\n",
      "\"forthcoming\"\t863\r\n",
      "\"maria\"\t863\r\n",
      "\"subdued\"\t863\r\n",
      "\"symptomatic\"\t863\r\n",
      "\"signifies\"\t863\r\n",
      "\"scenery\"\t862\r\n",
      "\"maid\"\t862\r\n",
      "\"clusters\"\t862\r\n",
      "\"goodbye\"\t862\r\n",
      "\"abhorrence\"\t862\r\n",
      "\"rash\"\t861\r\n",
      "\"samuel\"\t861\r\n",
      "\"strides\"\t861\r\n",
      "\"pharmacological\"\t861\r\n",
      "\"ok\"\t860\r\n",
      "\"occurrences\"\t860\r\n",
      "\"surviving\"\t860\r\n",
      "\"insofar\"\t860\r\n",
      "\"electorate\"\t859\r\n",
      "\"elite\"\t859\r\n",
      "\"proxy\"\t859\r\n",
      "\"refrigerator\"\t859\r\n",
      "\"mom\"\t859\r\n",
      "\"sore\"\t859\r\n",
      "\"stately\"\t858\r\n",
      "\"symposium\"\t858\r\n",
      "\"endanger\"\t858\r\n",
      "\"hailed\"\t858\r\n",
      "\"headings\"\t857\r\n",
      "\"earmarks\"\t857\r\n",
      "\"hinges\"\t857\r\n",
      "\"regiments\"\t857\r\n",
      "\"reverend\"\t856\r\n",
      "\"cochlear\"\t856\r\n",
      "\"heap\"\t856\r\n",
      "\"cruisers\"\t856\r\n",
      "\"consolidate\"\t856\r\n",
      "\"facilitated\"\t856\r\n",
      "\"impunity\"\t855\r\n",
      "\"bite\"\t855\r\n",
      "\"deposition\"\t855\r\n",
      "\"styloid\"\t855\r\n",
      "\"pink\"\t855\r\n",
      "\"professors\"\t855\r\n",
      "\"yourselves\"\t854\r\n",
      "\"solidarity\"\t854\r\n",
      "\"arched\"\t854\r\n",
      "\"infliction\"\t854\r\n",
      "\"inferences\"\t853\r\n",
      "\"hypertrophy\"\t853\r\n",
      "\"irregular\"\t853\r\n",
      "\"parentheses\"\t853\r\n",
      "\"seizing\"\t852\r\n",
      "\"rearing\"\t852\r\n",
      "\"sun's\"\t852\r\n",
      "\"restless\"\t852\r\n",
      "\"jutting\"\t852\r\n",
      "\"suffers\"\t852\r\n",
      "\"exertion\"\t852\r\n",
      "\"avowed\"\t852\r\n",
      "\"contacts\"\t851\r\n",
      "\"handkerchief\"\t851\r\n",
      "\"englishmen\"\t851\r\n",
      "\"infidel\"\t851\r\n",
      "\"subjective\"\t851\r\n",
      "\"secures\"\t851\r\n",
      "\"radiant\"\t850\r\n",
      "\"suez\"\t850\r\n",
      "\"weaknesses\"\t850\r\n",
      "\"fingertips\"\t850\r\n",
      "\"deferred\"\t850\r\n",
      "\"heading\"\t849\r\n",
      "\"combed\"\t849\r\n",
      "\"dublin\"\t849\r\n",
      "\"brush\"\t849\r\n",
      "\"professes\"\t849\r\n",
      "\"sur\"\t849\r\n",
      "\"proprietor\"\t849\r\n",
      "\"scared\"\t848\r\n",
      "\"objected\"\t848\r\n",
      "\"wife's\"\t848\r\n",
      "\"uncovered\"\t848\r\n",
      "\"bronchioles\"\t848\r\n",
      "\"benefited\"\t847\r\n",
      "\"bloodiest\"\t847\r\n",
      "\"fountain\"\t847\r\n",
      "\"hem\"\t847\r\n",
      "\"relish\"\t847\r\n",
      "\"swedish\"\t846\r\n",
      "\"unfit\"\t846\r\n",
      "\"thereon\"\t846\r\n",
      "\"foreseen\"\t846\r\n",
      "\"erie\"\t846\r\n",
      "\"closet\"\t846\r\n",
      "\"intolerable\"\t845\r\n",
      "\"dissatisfaction\"\t845\r\n",
      "\"chatted\"\t845\r\n",
      "\"foreigners\"\t845\r\n",
      "\"mail\"\t845\r\n",
      "\"reversals\"\t845\r\n",
      "\"pharisees\"\t845\r\n",
      "\"sigma\"\t845\r\n",
      "\"submucosa\"\t844\r\n",
      "\"wells\"\t844\r\n",
      "\"mutation\"\t844\r\n",
      "\"absurdity\"\t844\r\n",
      "\"expectancy\"\t844\r\n",
      "\"adolescent\"\t844\r\n",
      "\"disparity\"\t844\r\n",
      "\"denomination\"\t844\r\n",
      "\"await\"\t843\r\n",
      "\"callosum\"\t843\r\n",
      "\"accustom\"\t843\r\n",
      "\"subsidiary\"\t843\r\n",
      "\"packet\"\t842\r\n",
      "\"slot\"\t842\r\n",
      "\"simplification\"\t842\r\n",
      "\"maturation\"\t842\r\n",
      "\"ascent\"\t842\r\n",
      "\"gentry\"\t842\r\n",
      "\"contended\"\t842\r\n",
      "\"cannon\"\t842\r\n",
      "\"capabilities\"\t841\r\n",
      "\"distilled\"\t841\r\n",
      "\"bethlehem\"\t841\r\n",
      "\"inflict\"\t841\r\n",
      "\"exemplified\"\t841\r\n",
      "\"silly\"\t841\r\n",
      "\"po\"\t841\r\n",
      "\"sanitary\"\t841\r\n",
      "\"rumors\"\t841\r\n",
      "\"macedonians\"\t841\r\n",
      "\"sanctions\"\t841\r\n",
      "\"overlap\"\t840\r\n",
      "\"resumption\"\t840\r\n",
      "\"mills\"\t840\r\n",
      "\"subjection\"\t840\r\n",
      "\"placement\"\t840\r\n",
      "\"scotia\"\t840\r\n",
      "\"copied\"\t840\r\n",
      "\"chihuahua\"\t839\r\n",
      "\"pendulum\"\t839\r\n",
      "\"reproductive\"\t839\r\n",
      "\"laborer\"\t839\r\n",
      "\"sophisticated\"\t839\r\n",
      "\"wretch\"\t839\r\n",
      "\"parting\"\t838\r\n",
      "\"styles\"\t838\r\n",
      "\"disregard\"\t838\r\n",
      "\"chemicals\"\t838\r\n",
      "\"boom\"\t838\r\n",
      "\"constancy\"\t838\r\n",
      "\"amended\"\t837\r\n",
      "\"belize\"\t837\r\n",
      "\"challenging\"\t837\r\n",
      "\"baptism\"\t837\r\n",
      "\"surveillance\"\t837\r\n",
      "\"owes\"\t836\r\n",
      "\"peece\"\t836\r\n",
      "\"drowned\"\t836\r\n",
      "\"dramatically\"\t835\r\n",
      "\"charitable\"\t835\r\n",
      "\"antigens\"\t835\r\n",
      "\"strand\"\t835\r\n",
      "\"warnings\"\t835\r\n",
      "\"unification\"\t835\r\n",
      "\"locations\"\t834\r\n",
      "\"subversion\"\t834\r\n",
      "\"arduous\"\t834\r\n",
      "\"innovations\"\t834\r\n",
      "\"hereunto\"\t834\r\n",
      "\"discrete\"\t834\r\n",
      "\"andean\"\t833\r\n",
      "\"contradictory\"\t833\r\n",
      "\"repeatedly\"\t833\r\n",
      "\"vocabulary\"\t833\r\n",
      "\"swearing\"\t832\r\n",
      "\"vault\"\t832\r\n",
      "\"reinforcement\"\t832\r\n",
      "\"waived\"\t832\r\n",
      "\"constrained\"\t832\r\n",
      "\"advocated\"\t831\r\n",
      "\"effectually\"\t831\r\n",
      "\"excommunicated\"\t831\r\n",
      "\"sights\"\t831\r\n",
      "\"norfolk\"\t831\r\n",
      "\"resumed\"\t831\r\n",
      "\"alluded\"\t830\r\n",
      "\"cooled\"\t830\r\n",
      "\"anxiously\"\t830\r\n",
      "\"aliquot\"\t829\r\n",
      "\"designer\"\t829\r\n",
      "\"cataract\"\t829\r\n",
      "\"taxpayer\"\t829\r\n",
      "\"sessions\"\t829\r\n",
      "\"provoked\"\t829\r\n",
      "\"stigma\"\t829\r\n",
      "\"woke\"\t828\r\n",
      "\"assaults\"\t828\r\n",
      "\"denotes\"\t828\r\n",
      "\"decorated\"\t828\r\n",
      "\"mainland\"\t827\r\n",
      "\"spectacle\"\t827\r\n",
      "\"photographs\"\t826\r\n",
      "\"unlimited\"\t826\r\n",
      "\"manipulation\"\t826\r\n",
      "\"bladder\"\t826\r\n",
      "\"iliac\"\t826\r\n",
      "\"displaced\"\t825\r\n",
      "\"brushed\"\t825\r\n",
      "\"stump\"\t825\r\n",
      "\"oscillation\"\t825\r\n",
      "\"sang\"\t825\r\n",
      "\"denying\"\t824\r\n",
      "\"cottage\"\t823\r\n",
      "\"caution\"\t823\r\n",
      "\"backed\"\t823\r\n",
      "\"coil\"\t823\r\n",
      "\"contests\"\t823\r\n",
      "\"brigands\"\t823\r\n",
      "\"anti\"\t823\r\n",
      "\"pit\"\t823\r\n",
      "\"rs\"\t823\r\n",
      "\"tasting\"\t823\r\n",
      "\"accompaniment\"\t822\r\n",
      "\"conduction\"\t822\r\n",
      "\"gaping\"\t822\r\n",
      "\"hasten\"\t822\r\n",
      "\"feathers\"\t821\r\n",
      "\"fetch\"\t821\r\n",
      "\"cardinals\"\t821\r\n",
      "\"dined\"\t821\r\n",
      "\"peritoneal\"\t821\r\n",
      "\"trademarks\"\t820\r\n",
      "\"korean\"\t820\r\n",
      "\"retrieve\"\t820\r\n",
      "\"inconvenient\"\t820\r\n",
      "\"curved\"\t820\r\n",
      "\"aggravated\"\t820\r\n",
      "\"atrium\"\t820\r\n",
      "\"entity\"\t820\r\n",
      "\"authenticity\"\t819\r\n",
      "\"impurities\"\t819\r\n",
      "\"indicative\"\t819\r\n",
      "\"simplified\"\t819\r\n",
      "\"nazareth\"\t819\r\n",
      "\"summons\"\t819\r\n",
      "\"serotonin\"\t819\r\n",
      "\"splendor\"\t819\r\n",
      "\"shifting\"\t819\r\n",
      "\"aboard\"\t818\r\n",
      "\"flanders\"\t818\r\n",
      "\"careers\"\t818\r\n",
      "\"falsehood\"\t818\r\n",
      "\"amazement\"\t817\r\n",
      "\"iowa\"\t817\r\n",
      "\"jew\"\t817\r\n",
      "\"collector\"\t817\r\n",
      "\"locality\"\t817\r\n",
      "\"untrue\"\t817\r\n",
      "\"peered\"\t817\r\n",
      "\"midpoint\"\t817\r\n",
      "\"molten\"\t816\r\n",
      "\"surveyed\"\t816\r\n",
      "\"norwegian\"\t816\r\n",
      "\"vie\"\t816\r\n",
      "\"missions\"\t815\r\n",
      "\"suppressed\"\t815\r\n",
      "\"predictor\"\t815\r\n",
      "\"theorem\"\t815\r\n",
      "\"nearby\"\t815\r\n",
      "\"seizure\"\t815\r\n",
      "\"inclusive\"\t815\r\n",
      "\"curvature\"\t815\r\n",
      "\"bows\"\t815\r\n",
      "\"bail\"\t815\r\n",
      "\"binary\"\t814\r\n",
      "\"virtual\"\t814\r\n",
      "\"politically\"\t813\r\n",
      "\"microcosm\"\t813\r\n",
      "\"hiv\"\t813\r\n",
      "\"groans\"\t813\r\n",
      "\"foreword\"\t813\r\n",
      "\"employing\"\t813\r\n",
      "\"beheld\"\t813\r\n",
      "\"damaged\"\t813\r\n",
      "\"flank\"\t813\r\n",
      "\"grove\"\t812\r\n",
      "\"designate\"\t812\r\n",
      "\"furtherance\"\t812\r\n",
      "\"aunt\"\t812\r\n",
      "\"football\"\t812\r\n",
      "\"trait\"\t812\r\n",
      "\"reproducing\"\t812\r\n",
      "\"sober\"\t812\r\n",
      "\"saturation\"\t812\r\n",
      "\"translate\"\t810\r\n",
      "\"respectively\"\t810\r\n",
      "\"provisional\"\t810\r\n",
      "\"refractory\"\t810\r\n",
      "\"craft\"\t810\r\n",
      "\"aiding\"\t810\r\n",
      "\"cherished\"\t810\r\n",
      "\"inquiring\"\t809\r\n",
      "\"endued\"\t809\r\n",
      "\"imminent\"\t809\r\n",
      "\"stumbled\"\t809\r\n",
      "\"vile\"\t809\r\n",
      "\"pearl\"\t808\r\n",
      "\"entities\"\t808\r\n",
      "\"benign\"\t808\r\n",
      "\"afterward\"\t808\r\n",
      "\"industrializing\"\t808\r\n",
      "\"alienating\"\t808\r\n",
      "\"adhesive\"\t808\r\n",
      "\"admits\"\t807\r\n",
      "\"rainfall\"\t807\r\n",
      "\"plaintiff's\"\t807\r\n",
      "\"reigns\"\t807\r\n",
      "\"researcher\"\t807\r\n",
      "\"polish\"\t806\r\n",
      "\"underdeveloped\"\t806\r\n",
      "\"judicious\"\t806\r\n",
      "\"bacilli\"\t806\r\n",
      "\"adjourned\"\t805\r\n",
      "\"dilatation\"\t805\r\n",
      "\"sampling\"\t805\r\n",
      "\"pave\"\t805\r\n",
      "\"pretends\"\t805\r\n",
      "\"vestiges\"\t805\r\n",
      "\"tidings\"\t805\r\n",
      "\"terrorist\"\t805\r\n",
      "\"symbolism\"\t804\r\n",
      "\"terrace\"\t804\r\n",
      "\"rarity\"\t804\r\n",
      "\"unprecedented\"\t804\r\n",
      "\"paramount\"\t804\r\n",
      "\"grotesque\"\t804\r\n",
      "\"governance\"\t803\r\n",
      "\"elegant\"\t803\r\n",
      "\"coarse\"\t803\r\n",
      "\"franciscans\"\t803\r\n",
      "\"programmes\"\t803\r\n",
      "\"sings\"\t803\r\n",
      "\"uneasiness\"\t802\r\n",
      "\"listener\"\t802\r\n",
      "\"meals\"\t802\r\n",
      "\"polls\"\t802\r\n",
      "\"relegated\"\t802\r\n",
      "\"ingenuity\"\t802\r\n",
      "\"embarrassed\"\t801\r\n",
      "\"epsilon\"\t801\r\n",
      "\"automatic\"\t801\r\n",
      "\"privacy\"\t801\r\n",
      "\"sometime\"\t801\r\n",
      "\"vogue\"\t800\r\n",
      "\"lays\"\t800\r\n",
      "\"racism\"\t800\r\n",
      "\"perpetually\"\t800\r\n",
      "\"gracious\"\t800\r\n",
      "\"analyzing\"\t800\r\n",
      "\"drives\"\t800\r\n",
      "\"fortified\"\t799\r\n",
      "\"nominate\"\t799\r\n",
      "\"heal\"\t798\r\n",
      "\"invented\"\t798\r\n",
      "\"inspector\"\t797\r\n",
      "\"hesitation\"\t797\r\n",
      "\"pharynx\"\t797\r\n",
      "\"overtaken\"\t796\r\n",
      "\"deduced\"\t796\r\n",
      "\"expressive\"\t796\r\n",
      "\"compares\"\t796\r\n",
      "\"coverage\"\t796\r\n",
      "\"arabia\"\t796\r\n",
      "\"advertisement\"\t796\r\n",
      "\"encroached\"\t795\r\n",
      "\"lewis\"\t795\r\n",
      "\"socialists\"\t795\r\n",
      "\"reporter\"\t795\r\n",
      "\"vacant\"\t795\r\n",
      "\"rings\"\t794\r\n",
      "\"recueil\"\t794\r\n",
      "\"lois\"\t794\r\n",
      "\"answering\"\t794\r\n",
      "\"clues\"\t794\r\n",
      "\"fossil\"\t794\r\n",
      "\"funded\"\t794\r\n",
      "\"chill\"\t794\r\n",
      "\"anciennes\"\t794\r\n",
      "\"challenged\"\t794\r\n",
      "\"reinforce\"\t793\r\n",
      "\"tedious\"\t793\r\n",
      "\"papal\"\t793\r\n",
      "\"soweth\"\t792\r\n",
      "\"sterile\"\t792\r\n",
      "\"restrained\"\t792\r\n",
      "\"eventual\"\t792\r\n",
      "\"fibre\"\t792\r\n",
      "\"composer\"\t792\r\n",
      "\"hastened\"\t791\r\n",
      "\"blaze\"\t791\r\n",
      "\"configuration\"\t791\r\n",
      "\"danish\"\t791\r\n",
      "\"economists\"\t791\r\n",
      "\"virtuous\"\t791\r\n",
      "\"reflex\"\t791\r\n",
      "\"pepper\"\t791\r\n",
      "\"patrons\"\t790\r\n",
      "\"condolence\"\t790\r\n",
      "\"calculus\"\t790\r\n",
      "\"fugitives\"\t790\r\n",
      "\"chalk\"\t789\r\n",
      "\"israeli\"\t789\r\n",
      "\"abstraction\"\t789\r\n",
      "\"coolidge\"\t789\r\n",
      "\"executors\"\t789\r\n",
      "\"pilgrim\"\t789\r\n",
      "\"rearranged\"\t789\r\n",
      "\"platelet\"\t789\r\n",
      "\"silica\"\t789\r\n",
      "\"malaysian\"\t788\r\n",
      "\"crowned\"\t788\r\n",
      "\"emigration\"\t788\r\n",
      "\"envisaged\"\t787\r\n",
      "\"distinguishes\"\t787\r\n",
      "\"graceful\"\t787\r\n",
      "\"hoover\"\t787\r\n",
      "\"infinitesimal\"\t787\r\n",
      "\"velvet\"\t787\r\n",
      "\"stringent\"\t786\r\n",
      "\"rejoiced\"\t786\r\n",
      "\"notices\"\t786\r\n",
      "\"enlarge\"\t786\r\n",
      "\"cooperative\"\t786\r\n",
      "\"informing\"\t785\r\n",
      "\"complexes\"\t785\r\n",
      "\"hateful\"\t785\r\n",
      "\"clearness\"\t785\r\n",
      "\"experiencing\"\t785\r\n",
      "\"tightly\"\t785\r\n",
      "\"wolf\"\t785\r\n",
      "\"overhead\"\t785\r\n",
      "\"westerly\"\t784\r\n",
      "\"antagonistic\"\t784\r\n",
      "\"inhibition\"\t784\r\n",
      "\"destination\"\t784\r\n",
      "\"castles\"\t783\r\n",
      "\"damaging\"\t783\r\n",
      "\"anastomosis\"\t783\r\n",
      "\"negation\"\t783\r\n",
      "\"rationalism\"\t783\r\n",
      "\"supplications\"\t783\r\n",
      "\"tv\"\t782\r\n",
      "\"necks\"\t782\r\n",
      "\"defences\"\t782\r\n",
      "\"dexterity\"\t782\r\n",
      "\"grounded\"\t782\r\n",
      "\"iranian\"\t781\r\n",
      "\"allotted\"\t781\r\n",
      "\"downs\"\t781\r\n",
      "\"ram\"\t781\r\n",
      "\"preamble\"\t781\r\n",
      "\"vigour\"\t781\r\n",
      "\"nationalities\"\t781\r\n",
      "\"rupture\"\t780\r\n",
      "\"listens\"\t780\r\n",
      "\"rugged\"\t780\r\n",
      "\"transfers\"\t780\r\n",
      "\"desolate\"\t780\r\n",
      "\"campus\"\t780\r\n",
      "\"chorus\"\t780\r\n",
      "\"cherish\"\t780\r\n",
      "\"consul\"\t780\r\n",
      "\"excesses\"\t779\r\n",
      "\"eloquence\"\t779\r\n",
      "\"incentives\"\t779\r\n",
      "\"excel\"\t779\r\n",
      "\"crying\"\t779\r\n",
      "\"consented\"\t779\r\n",
      "\"adjunct\"\t779\r\n",
      "\"ratify\"\t779\r\n",
      "\"sovereigns\"\t779\r\n",
      "\"vastly\"\t779\r\n",
      "\"scraps\"\t778\r\n",
      "\"hepatic\"\t778\r\n",
      "\"cumulative\"\t778\r\n",
      "\"contradict\"\t777\r\n",
      "\"doubled\"\t777\r\n",
      "\"destroying\"\t777\r\n",
      "\"volcano\"\t777\r\n",
      "\"zur\"\t777\r\n",
      "\"sub\"\t776\r\n",
      "\"sorrows\"\t776\r\n",
      "\"literal\"\t776\r\n",
      "\"circumscribed\"\t776\r\n",
      "\"damp\"\t775\r\n",
      "\"cardiogenic\"\t775\r\n",
      "\"drops\"\t775\r\n",
      "\"determinations\"\t774\r\n",
      "\"abrupt\"\t774\r\n",
      "\"authorize\"\t774\r\n",
      "\"lighter\"\t774\r\n",
      "\"veneration\"\t774\r\n",
      "\"prospective\"\t774\r\n",
      "\"sentimental\"\t774\r\n",
      "\"ss\"\t773\r\n",
      "\"sunlight\"\t773\r\n",
      "\"faded\"\t773\r\n",
      "\"extinguished\"\t773\r\n",
      "\"infamous\"\t773\r\n",
      "\"drafts\"\t773\r\n",
      "\"disclosure\"\t773\r\n",
      "\"insulted\"\t773\r\n",
      "\"irrigation\"\t773\r\n",
      "\"induction\"\t773\r\n",
      "\"backbone\"\t773\r\n",
      "\"alienation\"\t773\r\n",
      "\"formulating\"\t772\r\n",
      "\"fifths\"\t772\r\n",
      "\"dean\"\t772\r\n",
      "\"resorted\"\t772\r\n",
      "\"revealing\"\t772\r\n",
      "\"presiding\"\t771\r\n",
      "\"peru\"\t771\r\n",
      "\"reservoir\"\t771\r\n",
      "\"comic\"\t771\r\n",
      "\"carbohydrate\"\t771\r\n",
      "\"extant\"\t771\r\n",
      "\"eloquent\"\t771\r\n",
      "\"empires\"\t771\r\n",
      "\"addicted\"\t771\r\n",
      "\"complimentary\"\t771\r\n",
      "\"imaging\"\t770\r\n",
      "\"civic\"\t770\r\n",
      "\"thirties\"\t770\r\n",
      "\"mushrooms\"\t770\r\n",
      "\"supporter\"\t770\r\n",
      "\"poorer\"\t769\r\n",
      "\"sustainable\"\t769\r\n",
      "\"speedily\"\t769\r\n",
      "\"gallant\"\t769\r\n",
      "\"divers\"\t768\r\n",
      "\"fin\"\t768\r\n",
      "\"com\"\t768\r\n",
      "\"doubling\"\t768\r\n",
      "\"angola\"\t768\r\n",
      "\"pernicious\"\t768\r\n",
      "\"lingering\"\t768\r\n",
      "\"overtake\"\t768\r\n",
      "\"ounce\"\t768\r\n",
      "\"galleys\"\t767\r\n",
      "\"inspire\"\t767\r\n",
      "\"apology\"\t767\r\n",
      "\"anomalies\"\t767\r\n",
      "\"judiciary\"\t767\r\n",
      "\"bankruptcy\"\t766\r\n",
      "\"thronged\"\t766\r\n",
      "\"perseverance\"\t765\r\n",
      "\"brother's\"\t765\r\n",
      "\"brook\"\t765\r\n",
      "\"huron\"\t764\r\n",
      "\"holiness\"\t763\r\n",
      "\"distention\"\t763\r\n",
      "\"directory\"\t763\r\n",
      "\"endurance\"\t763\r\n",
      "\"vertebra\"\t763\r\n",
      "\"stuart\"\t763\r\n",
      "\"reflecting\"\t763\r\n",
      "\"warrior\"\t763\r\n",
      "\"namely\"\t763\r\n",
      "\"vanished\"\t762\r\n",
      "\"profitably\"\t762\r\n",
      "\"roused\"\t762\r\n",
      "\"circumference\"\t762\r\n",
      "\"capricious\"\t762\r\n",
      "\"coronation\"\t762\r\n",
      "\"creativity\"\t762\r\n",
      "\"discontent\"\t762\r\n",
      "\"impatience\"\t761\r\n",
      "\"embody\"\t761\r\n",
      "\"bags\"\t761\r\n",
      "\"logically\"\t761\r\n",
      "\"underworld\"\t761\r\n",
      "\"visions\"\t761\r\n",
      "\"papua\"\t761\r\n",
      "\"pretense\"\t760\r\n",
      "\"oft\"\t760\r\n",
      "\"infallibility\"\t760\r\n",
      "\"cadillac\"\t760\r\n",
      "\"cunning\"\t760\r\n",
      "\"freud's\"\t759\r\n",
      "\"dominance\"\t759\r\n",
      "\"contaminated\"\t759\r\n",
      "\"eminence\"\t759\r\n",
      "\"trivial\"\t759\r\n",
      "\"strove\"\t759\r\n",
      "\"utilize\"\t759\r\n",
      "\"musket\"\t759\r\n",
      "\"penetrated\"\t758\r\n",
      "\"zippor\"\t758\r\n",
      "\"wrongs\"\t758\r\n",
      "\"specially\"\t758\r\n",
      "\"unpopular\"\t758\r\n",
      "\"balak\"\t758\r\n",
      "\"inaccessible\"\t758\r\n",
      "\"homologous\"\t757\r\n",
      "\"attracting\"\t757\r\n",
      "\"camps\"\t757\r\n",
      "\"babies\"\t757\r\n",
      "\"deliberations\"\t757\r\n",
      "\"mellitus\"\t757\r\n",
      "\"premier\"\t757\r\n",
      "\"notch\"\t756\r\n",
      "\"chromosome\"\t756\r\n",
      "\"disconcerted\"\t756\r\n",
      "\"judith\"\t756\r\n",
      "\"bleed\"\t756\r\n",
      "\"harnessed\"\t755\r\n",
      "\"reinforced\"\t755\r\n",
      "\"manifesto\"\t755\r\n",
      "\"sends\"\t755\r\n",
      "\"sculpture\"\t755\r\n",
      "\"tremble\"\t754\r\n",
      "\"weakening\"\t754\r\n",
      "\"monstrous\"\t754\r\n",
      "\"crane\"\t754\r\n",
      "\"fourier\"\t754\r\n",
      "\"den\"\t753\r\n",
      "\"conveying\"\t753\r\n",
      "\"albert\"\t753\r\n",
      "\"educating\"\t753\r\n",
      "\"basically\"\t752\r\n",
      "\"characterize\"\t752\r\n",
      "\"destitute\"\t752\r\n",
      "\"relics\"\t752\r\n",
      "\"quicker\"\t752\r\n",
      "\"tough\"\t752\r\n",
      "\"pangs\"\t752\r\n",
      "\"needy\"\t752\r\n",
      "\"lodging\"\t752\r\n",
      "\"upheld\"\t751\r\n",
      "\"perpetuate\"\t751\r\n",
      "\"rabbit\"\t751\r\n",
      "\"blockade\"\t751\r\n",
      "\"bridges\"\t750\r\n",
      "\"retina\"\t750\r\n",
      "\"sift\"\t750\r\n",
      "\"vienna\"\t749\r\n",
      "\"wandering\"\t749\r\n",
      "\"microscope\"\t749\r\n",
      "\"assemblies\"\t749\r\n",
      "\"incur\"\t749\r\n",
      "\"formative\"\t749\r\n",
      "\"standardization\"\t748\r\n",
      "\"traditionally\"\t748\r\n",
      "\"que\"\t748\r\n",
      "\"obstinate\"\t747\r\n",
      "\"widening\"\t747\r\n",
      "\"israelites\"\t747\r\n",
      "\"identifying\"\t747\r\n",
      "\"causally\"\t747\r\n",
      "\"distorted\"\t747\r\n",
      "\"grandchildren\"\t747\r\n",
      "\"conscientious\"\t746\r\n",
      "\"hygiene\"\t746\r\n",
      "\"monastic\"\t746\r\n",
      "\"qualify\"\t746\r\n",
      "\"railways\"\t746\r\n",
      "\"memorials\"\t746\r\n",
      "\"preclude\"\t745\r\n",
      "\"deliberately\"\t745\r\n",
      "\"individuality\"\t745\r\n",
      "\"birmingham\"\t745\r\n",
      "\"executrix\"\t745\r\n",
      "\"escaping\"\t744\r\n",
      "\"castro\"\t744\r\n",
      "\"frederick\"\t744\r\n",
      "\"absolve\"\t744\r\n",
      "\"diametrically\"\t744\r\n",
      "\"santo\"\t744\r\n",
      "\"token\"\t744\r\n",
      "\"tavern\"\t744\r\n",
      "\"offender\"\t744\r\n",
      "\"specification\"\t744\r\n",
      "\"topical\"\t744\r\n",
      "\"simon\"\t744\r\n",
      "\"longed\"\t743\r\n",
      "\"trick\"\t743\r\n",
      "\"terrors\"\t743\r\n",
      "\"baltimore\"\t743\r\n",
      "\"cyrus\"\t743\r\n",
      "\"insulation\"\t743\r\n",
      "\"brains\"\t743\r\n",
      "\"accomplishments\"\t742\r\n",
      "\"toe\"\t742\r\n",
      "\"speculated\"\t742\r\n",
      "\"sells\"\t742\r\n",
      "\"scots\"\t742\r\n",
      "\"throws\"\t741\r\n",
      "\"suorum\"\t741\r\n",
      "\"parium\"\t741\r\n",
      "\"surety\"\t741\r\n",
      "\"legale\"\t741\r\n",
      "\"recognizing\"\t741\r\n",
      "\"highlight\"\t741\r\n",
      "\"backgrounds\"\t741\r\n",
      "\"judicium\"\t741\r\n",
      "\"adrenaline\"\t740\r\n",
      "\"backing\"\t740\r\n",
      "\"edict\"\t740\r\n",
      "\"inducing\"\t740\r\n",
      "\"excluding\"\t739\r\n",
      "\"eleventh\"\t739\r\n",
      "\"heavier\"\t739\r\n",
      "\"fruition\"\t739\r\n",
      "\"hemodialysis\"\t739\r\n",
      "\"mohamad\"\t739\r\n",
      "\"mahathir\"\t739\r\n",
      "\"norway\"\t739\r\n",
      "\"rebuilt\"\t738\r\n",
      "\"soils\"\t738\r\n",
      "\"surrounds\"\t738\r\n",
      "\"dumb\"\t738\r\n",
      "\"invaders\"\t738\r\n",
      "\"delimitation\"\t738\r\n",
      "\"barons\"\t738\r\n",
      "\"deficient\"\t738\r\n",
      "\"clothe\"\t737\r\n",
      "\"decency\"\t737\r\n",
      "\"belligerents\"\t737\r\n",
      "\"dictionary\"\t737\r\n",
      "\"revenge\"\t737\r\n",
      "\"storming\"\t737\r\n",
      "\"silicon\"\t737\r\n",
      "\"upshot\"\t736\r\n",
      "\"shower\"\t736\r\n",
      "\"ventilation\"\t736\r\n",
      "\"mists\"\t736\r\n",
      "\"withdrawing\"\t736\r\n",
      "\"banker\"\t736\r\n",
      "\"honours\"\t736\r\n",
      "\"aspiration\"\t735\r\n",
      "\"inhibitors\"\t735\r\n",
      "\"apprehensive\"\t735\r\n",
      "\"fibrous\"\t735\r\n",
      "\"concur\"\t735\r\n",
      "\"abruptly\"\t735\r\n",
      "\"reciprocal\"\t735\r\n",
      "\"plead\"\t735\r\n",
      "\"spinning\"\t735\r\n",
      "\"vatican\"\t735\r\n",
      "\"tanzania\"\t734\r\n",
      "\"couched\"\t734\r\n",
      "\"declarations\"\t734\r\n",
      "\"hosts\"\t734\r\n",
      "\"aptitude\"\t733\r\n",
      "\"breaker\"\t733\r\n",
      "\"confederates\"\t733\r\n",
      "\"hull\"\t733\r\n",
      "\"toy\"\t733\r\n",
      "\"remembering\"\t732\r\n",
      "\"undisturbed\"\t732\r\n",
      "\"trifle\"\t732\r\n",
      "\"miraculous\"\t732\r\n",
      "\"coordination\"\t732\r\n",
      "\"affixed\"\t732\r\n",
      "\"conclusively\"\t732\r\n",
      "\"farming\"\t731\r\n",
      "\"humanly\"\t731\r\n",
      "\"elizabethan\"\t731\r\n",
      "\"adjustments\"\t731\r\n",
      "\"stanley\"\t731\r\n",
      "\"pre\"\t731\r\n",
      "\"rails\"\t731\r\n",
      "\"purport\"\t731\r\n",
      "\"scratch\"\t731\r\n",
      "\"mammals\"\t730\r\n",
      "\"who's\"\t730\r\n",
      "\"multitudes\"\t730\r\n",
      "\"florence\"\t730\r\n",
      "\"augmentation\"\t730\r\n",
      "\"indefinite\"\t729\r\n",
      "\"demon\"\t729\r\n",
      "\"mould\"\t729\r\n",
      "\"prussian\"\t729\r\n",
      "\"stove\"\t729\r\n",
      "\"simulation\"\t728\r\n",
      "\"subordinated\"\t728\r\n",
      "\"secretly\"\t728\r\n",
      "\"locate\"\t728\r\n",
      "\"glowing\"\t728\r\n",
      "\"insulin\"\t727\r\n",
      "\"chronology\"\t727\r\n",
      "\"cured\"\t727\r\n",
      "\"allocated\"\t727\r\n",
      "\"melt\"\t727\r\n",
      "\"singly\"\t727\r\n",
      "\"realism\"\t727\r\n",
      "\"pleaded\"\t727\r\n",
      "\"touches\"\t726\r\n",
      "\"numbered\"\t726\r\n",
      "\"organization's\"\t726\r\n",
      "\"glories\"\t726\r\n",
      "\"goat\"\t725\r\n",
      "\"fashioned\"\t725\r\n",
      "\"deference\"\t725\r\n",
      "\"hymns\"\t725\r\n",
      "\"steer\"\t725\r\n",
      "\"triple\"\t725\r\n",
      "\"spectator\"\t725\r\n",
      "\"reconstructed\"\t724\r\n",
      "\"twin\"\t724\r\n",
      "\"liberate\"\t724\r\n",
      "\"derogation\"\t724\r\n",
      "\"constituents\"\t724\r\n",
      "\"atmospheric\"\t724\r\n",
      "\"choir\"\t724\r\n",
      "\"interrupt\"\t723\r\n",
      "\"hawaiian\"\t723\r\n",
      "\"irregularity\"\t723\r\n",
      "\"fitness\"\t723\r\n",
      "\"costa\"\t723\r\n",
      "\"opponent\"\t723\r\n",
      "\"purest\"\t723\r\n",
      "\"needful\"\t723\r\n",
      "\"thrive\"\t722\r\n",
      "\"precipitation\"\t722\r\n",
      "\"shawl\"\t722\r\n",
      "\"calvin\"\t722\r\n",
      "\"beats\"\t722\r\n",
      "\"ac\"\t722\r\n",
      "\"conditioned\"\t722\r\n",
      "\"dispassionate\"\t722\r\n",
      "\"heroine\"\t722\r\n",
      "\"allude\"\t721\r\n",
      "\"articulate\"\t721\r\n",
      "\"variability\"\t721\r\n",
      "\"switzerland\"\t721\r\n",
      "\"temperance\"\t721\r\n",
      "\"shedding\"\t721\r\n",
      "\"tomography\"\t721\r\n",
      "\"lithium\"\t720\r\n",
      "\"suburb\"\t720\r\n",
      "\"sofa\"\t720\r\n",
      "\"framing\"\t720\r\n",
      "\"debilitating\"\t720\r\n",
      "\"anchored\"\t719\r\n",
      "\"chromosomes\"\t719\r\n",
      "\"neuropathy\"\t719\r\n",
      "\"wrists\"\t719\r\n",
      "\"thunder\"\t719\r\n",
      "\"lighting\"\t719\r\n",
      "\"politician\"\t718\r\n",
      "\"lap\"\t718\r\n",
      "\"roger\"\t718\r\n",
      "\"ischemia\"\t718\r\n",
      "\"butler\"\t717\r\n",
      "\"innovative\"\t717\r\n",
      "\"discriminated\"\t717\r\n",
      "\"manly\"\t717\r\n",
      "\"vigor\"\t717\r\n",
      "\"tranquillity\"\t717\r\n",
      "\"nuclei\"\t716\r\n",
      "\"washings\"\t716\r\n",
      "\"plague\"\t716\r\n",
      "\"wits\"\t716\r\n",
      "\"shouted\"\t716\r\n",
      "\"franklin\"\t716\r\n",
      "\"enumerated\"\t716\r\n",
      "\"controversies\"\t715\r\n",
      "\"bloom\"\t715\r\n",
      "\"heroism\"\t715\r\n",
      "\"enlightenment\"\t715\r\n",
      "\"gloomy\"\t715\r\n",
      "\"dentist\"\t715\r\n",
      "\"harmless\"\t715\r\n",
      "\"sanguine\"\t715\r\n",
      "\"kentucky\"\t715\r\n",
      "\"triangular\"\t715\r\n",
      "\"malawi\"\t714\r\n",
      "\"solemnly\"\t714\r\n",
      "\"heel\"\t714\r\n",
      "\"forgiveness\"\t714\r\n",
      "\"fixation\"\t714\r\n",
      "\"fist\"\t713\r\n",
      "\"episcopal\"\t713\r\n",
      "\"caudal\"\t713\r\n",
      "\"anarchy\"\t713\r\n",
      "\"appropriated\"\t713\r\n",
      "\"meridian\"\t713\r\n",
      "\"regulatory\"\t713\r\n",
      "\"ovum\"\t713\r\n",
      "\"prized\"\t713\r\n",
      "\"ontario\"\t712\r\n",
      "\"productivity\"\t712\r\n",
      "\"pushing\"\t712\r\n",
      "\"pamphlets\"\t712\r\n",
      "\"spy\"\t712\r\n",
      "\"html\"\t712\r\n",
      "\"inquired\"\t712\r\n",
      "\"cytoplasm\"\t712\r\n",
      "\"herbs\"\t712\r\n",
      "\"cancel\"\t712\r\n",
      "\"habitually\"\t711\r\n",
      "\"drafted\"\t711\r\n",
      "\"ethic\"\t711\r\n",
      "\"mock\"\t711\r\n",
      "\"supplier\"\t710\r\n",
      "\"tartar\"\t710\r\n",
      "\"indicted\"\t710\r\n",
      "\"fairer\"\t710\r\n",
      "\"hamilton\"\t710\r\n",
      "\"deducted\"\t709\r\n",
      "\"exporting\"\t709\r\n",
      "\"interpolation\"\t709\r\n",
      "\"hungary\"\t709\r\n",
      "\"crawl\"\t709\r\n",
      "\"robes\"\t709\r\n",
      "\"researches\"\t709\r\n",
      "\"processor\"\t709\r\n",
      "\"prerogative\"\t709\r\n",
      "\"streak\"\t709\r\n",
      "\"tyrant\"\t708\r\n",
      "\"probabilities\"\t708\r\n",
      "\"secessionist\"\t708\r\n",
      "\"historiography\"\t708\r\n",
      "\"gower\"\t708\r\n",
      "\"exalted\"\t708\r\n",
      "\"fills\"\t708\r\n",
      "\"emancipation\"\t708\r\n"
     ]
    }
   ],
   "source": [
    "!cat frequencies5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stripes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stripes5_5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stripes5_5.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import itertools\n",
    "import collections\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class stripes(MRJob):\n",
    "  \n",
    "    #START SUDENT CODE531_STRIPES\n",
    "  \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        self.valid_words = set()\n",
    "        super(stripes, self).__init__(args)\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        # Load the left table in the init so all mappers get this info\n",
    "        with open(\"frequencies5.5\", 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                x = line.strip().split(\"\\t\")\n",
    "                self.valid_words.add(x[0].strip(\"\\\"\"))\n",
    "            \n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "\n",
    "        words = splits[0].lower().split()\n",
    "        count = splits[1]\n",
    "\n",
    "        H = {}\n",
    "        for subset in itertools.combinations(sorted(set(words)), 2):\n",
    "            \n",
    "            if subset[0] in self.valid_words and subset[1] in self.valid_words:\n",
    "\n",
    "                # Process combinations in sorted order, i.e. \"hello\",\"tomorrow\"\n",
    "                if subset[0] not in H.keys():\n",
    "                    H[subset[0]] = {}\n",
    "                    H[subset[0]][subset[1]] = count \n",
    "                elif subset[1] not in H[subset[0]]:\n",
    "                    H[subset[0]][subset[1]] = count\n",
    "                else:\n",
    "                    H[subset[0]][subset[1]] += count\n",
    "\n",
    "                # Obtain combinations in reverse order, to consider them both ways\n",
    "                # TODO: Should refactor this and the block above, shameless copy-paste\n",
    "                if subset[1] not in H.keys():\n",
    "                    H[subset[1]] = {}\n",
    "                    H[subset[1]][subset[0]] = count \n",
    "                elif subset[0] not in H[subset[1]]:\n",
    "                    H[subset[1]][subset[0]] = count\n",
    "                else:\n",
    "                    H[subset[1]][subset[0]] += count\n",
    "        for key in H.keys():\n",
    "            #print \"%s\\t%s\" % (key, json.dumps(H[key]))\n",
    "            yield key, H[key]\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        \n",
    "        counter = {}\n",
    "\n",
    "        for value in values:\n",
    "            \n",
    "            for k, v in value.iteritems():\n",
    "                if k in counter:\n",
    "                    counter[k] += int(v)\n",
    "                else:\n",
    "                    counter[k] = int(v)\n",
    "        \n",
    "        yield key, counter\n",
    "\n",
    "  #END SUDENT CODE531_STRIPES\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    stripes.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `stripes5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/stripes5_5.root.20170616.223242.125605\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/stripes5_5.root.20170616.223242.125605/files/...\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob5118814237556475014.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0006\n",
      "  Submitted application application_1497651454196_0006\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0006/\n",
      "  Running job: job_1497651454196_0006\n",
      "  Job job_1497651454196_0006 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0006 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/stripes5_5.root.20170616.223242.125605/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=11448710\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3741\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=4617\n",
      "\t\tFILE: Number of bytes written=365729\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=11449108\n",
      "\t\tHDFS: Number of bytes written=3741\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=8843264\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2507776\n",
      "\t\tTotal time spent by all map tasks (ms)=8636\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=8636\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2449\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2449\n",
      "\t\tTotal vcore-seconds taken by all map tasks=8636\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2449\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1610\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=91\n",
      "\t\tInput split bytes=398\n",
      "\t\tMap input records=311614\n",
      "\t\tMap output bytes=4341\n",
      "\t\tMap output materialized bytes=4623\n",
      "\t\tMap output records=135\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=804491264\n",
      "\t\tReduce input groups=135\n",
      "\t\tReduce input records=135\n",
      "\t\tReduce output records=123\n",
      "\t\tReduce shuffle bytes=4623\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=270\n",
      "\t\tTotal committed heap usage (bytes)=907542528\n",
      "\t\tVirtual memory (bytes) snapshot=4107857920\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/stripes5_5.root.20170616.223242.125605/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/stripes5_5.root.20170616.223242.125605...\n",
      "Removing temp directory /tmp/stripes5_5.root.20170616.223242.125605...\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"accepts\"\t{\"embody\": 382}\r\n",
      "\"adjustments\"\t{\"placement\": 46}\r\n",
      "\"albert\"\t{\"lee\": 57}\r\n",
      "\"anastomosis\"\t{\"donor\": 52}\r\n",
      "\"anciennes\"\t{\"recueil\": 794, \"lois\": 794}\r\n",
      "\"anti\"\t{\"goat\": 72}\r\n",
      "\"arrives\"\t{\"pilgrim\": 321}\r\n",
      "\"atmospheric\"\t{\"fixation\": 313}\r\n",
      "\"au\"\t{\"vie\": 272}\r\n",
      "\"aunt\"\t{\"maria\": 43}\r\n",
      "\"automatic\"\t{\"ventilation\": 411}\r\n",
      "\"balak\"\t{\"zippor\": 758}\r\n",
      "\"brook\"\t{\"rugged\": 95}\r\n",
      "\"brother's\"\t{\"vacant\": 46}\r\n",
      "\"calculus\"\t{\"probabilities\": 115, \"infinitesimal\": 412}\r\n",
      "\"calvin\"\t{\"hoover\": 680, \"coolidge\": 680}\r\n",
      "\"cancel\"\t{\"ok\": 589}\r\n",
      "\"cannon\"\t{\"thunder\": 80}\r\n",
      "\"cardinals\"\t{\"seizing\": 43}\r\n",
      "\"caudal\"\t{\"fin\": 60}\r\n",
      "\"chromosome\"\t{\"chromosomes\": 44}\r\n",
      "\"chromosomes\"\t{\"chromosome\": 44}\r\n",
      "\"clusters\"\t{\"creativity\": 63}\r\n",
      "\"compliment\"\t{\"graceful\": 44, \"relish\": 44}\r\n",
      "\"conditioned\"\t{\"inhibition\": 70}\r\n",
      "\"constrained\"\t{\"gentry\": 40}\r\n",
      "\"coolidge\"\t{\"hoover\": 680, \"calvin\": 680}\r\n",
      "\"crane\"\t{\"necks\": 67}\r\n",
      "\"crawl\"\t{\"strove\": 56}\r\n",
      "\"creativity\"\t{\"clusters\": 63, \"ingenuity\": 229}\r\n",
      "\"cyrus\"\t{\"edict\": 67}\r\n",
      "\"desolate\"\t{\"wandering\": 73}\r\n",
      "\"distilled\"\t{\"sterile\": 170}\r\n",
      "\"donor\"\t{\"anastomosis\": 52}\r\n",
      "\"edict\"\t{\"preamble\": 53, \"cyrus\": 67}\r\n",
      "\"embody\"\t{\"accepts\": 382}\r\n",
      "\"englishmen\"\t{\"subjection\": 52}\r\n",
      "\"epsilon\"\t{\"sigma\": 801}\r\n",
      "\"erie\"\t{\"huron\": 93}\r\n",
      "\"excel\"\t{\"virtuous\": 225}\r\n",
      "\"falsehood\"\t{\"needful\": 74, \"vanished\": 127, \"mock\": 248}\r\n",
      "\"fin\"\t{\"caudal\": 60}\r\n",
      "\"fixation\"\t{\"atmospheric\": 313}\r\n",
      "\"gentry\"\t{\"constrained\": 40}\r\n",
      "\"goat\"\t{\"anti\": 72}\r\n",
      "\"graceful\"\t{\"compliment\": 44}\r\n",
      "\"grotesque\"\t{\"visions\": 149}\r\n",
      "\"heavier\"\t{\"rails\": 67}\r\n",
      "\"hepatic\"\t{\"inducing\": 115}\r\n",
      "\"hoover\"\t{\"coolidge\": 680, \"calvin\": 680}\r\n",
      "\"huron\"\t{\"erie\": 93}\r\n",
      "\"incentives\"\t{\"manipulation\": 49}\r\n",
      "\"inducing\"\t{\"hepatic\": 115}\r\n",
      "\"infinitesimal\"\t{\"calculus\": 412}\r\n",
      "\"ingenuity\"\t{\"creativity\": 229}\r\n",
      "\"inhibition\"\t{\"serotonin\": 53, \"conditioned\": 70}\r\n",
      "\"inhibitors\"\t{\"serotonin\": 580}\r\n",
      "\"inspector\"\t{\"sanitary\": 46}\r\n",
      "\"insulted\"\t{\"mock\": 60}\r\n",
      "\"intolerable\"\t{\"pangs\": 44}\r\n",
      "\"invaders\"\t{\"vigour\": 53}\r\n",
      "\"judicium\"\t{\"legale\": 741, \"parium\": 741, \"suorum\": 741}\r\n",
      "\"korean\"\t{\"unification\": 74}\r\n",
      "\"lee\"\t{\"albert\": 57}\r\n",
      "\"legale\"\t{\"parium\": 741, \"judicium\": 741, \"suorum\": 741}\r\n",
      "\"lois\"\t{\"recueil\": 794, \"anciennes\": 794}\r\n",
      "\"mahathir\"\t{\"mohamad\": 739, \"malaysian\": 739}\r\n",
      "\"malaysian\"\t{\"mahathir\": 739, \"mohamad\": 739}\r\n",
      "\"manipulation\"\t{\"incentives\": 49}\r\n",
      "\"maria\"\t{\"aunt\": 43}\r\n",
      "\"mock\"\t{\"falsehood\": 248, \"insulted\": 60}\r\n",
      "\"mohamad\"\t{\"mahathir\": 739, \"malaysian\": 739}\r\n",
      "\"monastic\"\t{\"vestiges\": 76}\r\n",
      "\"necks\"\t{\"crane\": 67}\r\n",
      "\"needful\"\t{\"falsehood\": 74}\r\n",
      "\"norfolk\"\t{\"presiding\": 57}\r\n",
      "\"ok\"\t{\"cancel\": 589}\r\n",
      "\"pangs\"\t{\"intolerable\": 44, \"parting\": 111}\r\n",
      "\"parium\"\t{\"legale\": 741, \"judicium\": 741, \"suorum\": 741}\r\n",
      "\"parting\"\t{\"pangs\": 111}\r\n",
      "\"pearl\"\t{\"sells\": 42}\r\n",
      "\"pernicious\"\t{\"tyrant\": 81}\r\n",
      "\"pilgrim\"\t{\"arrives\": 321}\r\n",
      "\"placement\"\t{\"adjustments\": 46}\r\n",
      "\"preamble\"\t{\"edict\": 53}\r\n",
      "\"presiding\"\t{\"norfolk\": 57}\r\n",
      "\"probabilities\"\t{\"calculus\": 115}\r\n",
      "\"prospective\"\t{\"seizure\": 66}\r\n",
      "\"que\"\t{\"se\": 56}\r\n",
      "\"rails\"\t{\"heavier\": 67}\r\n",
      "\"recueil\"\t{\"lois\": 794, \"anciennes\": 794}\r\n",
      "\"reinforcement\"\t{\"speedily\": 62}\r\n",
      "\"relish\"\t{\"compliment\": 44}\r\n",
      "\"rugged\"\t{\"brook\": 95}\r\n",
      "\"sanitary\"\t{\"inspector\": 46}\r\n",
      "\"scared\"\t{\"who's\": 60}\r\n",
      "\"se\"\t{\"que\": 56}\r\n",
      "\"seizing\"\t{\"cardinals\": 43}\r\n",
      "\"seizure\"\t{\"prospective\": 66}\r\n",
      "\"sells\"\t{\"pearl\": 42}\r\n",
      "\"serotonin\"\t{\"inhibition\": 53, \"inhibitors\": 580}\r\n",
      "\"sigma\"\t{\"epsilon\": 801}\r\n",
      "\"speedily\"\t{\"reinforcement\": 62}\r\n",
      "\"sterile\"\t{\"distilled\": 170}\r\n",
      "\"strand\"\t{\"triple\": 117}\r\n",
      "\"strove\"\t{\"crawl\": 56}\r\n",
      "\"subjection\"\t{\"englishmen\": 52}\r\n",
      "\"suorum\"\t{\"legale\": 741, \"judicium\": 741, \"parium\": 741}\r\n",
      "\"thunder\"\t{\"cannon\": 80}\r\n",
      "\"triple\"\t{\"strand\": 117}\r\n",
      "\"tyrant\"\t{\"pernicious\": 81}\r\n",
      "\"unification\"\t{\"korean\": 74}\r\n",
      "\"vacant\"\t{\"brother's\": 46}\r\n",
      "\"vanished\"\t{\"falsehood\": 127}\r\n",
      "\"ventilation\"\t{\"automatic\": 411}\r\n",
      "\"vestiges\"\t{\"monastic\": 76}\r\n",
      "\"vie\"\t{\"au\": 272}\r\n",
      "\"vigour\"\t{\"invaders\": 53}\r\n",
      "\"virtuous\"\t{\"excel\": 225}\r\n",
      "\"visions\"\t{\"grotesque\": 149}\r\n",
      "\"wandering\"\t{\"desolate\": 73}\r\n",
      "\"who's\"\t{\"scared\": 60}\r\n",
      "\"zippor\"\t{\"balak\": 758}\r\n"
     ]
    }
   ],
   "source": [
    "!cat stripes5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting index5_5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile index5_5.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class index(MRJob):\n",
    "    \n",
    "    #START SUDENT CODE531_INV_INDEX\n",
    "  \n",
    "    def mapper(self, _, line):\n",
    "        key, stripeJson = line.strip().split('\\t')\n",
    "        key = key.strip(\"\\\"\")\n",
    "        stripe = json.loads(stripeJson)\n",
    "        \n",
    "        for k, v in stripe.iteritems():\n",
    "            yield k, [key, len(stripe)]\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "\n",
    "        table = {}\n",
    "        for value in values:\n",
    "            table[value[0]] = value[1]\n",
    "            \n",
    "        yield key, table\n",
    "        \n",
    "    #END SUDENT CODE531_INV_INDEX\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    index.run() \n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `index5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/index5_5.root.20170616.223655.035482\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/index5_5.root.20170616.223655.035482/files/...\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob2385366140107570970.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0008\n",
      "  Submitted application application_1497651454196_0008\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0008/\n",
      "  Running job: job_1497651454196_0008\n",
      "  Job job_1497651454196_0008 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0008 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/index5_5.root.20170616.223655.035482/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=5612\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3521\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=4130\n",
      "\t\tFILE: Number of bytes written=361785\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=5926\n",
      "\t\tHDFS: Number of bytes written=3521\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=6293504\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2485248\n",
      "\t\tTotal time spent by all map tasks (ms)=6146\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=6146\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2427\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2427\n",
      "\t\tTotal vcore-seconds taken by all map tasks=6146\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2427\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1140\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=56\n",
      "\t\tInput split bytes=314\n",
      "\t\tMap input records=123\n",
      "\t\tMap output bytes=3824\n",
      "\t\tMap output materialized bytes=4136\n",
      "\t\tMap output records=150\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=735563776\n",
      "\t\tReduce input groups=123\n",
      "\t\tReduce input records=150\n",
      "\t\tReduce output records=123\n",
      "\t\tReduce shuffle bytes=4136\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=300\n",
      "\t\tTotal committed heap usage (bytes)=750780416\n",
      "\t\tVirtual memory (bytes) snapshot=4077588480\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/index5_5.root.20170616.223655.035482/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/index5_5.root.20170616.223655.035482...\n",
      "Removing temp directory /tmp/index5_5.root.20170616.223655.035482...\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"accepts\"\t{\"embody\": 1}\r\n",
      "\"adjustments\"\t{\"placement\": 1}\r\n",
      "\"albert\"\t{\"lee\": 1}\r\n",
      "\"anastomosis\"\t{\"donor\": 1}\r\n",
      "\"anciennes\"\t{\"recueil\": 2, \"lois\": 2}\r\n",
      "\"anti\"\t{\"goat\": 1}\r\n",
      "\"arrives\"\t{\"pilgrim\": 1}\r\n",
      "\"atmospheric\"\t{\"fixation\": 1}\r\n",
      "\"au\"\t{\"vie\": 1}\r\n",
      "\"aunt\"\t{\"maria\": 1}\r\n",
      "\"automatic\"\t{\"ventilation\": 1}\r\n",
      "\"balak\"\t{\"zippor\": 1}\r\n",
      "\"brook\"\t{\"rugged\": 1}\r\n",
      "\"brother's\"\t{\"vacant\": 1}\r\n",
      "\"calculus\"\t{\"probabilities\": 1, \"infinitesimal\": 1}\r\n",
      "\"calvin\"\t{\"hoover\": 2, \"coolidge\": 2}\r\n",
      "\"cancel\"\t{\"ok\": 1}\r\n",
      "\"cannon\"\t{\"thunder\": 1}\r\n",
      "\"cardinals\"\t{\"seizing\": 1}\r\n",
      "\"caudal\"\t{\"fin\": 1}\r\n",
      "\"chromosome\"\t{\"chromosomes\": 1}\r\n",
      "\"chromosomes\"\t{\"chromosome\": 1}\r\n",
      "\"clusters\"\t{\"creativity\": 2}\r\n",
      "\"compliment\"\t{\"graceful\": 1, \"relish\": 1}\r\n",
      "\"conditioned\"\t{\"inhibition\": 2}\r\n",
      "\"constrained\"\t{\"gentry\": 1}\r\n",
      "\"coolidge\"\t{\"hoover\": 2, \"calvin\": 2}\r\n",
      "\"crane\"\t{\"necks\": 1}\r\n",
      "\"crawl\"\t{\"strove\": 1}\r\n",
      "\"creativity\"\t{\"clusters\": 1, \"ingenuity\": 1}\r\n",
      "\"cyrus\"\t{\"edict\": 2}\r\n",
      "\"desolate\"\t{\"wandering\": 1}\r\n",
      "\"distilled\"\t{\"sterile\": 1}\r\n",
      "\"donor\"\t{\"anastomosis\": 1}\r\n",
      "\"edict\"\t{\"preamble\": 1, \"cyrus\": 1}\r\n",
      "\"embody\"\t{\"accepts\": 1}\r\n",
      "\"englishmen\"\t{\"subjection\": 1}\r\n",
      "\"epsilon\"\t{\"sigma\": 1}\r\n",
      "\"erie\"\t{\"huron\": 1}\r\n",
      "\"excel\"\t{\"virtuous\": 1}\r\n",
      "\"falsehood\"\t{\"vanished\": 1, \"needful\": 1, \"mock\": 2}\r\n",
      "\"fin\"\t{\"caudal\": 1}\r\n",
      "\"fixation\"\t{\"atmospheric\": 1}\r\n",
      "\"gentry\"\t{\"constrained\": 1}\r\n",
      "\"goat\"\t{\"anti\": 1}\r\n",
      "\"graceful\"\t{\"compliment\": 2}\r\n",
      "\"grotesque\"\t{\"visions\": 1}\r\n",
      "\"heavier\"\t{\"rails\": 1}\r\n",
      "\"hepatic\"\t{\"inducing\": 1}\r\n",
      "\"hoover\"\t{\"coolidge\": 2, \"calvin\": 2}\r\n",
      "\"huron\"\t{\"erie\": 1}\r\n",
      "\"incentives\"\t{\"manipulation\": 1}\r\n",
      "\"inducing\"\t{\"hepatic\": 1}\r\n",
      "\"infinitesimal\"\t{\"calculus\": 2}\r\n",
      "\"ingenuity\"\t{\"creativity\": 2}\r\n",
      "\"inhibition\"\t{\"serotonin\": 2, \"conditioned\": 1}\r\n",
      "\"inhibitors\"\t{\"serotonin\": 2}\r\n",
      "\"inspector\"\t{\"sanitary\": 1}\r\n",
      "\"insulted\"\t{\"mock\": 2}\r\n",
      "\"intolerable\"\t{\"pangs\": 2}\r\n",
      "\"invaders\"\t{\"vigour\": 1}\r\n",
      "\"judicium\"\t{\"legale\": 3, \"parium\": 3, \"suorum\": 3}\r\n",
      "\"korean\"\t{\"unification\": 1}\r\n",
      "\"lee\"\t{\"albert\": 1}\r\n",
      "\"legale\"\t{\"parium\": 3, \"judicium\": 3, \"suorum\": 3}\r\n",
      "\"lois\"\t{\"recueil\": 2, \"anciennes\": 2}\r\n",
      "\"mahathir\"\t{\"mohamad\": 2, \"malaysian\": 2}\r\n",
      "\"malaysian\"\t{\"mahathir\": 2, \"mohamad\": 2}\r\n",
      "\"manipulation\"\t{\"incentives\": 1}\r\n",
      "\"maria\"\t{\"aunt\": 1}\r\n",
      "\"mock\"\t{\"falsehood\": 3, \"insulted\": 1}\r\n",
      "\"mohamad\"\t{\"mahathir\": 2, \"malaysian\": 2}\r\n",
      "\"monastic\"\t{\"vestiges\": 1}\r\n",
      "\"necks\"\t{\"crane\": 1}\r\n",
      "\"needful\"\t{\"falsehood\": 3}\r\n",
      "\"norfolk\"\t{\"presiding\": 1}\r\n",
      "\"ok\"\t{\"cancel\": 1}\r\n",
      "\"pangs\"\t{\"intolerable\": 1, \"parting\": 1}\r\n",
      "\"parium\"\t{\"legale\": 3, \"judicium\": 3, \"suorum\": 3}\r\n",
      "\"parting\"\t{\"pangs\": 2}\r\n",
      "\"pearl\"\t{\"sells\": 1}\r\n",
      "\"pernicious\"\t{\"tyrant\": 1}\r\n",
      "\"pilgrim\"\t{\"arrives\": 1}\r\n",
      "\"placement\"\t{\"adjustments\": 1}\r\n",
      "\"preamble\"\t{\"edict\": 2}\r\n",
      "\"presiding\"\t{\"norfolk\": 1}\r\n",
      "\"probabilities\"\t{\"calculus\": 2}\r\n",
      "\"prospective\"\t{\"seizure\": 1}\r\n",
      "\"que\"\t{\"se\": 1}\r\n",
      "\"rails\"\t{\"heavier\": 1}\r\n",
      "\"recueil\"\t{\"lois\": 2, \"anciennes\": 2}\r\n",
      "\"reinforcement\"\t{\"speedily\": 1}\r\n",
      "\"relish\"\t{\"compliment\": 2}\r\n",
      "\"rugged\"\t{\"brook\": 1}\r\n",
      "\"sanitary\"\t{\"inspector\": 1}\r\n",
      "\"scared\"\t{\"who's\": 1}\r\n",
      "\"se\"\t{\"que\": 1}\r\n",
      "\"seizing\"\t{\"cardinals\": 1}\r\n",
      "\"seizure\"\t{\"prospective\": 1}\r\n",
      "\"sells\"\t{\"pearl\": 1}\r\n",
      "\"serotonin\"\t{\"inhibition\": 2, \"inhibitors\": 1}\r\n",
      "\"sigma\"\t{\"epsilon\": 1}\r\n",
      "\"speedily\"\t{\"reinforcement\": 1}\r\n",
      "\"sterile\"\t{\"distilled\": 1}\r\n",
      "\"strand\"\t{\"triple\": 1}\r\n",
      "\"strove\"\t{\"crawl\": 1}\r\n",
      "\"subjection\"\t{\"englishmen\": 1}\r\n",
      "\"suorum\"\t{\"parium\": 3, \"judicium\": 3, \"legale\": 3}\r\n",
      "\"thunder\"\t{\"cannon\": 1}\r\n",
      "\"triple\"\t{\"strand\": 1}\r\n",
      "\"tyrant\"\t{\"pernicious\": 1}\r\n",
      "\"unification\"\t{\"korean\": 1}\r\n",
      "\"vacant\"\t{\"brother's\": 1}\r\n",
      "\"vanished\"\t{\"falsehood\": 3}\r\n",
      "\"ventilation\"\t{\"automatic\": 1}\r\n",
      "\"vestiges\"\t{\"monastic\": 1}\r\n",
      "\"vie\"\t{\"au\": 1}\r\n",
      "\"vigour\"\t{\"invaders\": 1}\r\n",
      "\"virtuous\"\t{\"excel\": 1}\r\n",
      "\"visions\"\t{\"grotesque\": 1}\r\n",
      "\"wandering\"\t{\"desolate\": 1}\r\n",
      "\"who's\"\t{\"scared\": 1}\r\n",
      "\"zippor\"\t{\"balak\": 1}\r\n"
     ]
    }
   ],
   "source": [
    "!cat index5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting similarity5_5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile similarity5_5.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "#import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class similarity(MRJob):\n",
    "  \n",
    "    #START SUDENT CODE531_SIMILARITY\n",
    "\n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        key, valuesJson = line.strip().split('\\t')\n",
    "        key = key.strip(\"\\\"\")\n",
    "        values = json.loads(valuesJson)\n",
    "\n",
    "        for pair in itertools.combinations(sorted(set(values)), 2):\n",
    "            yield pair, [values[pair[0]], values[pair[1]]]\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        intersection = 0\n",
    "        count1 = None\n",
    "        count2 = None\n",
    "        \n",
    "        cosine = 0.0\n",
    "        \n",
    "        # Iterate through the values\n",
    "        for value in values:\n",
    "            # Jaccard, get counts for the intersection, and for each set\n",
    "            intersection += 1\n",
    "            if count1 == None:\n",
    "                count1 = value[0]\n",
    "                count2 = value[1]\n",
    "        \n",
    "            # Cosine\n",
    "            a = 1 / math.sqrt(value[0])\n",
    "            b = 1 / math.sqrt(value[1])\n",
    "            cosine += a * b\n",
    "            \n",
    "        jaccard = float(intersection) / float(count1 + count2 - intersection)\n",
    "        \n",
    "        overlap_coefficient = float(intersection) / min(count1, count2)\n",
    "        \n",
    "        dice_coefficient = float(2 * intersection) / (count1 + count2)\n",
    "        \n",
    "        average = (cosine + jaccard + overlap_coefficient + dice_coefficient) / 4.0\n",
    "        \n",
    "        yield average, [key[0] + ' - ' + key[1], cosine, jaccard, overlap_coefficient, dice_coefficient, average]\n",
    "    \n",
    "    \n",
    "    def max_reducer(self, average, records):\n",
    "        for record in records:\n",
    "            yield average, record\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'2',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1,1nr',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(mapper=self.mapper,\n",
    "                    reducer=self.reducer),\n",
    "                MRStep(jobconf=custom_jobconf,\n",
    "                       reducer=self.max_reducer)\n",
    "                 ]\n",
    "    \n",
    "    #END SUDENT CODE531_SIMILARITY\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    similarity.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `similarity5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/similarity5_5.root.20170616.225146.757743\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/similarity5_5.root.20170616.225146.757743/files/...\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob4594933984191735185.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0015\n",
      "  Submitted application application_1497651454196_0015\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0015/\n",
      "  Running job: job_1497651454196_0015\n",
      "  Job job_1497651454196_0015 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0015 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/similarity5_5.root.20170616.225146.757743/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=5282\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2549\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1081\n",
      "\t\tFILE: Number of bytes written=357388\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=5602\n",
      "\t\tHDFS: Number of bytes written=2549\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=6223872\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2456576\n",
      "\t\tTotal time spent by all map tasks (ms)=6078\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=6078\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2399\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2399\n",
      "\t\tTotal vcore-seconds taken by all map tasks=6078\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2399\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1150\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=69\n",
      "\t\tInput split bytes=320\n",
      "\t\tMap input records=123\n",
      "\t\tMap output bytes=1011\n",
      "\t\tMap output materialized bytes=1087\n",
      "\t\tMap output records=32\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=732094464\n",
      "\t\tReduce input groups=26\n",
      "\t\tReduce input records=32\n",
      "\t\tReduce output records=26\n",
      "\t\tReduce shuffle bytes=1087\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=64\n",
      "\t\tTotal committed heap usage (bytes)=794296320\n",
      "\t\tVirtual memory (bytes) snapshot=4099485696\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  mapred.output.key.comparator.class is deprecated. Instead, use mapreduce.job.output.key.comparator.class\n",
      "  mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "  mapred.text.key.comparator.options is deprecated. Instead, use mapreduce.partition.keycomparator.options\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob6104676176069256590.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0016\n",
      "  Submitted application application_1497651454196_0016\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0016/\n",
      "  Running job: job_1497651454196_0016\n",
      "  Job job_1497651454196_0016 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0016 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/similarity5_5.root.20170616.225146.757743/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3824\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2549\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2633\n",
      "\t\tFILE: Number of bytes written=361332\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4170\n",
      "\t\tHDFS: Number of bytes written=2549\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=6389760\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2485248\n",
      "\t\tTotal time spent by all map tasks (ms)=6240\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=6240\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2427\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2427\n",
      "\t\tTotal vcore-seconds taken by all map tasks=6240\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2427\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1160\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=44\n",
      "\t\tInput split bytes=346\n",
      "\t\tMap input records=26\n",
      "\t\tMap output bytes=2575\n",
      "\t\tMap output materialized bytes=2639\n",
      "\t\tMap output records=26\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=785276928\n",
      "\t\tReduce input groups=26\n",
      "\t\tReduce input records=26\n",
      "\t\tReduce output records=26\n",
      "\t\tReduce shuffle bytes=2639\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=52\n",
      "\t\tTotal committed heap usage (bytes)=756547584\n",
      "\t\tVirtual memory (bytes) snapshot=4079706112\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/similarity5_5.root.20170616.225146.757743/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/similarity5_5.root.20170616.225146.757743...\n",
      "Removing temp directory /tmp/similarity5_5.root.20170616.225146.757743...\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\t[\"needful - vanished\", 1.0, 1.0, 1.0, 1.0, 1.0]\r\n",
      "1.0\t[\"clusters - ingenuity\", 1.0, 1.0, 1.0, 1.0, 1.0]\r\n",
      "1.0\t[\"intolerable - parting\", 1.0, 1.0, 1.0, 1.0, 1.0]\r\n",
      "1.0\t[\"infinitesimal - probabilities\", 1.0, 1.0, 1.0, 1.0, 1.0]\r\n",
      "1.0\t[\"graceful - relish\", 1.0, 1.0, 1.0, 1.0, 1.0]\r\n",
      "1.0\t[\"cyrus - preamble\", 1.0, 1.0, 1.0, 1.0, 1.0]\r\n",
      "0.7184433619633035\t[\"inhibition - inhibitors\", 0.70710678118654746, 0.5, 1.0, 0.66666666666666663, 0.7184433619633035]\r\n",
      "0.7184433619633035\t[\"conditioned - serotonin\", 0.70710678118654746, 0.5, 1.0, 0.66666666666666663, 0.7184433619633035]\r\n",
      "0.7184433619633035\t[\"mock - vanished\", 0.70710678118654746, 0.5, 1.0, 0.66666666666666663, 0.7184433619633035]\r\n",
      "0.7184433619633035\t[\"mock - needful\", 0.70710678118654746, 0.5, 1.0, 0.66666666666666663, 0.7184433619633035]\r\n",
      "0.625\t[\"parium - suorum\", 0.66666666666666685, 0.5, 0.66666666666666663, 0.66666666666666663, 0.625]\r\n",
      "0.625\t[\"legale - suorum\", 0.66666666666666685, 0.5, 0.66666666666666663, 0.66666666666666663, 0.625]\r\n",
      "0.625\t[\"legale - parium\", 0.66666666666666685, 0.5, 0.66666666666666663, 0.66666666666666663, 0.625]\r\n",
      "0.625\t[\"judicium - suorum\", 0.66666666666666685, 0.5, 0.66666666666666663, 0.66666666666666663, 0.625]\r\n",
      "0.625\t[\"judicium - parium\", 0.66666666666666685, 0.5, 0.66666666666666663, 0.66666666666666663, 0.625]\r\n",
      "0.625\t[\"judicium - legale\", 0.66666666666666685, 0.5, 0.66666666666666663, 0.66666666666666663, 0.625]\r\n",
      "0.6026709006307398\t[\"falsehood - insulted\", 0.57735026918962584, 0.33333333333333331, 1.0, 0.5, 0.6026709006307398]\r\n",
      "0.45833333333333331\t[\"coolidge - hoover\", 0.49999999999999989, 0.33333333333333331, 0.5, 0.5, 0.45833333333333331]\r\n",
      "0.45833333333333331\t[\"calvin - hoover\", 0.49999999999999989, 0.33333333333333331, 0.5, 0.5, 0.45833333333333331]\r\n",
      "0.45833333333333331\t[\"calvin - coolidge\", 0.49999999999999989, 0.33333333333333331, 0.5, 0.5, 0.45833333333333331]\r\n",
      "0.45833333333333331\t[\"anciennes - recueil\", 0.49999999999999989, 0.33333333333333331, 0.5, 0.5, 0.45833333333333331]\r\n",
      "0.45833333333333331\t[\"anciennes - lois\", 0.49999999999999989, 0.33333333333333331, 0.5, 0.5, 0.45833333333333331]\r\n",
      "0.45833333333333331\t[\"malaysian - mohamad\", 0.49999999999999989, 0.33333333333333331, 0.5, 0.5, 0.45833333333333331]\r\n",
      "0.45833333333333331\t[\"mahathir - mohamad\", 0.49999999999999989, 0.33333333333333331, 0.5, 0.5, 0.45833333333333331]\r\n",
      "0.45833333333333331\t[\"mahathir - malaysian\", 0.49999999999999989, 0.33333333333333331, 0.5, 0.5, 0.45833333333333331]\r\n",
      "0.45833333333333331\t[\"lois - recueil\", 0.49999999999999989, 0.33333333333333331, 0.5, 0.5, 0.45833333333333331]\r\n"
     ]
    }
   ],
   "source": [
    "!cat similarity5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> l\n",
      "\n",
      "Packages:\n",
      "  [ ] abc................. Australian Broadcasting Commission 2006\n",
      "  [ ] alpino.............. Alpino Dutch Treebank\n",
      "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
      "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
      "  [ ] basque_grammars..... Grammars for Basque\n",
      "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
      "                           Extraction Systems in Biology)\n",
      "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
      "  [ ] book_grammars....... Grammars from NLTK Book\n",
      "  [ ] brown............... Brown Corpus\n",
      "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
      "  [ ] cess_cat............ CESS-CAT Treebank\n",
      "  [ ] cess_esp............ CESS-ESP Treebank\n",
      "  [ ] chat80.............. Chat-80 Data Files\n",
      "  [ ] city_database....... City Database\n",
      "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
      "  [ ] comparative_sentences Comparative Sentence Dataset\n",
      "  [ ] comtrans............ ComTrans Corpus Sample\n",
      "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
      "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
      "Hit Enter to continue: \n",
      "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
      "                           and Basque Subset)\n",
      "  [ ] crubadan............ Crubadan Corpus\n",
      "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
      "  [ ] dolch............... Dolch Word List\n",
      "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
      "                           Corpus\n",
      "  [ ] floresta............ Portuguese Treebank\n",
      "  [ ] framenet_v15........ FrameNet 1.5\n",
      "  [ ] framenet_v17........ FrameNet 1.7\n",
      "  [ ] gazetteers.......... Gazeteer Lists\n",
      "  [ ] genesis............. Genesis Corpus\n",
      "  [ ] gutenberg........... Project Gutenberg Selections\n",
      "  [ ] hmm_treebank_pos_tagger Treebank Part of Speech Tagger (HMM)\n",
      "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
      "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
      "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
      "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
      "                           ChaSen format)\n",
      "  [ ] kimmo............... PC-KIMMO Data Files\n",
      "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
      "Hit Enter to continue: \n",
      "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
      "                           for parser comparison\n",
      "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
      "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
      "                           part-of-speech tags\n",
      "  [ ] machado............. Machado de Assis -- Obra Completa\n",
      "  [ ] masc_tagged......... MASC Tagged Corpus\n",
      "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
      "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
      "  [ ] moses_sample........ Moses Sample Models\n",
      "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
      "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
      "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
      "                           2015) subset of the Paraphrase Database.\n",
      "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
      "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
      "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
      "  [ ] nps_chat............ NPS Chat\n",
      "  [ ] omw................. Open Multilingual Wordnet\n",
      "  [ ] opinion_lexicon..... Opinion Lexicon\n",
      "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
      "Hit Enter to continue: \n",
      "  [ ] paradigms........... Paradigm Corpus\n",
      "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
      "                           Evaluation Shared Task\n",
      "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
      "                           character properties in Perl\n",
      "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
      "  [ ] pl196x.............. Polish language of the XX century sixties\n",
      "  [ ] porter_test......... Porter Stemmer Test Files\n",
      "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
      "  [ ] problem_reports..... Problem Report Corpus\n",
      "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
      "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
      "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
      "  [ ] pros_cons........... Pros and Cons\n",
      "  [ ] ptb................. Penn Treebank\n",
      "  [ ] punkt............... Punkt Tokenizer Models\n",
      "  [ ] qc.................. Experimental Data for Question Classification\n",
      "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
      "                           version\n",
      "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
      "                           Portuguesa)\n",
      "Hit Enter to continue: \n",
      "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
      "  [ ] sample_grammars..... Sample Grammars\n",
      "  [ ] semcor.............. SemCor 3.0\n",
      "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
      "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
      "  [ ] sentiwordnet........ SentiWordNet\n",
      "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
      "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
      "  [ ] smultron............ SMULTRON Corpus Sample\n",
      "  [ ] snowball_data....... Snowball Data\n",
      "  [ ] spanish_grammars.... Grammars for Spanish\n",
      "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
      "  [ ] stopwords........... Stopwords Corpus\n",
      "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
      "  [ ] swadesh............. Swadesh Wordlists\n",
      "  [ ] switchboard......... Switchboard Corpus Sample\n",
      "  [ ] tagsets............. Help on Tagsets\n",
      "  [ ] timit............... TIMIT Corpus Sample\n",
      "  [ ] toolbox............. Toolbox Sample Files\n",
      "  [ ] treebank............ Penn Treebank Sample\n",
      "  [ ] twitter_samples..... Twitter Samples\n",
      "Hit Enter to continue: \n",
      "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
      "                           (Unicode Version)\n",
      "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
      "  [ ] unicode_samples..... Unicode Samples\n",
      "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
      "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
      "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
      "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
      "  [ ] webtext............. Web Text Corpus\n",
      "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
      "  [ ] word2vec_sample..... Word2Vec Sample\n",
      "  [ ] wordnet............. WordNet\n",
      "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
      "  [ ] words............... Word Lists\n",
      "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
      "                           English Prose\n",
      "\n",
      "Collections:\n",
      "  [ ] all-corpora......... All the corpora\n",
      "  [ ] all-nltk............ All packages available on nltk_data gh-pages\n",
      "                           branch\n",
      "  [ ] all................. All packages\n",
      "Hit Enter to continue: \n",
      "  [ ] book................ Everything used in the NLTK Book\n",
      "  [ ] popular............. Popular packages\n",
      "  [ ] third-party......... Third-party data packages\n",
      "\n",
      "([*] marks installed packages)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> \n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> wordnet\n",
      "Command 'wordnet' unrecognized\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> download\n",
      "Command 'download' unrecognized\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> wordnet\n",
      "    Downloading package wordnet to /root/nltk_data...\n",
      "      Unzipping corpora/wordnet.zip.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-fec50ed38a60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/nltk/downloader.pyc\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;31m# function should make a new copy of self to use?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/nltk/downloader.pyc\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/nltk/downloader.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    996\u001b[0m             self._simple_interactive_menu(\n\u001b[1;32m    997\u001b[0m                 'd) Download', 'l) List', ' u) Update', 'c) Config', 'h) Help', 'q) Quit')\n\u001b[0;32m--> 998\u001b[0;31m             \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloader> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END STUDENT CODE 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
      "(From the entire data set)\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "            needful - vanished |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "          clusters - ingenuity |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         intolerable - parting |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      " infinitesimal - probabilities |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "             graceful - relish |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "              cyrus - preamble |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       inhibition - inhibitors |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
      "       conditioned - serotonin |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
      "               mock - vanished |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
      "                mock - needful |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
      "               parium - suorum |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "               legale - suorum |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "               legale - parium |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "             judicium - suorum |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "             judicium - parium |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "             judicium - legale |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "          falsehood - insulted |       0.577350 |       0.333333 |       1.000000 |       0.500000 |       0.602671\n",
      "             coolidge - hoover |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "               calvin - hoover |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "             calvin - coolidge |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "       inhibition - inhibitors |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
      "       conditioned - serotonin |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
      "               mock - vanished |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
      "                mock - needful |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
      "               parium - suorum |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "               legale - suorum |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "               legale - parium |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "             judicium - suorum |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "             judicium - parium |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "             judicium - legale |       0.666667 |       0.500000 |       0.666667 |       0.666667 |       0.625000\n",
      "          falsehood - insulted |       0.577350 |       0.333333 |       1.000000 |       0.500000 |       0.602671\n",
      "             coolidge - hoover |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "               calvin - hoover |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "             calvin - coolidge |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           anciennes - recueil |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              anciennes - lois |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           malaysian - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            mahathir - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          mahathir - malaysian |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "                lois - recueil |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print '—'*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print '—'*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
    "(From the entire data set)\n",
    "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
    "---------------------------------------------------------------------------------------------------------------------\n",
    "                   cons - pros |       0.894427 |       0.800000 |       1.000000 |       0.888889 |       0.895829\n",
    "            forties - twenties |       0.816497 |       0.666667 |       1.000000 |       0.800000 |       0.820791\n",
    "                    own - time |       0.809510 |       0.670563 |       0.921168 |       0.802799 |       0.801010\n",
    "                 little - time |       0.784197 |       0.630621 |       0.926101 |       0.773473 |       0.778598\n",
    "                  found - time |       0.783434 |       0.636364 |       0.883788 |       0.777778 |       0.770341\n",
    "                 nova - scotia |       0.774597 |       0.600000 |       1.000000 |       0.750000 |       0.781149\n",
    "                   hong - kong |       0.769800 |       0.615385 |       0.888889 |       0.761905 |       0.758995\n",
    "                   life - time |       0.769666 |       0.608789 |       0.925081 |       0.756829 |       0.765091\n",
    "                  time - world |       0.755476 |       0.585049 |       0.937500 |       0.738209 |       0.754058\n",
    "                  means - time |       0.752181 |       0.587117 |       0.902597 |       0.739854 |       0.745437\n",
    "                   form - time |       0.749943 |       0.588418 |       0.876733 |       0.740885 |       0.738995\n",
    "       infarction - myocardial |       0.748331 |       0.560000 |       1.000000 |       0.717949 |       0.756570\n",
    "                 people - time |       0.745788 |       0.573577 |       0.923875 |       0.729010 |       0.743063\n",
    "                 angeles - los |       0.745499 |       0.586207 |       0.850000 |       0.739130 |       0.730209\n",
    "                  little - own |       0.739343 |       0.585834 |       0.767296 |       0.738834 |       0.707827\n",
    "                    life - own |       0.737053 |       0.582217 |       0.778502 |       0.735951 |       0.708430\n",
    "          anterior - posterior |       0.733388 |       0.576471 |       0.790323 |       0.731343 |       0.707881\n",
    "                  power - time |       0.719611 |       0.533623 |       0.933586 |       0.695898 |       0.720680\n",
    "              dearly - install |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
    "                   found - own |       0.704802 |       0.544134 |       0.710949 |       0.704776 |       0.666165\n",
    "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "           arrival - essential |       0.008258 |       0.004098 |       0.009615 |       0.008163 |       0.007534\n",
    "         governments - surface |       0.008251 |       0.003534 |       0.014706 |       0.007042 |       0.008383\n",
    "                king - lesions |       0.008178 |       0.003106 |       0.017857 |       0.006192 |       0.008833\n",
    "              clinical - stood |       0.008178 |       0.003831 |       0.011905 |       0.007634 |       0.007887\n",
    "               till - validity |       0.008172 |       0.003367 |       0.015625 |       0.006711 |       0.008469\n",
    "            evidence - started |       0.008159 |       0.003802 |       0.012048 |       0.007576 |       0.007896\n",
    "               forces - record |       0.008152 |       0.003876 |       0.011364 |       0.007722 |       0.007778\n",
    "               primary - stone |       0.008146 |       0.004065 |       0.009091 |       0.008097 |       0.007350\n",
    "             beneath - federal |       0.008134 |       0.004082 |       0.008403 |       0.008130 |       0.007187\n",
    "                factors - rose |       0.008113 |       0.004032 |       0.009346 |       0.008032 |       0.007381\n",
    "           evening - functions |       0.008069 |       0.004049 |       0.008333 |       0.008065 |       0.007129\n",
    "                   bone - told |       0.008061 |       0.003704 |       0.012346 |       0.007380 |       0.007873\n",
    "             building - occurs |       0.008002 |       0.003891 |       0.010309 |       0.007752 |       0.007489\n",
    "                 company - fig |       0.007913 |       0.003257 |       0.015152 |       0.006494 |       0.008204\n",
    "               chronic - north |       0.007803 |       0.003268 |       0.014493 |       0.006515 |       0.008020\n",
    "             evaluation - king |       0.007650 |       0.003030 |       0.015625 |       0.006042 |       0.008087\n",
    "             resulting - stood |       0.007650 |       0.003663 |       0.010417 |       0.007299 |       0.007257\n",
    "                 agent - round |       0.007515 |       0.003289 |       0.012821 |       0.006557 |       0.007546\n",
    "         afterwards - analysis |       0.007387 |       0.003521 |       0.010204 |       0.007018 |       0.007032\n",
    "            posterior - spirit |       0.007156 |       0.002660 |       0.016129 |       0.005305 |       0.007812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.6  <a name=\"5.6\"></a> Evaluation of synonyms that your discovered\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "\n",
    "In this part of the assignment you will evaluate the success of you synonym detector (developed in response to HW5.4).\n",
    "Take the top 1,000 closest/most similar/correlative pairs of words as determined by your measure in HW5.4, and use the synonyms function in the accompanying python code:\n",
    "\n",
    "nltk_synonyms.py\n",
    "\n",
    "Note: This will require installing the python nltk package:\n",
    "\n",
    "http://www.nltk.org/install.html\n",
    "\n",
    "and downloading its data with nltk.download().\n",
    "\n",
    "For each (word1,word2) pair, check to see if word1 is in the list, \n",
    "synonyms(word2), and vice-versa. If one of the two is a synonym of the other, \n",
    "then consider this pair a 'hit', and then report the precision, recall, and F1 measure  of \n",
    "your detector across your 1,000 best guesses. Report the macro averages of these measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate performance measures:\n",
    "$$Precision (P) = \\frac{TP}{TP + FP} $$  \n",
    "$$Recall (R) = \\frac{TP}{TP + FN} $$  \n",
    "$$F1 = \\frac{2 * ( precision * recall )}{precision + recall}$$\n",
    "\n",
    "\n",
    "We calculate Precision by counting the number of hits and dividing by the number of occurances in our top1000 (opportunities)   \n",
    "We calculate Recall by counting the number of hits, and dividing by the number of synonyms in wordnet (syns)\n",
    "\n",
    "\n",
    "Other diagnostic measures not implemented here:  https://en.wikipedia.org/wiki/F1_score#Diagnostic_Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Number of Hits: 0 out of top 26\n",
      "Number of words without synonyms: 22\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Precision\t0.0\n",
      "Recall\t\t0.0\n",
      "F1\t\t0.0\n",
      "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Words without synonyms:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[] parium\n",
      "[] suorum\n",
      "[] legale\n",
      "[] suorum\n",
      "[] legale\n",
      "[] parium\n",
      "[] judicium\n",
      "[] suorum\n",
      "[] judicium\n",
      "[] parium\n",
      "[] judicium\n",
      "[] legale\n",
      "[] anciennes\n",
      "[] recueil\n",
      "[] anciennes\n",
      "[] lois\n",
      "[] mohamad\n",
      "[] mahathir\n",
      "[] mohamad\n",
      "[] mahathir\n",
      "[] lois\n",
      "[] recueil\n"
     ]
    }
   ],
   "source": [
    "''' Performance measures '''\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "\n",
    "#print all the synset element of an element\n",
    "def synonyms(string):\n",
    "    syndict = {}\n",
    "    for i,j in enumerate(wn.synsets(string)):\n",
    "        syns = j.lemma_names()\n",
    "        for syn in syns:\n",
    "            syndict.setdefault(syn,1)\n",
    "    return syndict.keys()\n",
    "hits = []\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "TOTAL = 0\n",
    "flag = False # so we don't double count, but at the same time don't miss hits\n",
    "start_time = time.time()\n",
    "top1000sims = []\n",
    "with open(\"sims2/top1000sims\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        top1000sims.append(lisst)\n",
    "    \n",
    "\n",
    "measures = {}\n",
    "not_in_wordnet = []\n",
    "\n",
    "for line in top1000sims:\n",
    "    TOTAL += 1\n",
    "\n",
    "    pair = line[0]\n",
    "    words = pair.split(\" - \")\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in measures:\n",
    "            measures[word] = {\"syns\":0,\"opps\": 0,\"hits\":0}\n",
    "        measures[word][\"opps\"] += 1 \n",
    "    \n",
    "    syns0 = synonyms(words[0])\n",
    "    measures[words[1]][\"syns\"] = len(syns0)\n",
    "    if len(syns0) == 0:\n",
    "        not_in_wordnet.append(words[0])\n",
    "        \n",
    "    if words[1] in syns0:\n",
    "        TP += 1\n",
    "        hits.append(line)\n",
    "        flag = True\n",
    "        measures[words[1]][\"hits\"] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    syns1 = synonyms(words[1]) \n",
    "    measures[words[0]][\"syns\"] = len(syns1)\n",
    "    if len(syns1) == 0:\n",
    "        not_in_wordnet.append(words[1])\n",
    "\n",
    "    if words[0] in syns1:\n",
    "        if flag == False:\n",
    "            TP += 1\n",
    "            hits.append(line)\n",
    "            measures[words[0]][\"hits\"] += 1\n",
    "            \n",
    "    flag = False    \n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for key in measures:\n",
    "    p,r,f = 0,0,0\n",
    "    if measures[key][\"hits\"] > 0 and measures[key][\"syns\"] > 0:\n",
    "        p = measures[key][\"hits\"]/measures[key][\"opps\"]\n",
    "        r = measures[key][\"hits\"]/measures[key][\"syns\"]\n",
    "        f = 2 * (p*r)/(p+r)\n",
    "    \n",
    "    # For calculating measures, only take into account words that have synonyms in wordnet\n",
    "    if measures[key][\"syns\"] > 0:\n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        f1.append(f)\n",
    "\n",
    "    \n",
    "# Take the mean of each measure    \n",
    "print \"—\"*110    \n",
    "print \"Number of Hits:\",TP, \"out of top\",TOTAL\n",
    "print \"Number of words without synonyms:\",len(not_in_wordnet)\n",
    "print \"—\"*110 \n",
    "print \"Precision\\t\", np.mean(precision)\n",
    "print \"Recall\\t\\t\", np.mean(recall)\n",
    "print \"F1\\t\\t\", np.mean(f1)\n",
    "print \"—\"*110  \n",
    "\n",
    "print \"Words without synonyms:\"\n",
    "print \"-\"*100\n",
    "\n",
    "for word in not_in_wordnet:\n",
    "    print synonyms(word),word\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "mins = elapsed_time/float(60)\n",
    "a = \"\"\"\n",
    "Elapsed time: %s seconds\n",
    "In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "logging.warning(a)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "Number of Hits: 31 out of top 1000\n",
    "Number of words without synonyms: 67\n",
    "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "Precision\t0.0280214404967\n",
    "Recall\t\t0.0178598869579\n",
    "F1\t\t0.013965517619\n",
    "——————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "Words without synonyms:\n",
    "----------------------------------------------------------------------------------------------------\n",
    "[] scotia\n",
    "[] hong\n",
    "[] kong\n",
    "[] angeles\n",
    "[] los\n",
    "[] nor\n",
    "[] themselves\n",
    "[] \n",
    "......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.7  <a name=\"5.7\"></a> OPTIONAL: using different vocabulary subsets\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "\n",
    "Repeat HW5 using vocabulary words ranked from 8001,-10,000;  7001,-10,000; 6001,-10,000; 5001,-10,000; 3001,-10,000; and 1001,-10,000;\n",
    "Dont forget to report you Cluster configuration.\n",
    "\n",
    "Generate the following graphs:\n",
    "-- vocabulary size (X-Axis) versus CPU time for indexing\n",
    "-- vocabulary size (X-Axis) versus number of pairs processed\n",
    "-- vocabulary size (X-Axis) versus F1 measure, Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 8001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `frequencies5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/frequencies5_5.root.20170617.070245.063231\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.070245.063231/files/...\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob4219690725143209880.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0021\n",
      "  Submitted application application_1497651454196_0021\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0021/\n",
      "  Running job: job_1497651454196_0021\n",
      "  Job job_1497651454196_0021 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0021 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.070245.063231/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=11448710\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=538130\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=901704\n",
      "\t\tFILE: Number of bytes written=2160242\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=11449116\n",
      "\t\tHDFS: Number of bytes written=538130\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=28674048\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=3456000\n",
      "\t\tTotal time spent by all map tasks (ms)=28002\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=28002\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3375\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3375\n",
      "\t\tTotal vcore-seconds taken by all map tasks=28002\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=3375\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=11540\n",
      "\t\tCombine input records=1558070\n",
      "\t\tCombine output records=54102\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=140\n",
      "\t\tInput split bytes=406\n",
      "\t\tMap input records=311614\n",
      "\t\tMap output bytes=18210060\n",
      "\t\tMap output materialized bytes=901710\n",
      "\t\tMap output records=1558070\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=775692288\n",
      "\t\tReduce input groups=36353\n",
      "\t\tReduce input records=54102\n",
      "\t\tReduce output records=36353\n",
      "\t\tReduce shuffle bytes=901710\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=108204\n",
      "\t\tTotal committed heap usage (bytes)=836763648\n",
      "\t\tVirtual memory (bytes) snapshot=4085370880\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  mapred.output.key.comparator.class is deprecated. Instead, use mapreduce.job.output.key.comparator.class\n",
      "  mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "  mapred.text.key.comparator.options is deprecated. Instead, use mapreduce.partition.keycomparator.options\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob8051247399245576914.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0022\n",
      "  Submitted application application_1497651454196_0022\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0022/\n",
      "  Running job: job_1497651454196_0022\n",
      "  Job job_1497651454196_0022 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0022 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.070245.063231/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=542226\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=30033\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=647195\n",
      "\t\tFILE: Number of bytes written=1650609\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=542574\n",
      "\t\tHDFS: Number of bytes written=30033\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=6435840\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2970624\n",
      "\t\tTotal time spent by all map tasks (ms)=6285\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=6285\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2901\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2901\n",
      "\t\tTotal vcore-seconds taken by all map tasks=6285\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2901\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2840\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=81\n",
      "\t\tInput split bytes=348\n",
      "\t\tMap input records=36353\n",
      "\t\tMap output bytes=574483\n",
      "\t\tMap output materialized bytes=647201\n",
      "\t\tMap output records=36353\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=757231616\n",
      "\t\tReduce input groups=36353\n",
      "\t\tReduce input records=36353\n",
      "\t\tReduce output records=2000\n",
      "\t\tReduce shuffle bytes=647201\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=72706\n",
      "\t\tTotal committed heap usage (bytes)=757596160\n",
      "\t\tVirtual memory (bytes) snapshot=4097490944\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.070245.063231/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/frequencies5_5.root.20170617.070245.063231...\n",
      "Removing temp directory /tmp/frequencies5_5.root.20170617.070245.063231...\n",
      "WARNING:root:Elapsed time: 62.8730959892 seconds\n",
      "    In minutes: 1.04788493315 mins\n",
      "rm: `stripes5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/stripes5_5.root.20170617.070350.152019\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/stripes5_5.root.20170617.070350.152019/files/...\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob2492567313006951298.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0023\n",
      "  Submitted application application_1497651454196_0023\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0023/\n",
      "  Running job: job_1497651454196_0023\n",
      "  Job job_1497651454196_0023 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0023 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/stripes5_5.root.20170617.070350.152019/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=11448710\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=17958\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=23752\n",
      "\t\tFILE: Number of bytes written=403999\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=11449108\n",
      "\t\tHDFS: Number of bytes written=17958\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=8050688\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2360320\n",
      "\t\tTotal time spent by all map tasks (ms)=7862\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=7862\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2305\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2305\n",
      "\t\tTotal vcore-seconds taken by all map tasks=7862\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2305\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1510\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=99\n",
      "\t\tInput split bytes=398\n",
      "\t\tMap input records=311614\n",
      "\t\tMap output bytes=22314\n",
      "\t\tMap output materialized bytes=23758\n",
      "\t\tMap output records=716\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=759828480\n",
      "\t\tReduce input groups=714\n",
      "\t\tReduce input records=716\n",
      "\t\tReduce output records=567\n",
      "\t\tReduce shuffle bytes=23758\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1432\n",
      "\t\tTotal committed heap usage (bytes)=833617920\n",
      "\t\tVirtual memory (bytes) snapshot=4077256704\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/stripes5_5.root.20170617.070350.152019/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/stripes5_5.root.20170617.070350.152019...\n",
      "Removing temp directory /tmp/stripes5_5.root.20170617.070350.152019...\n",
      "rm: `index5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/index5_5.root.20170617.070429.023253\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/index5_5.root.20170617.070429.023253/files/...\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob1476262892082415966.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0024\n",
      "  Submitted application application_1497651454196_0024\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0024/\n",
      "  Running job: job_1497651454196_0024\n",
      "  Job job_1497651454196_0024 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0024 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/index5_5.root.20170617.070429.023253/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=22054\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=16996\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=20128\n",
      "\t\tFILE: Number of bytes written=393781\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=22368\n",
      "\t\tHDFS: Number of bytes written=16996\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=5874688\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2323456\n",
      "\t\tTotal time spent by all map tasks (ms)=5737\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=5737\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2269\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2269\n",
      "\t\tTotal vcore-seconds taken by all map tasks=5737\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2269\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1220\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=58\n",
      "\t\tInput split bytes=314\n",
      "\t\tMap input records=567\n",
      "\t\tMap output bytes=18690\n",
      "\t\tMap output materialized bytes=20134\n",
      "\t\tMap output records=716\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=728055808\n",
      "\t\tReduce input groups=567\n",
      "\t\tReduce input records=716\n",
      "\t\tReduce output records=567\n",
      "\t\tReduce shuffle bytes=20134\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1432\n",
      "\t\tTotal committed heap usage (bytes)=794296320\n",
      "\t\tVirtual memory (bytes) snapshot=4082741248\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/index5_5.root.20170617.070429.023253/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/index5_5.root.20170617.070429.023253...\n",
      "Removing temp directory /tmp/index5_5.root.20170617.070429.023253...\n",
      "rm: `similarity5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in $PATH...\n",
      "Found hadoop binary: /usr/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/similarity5_5.root.20170617.070503.839752\n",
      "Copying local files to hdfs:///user/root/tmp/mrjob/similarity5_5.root.20170617.070503.839752/files/...\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob3473701266537159735.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0025\n",
      "  Submitted application application_1497651454196_0025\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0025/\n",
      "  Running job: job_1497651454196_0025\n",
      "  Job job_1497651454196_0025 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0025 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/similarity5_5.root.20170617.070503.839752/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=21092\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=15390\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=6089\n",
      "\t\tFILE: Number of bytes written=367404\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=21412\n",
      "\t\tHDFS: Number of bytes written=15390\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=6180864\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2324480\n",
      "\t\tTotal time spent by all map tasks (ms)=6036\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=6036\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2270\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2270\n",
      "\t\tTotal vcore-seconds taken by all map tasks=6036\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2270\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1120\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=67\n",
      "\t\tInput split bytes=320\n",
      "\t\tMap input records=567\n",
      "\t\tMap output bytes=5727\n",
      "\t\tMap output materialized bytes=6095\n",
      "\t\tMap output records=178\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=733151232\n",
      "\t\tReduce input groups=166\n",
      "\t\tReduce input records=178\n",
      "\t\tReduce output records=166\n",
      "\t\tReduce shuffle bytes=6095\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=356\n",
      "\t\tTotal committed heap usage (bytes)=794296320\n",
      "\t\tVirtual memory (bytes) snapshot=4074246144\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.6.0:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  mapred.output.key.comparator.class is deprecated. Instead, use mapreduce.job.output.key.comparator.class\n",
      "  mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "  mapred.text.key.comparator.options is deprecated. Instead, use mapreduce.partition.keycomparator.options\n",
      "  mapred.text.key.partitioner.options is deprecated. Instead, use mapreduce.partition.keypartitioner.options\n",
      "  packageJobJar: [] [/usr/jars/hadoop-streaming-2.6.0-cdh5.7.0.jar] /tmp/streamjob2226960022529566800.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497651454196_0026\n",
      "  Submitted application application_1497651454196_0026\n",
      "  The url to track the job: http://quickstart.cloudera:8088/proxy/application_1497651454196_0026/\n",
      "  Running job: job_1497651454196_0026\n",
      "  Job job_1497651454196_0026 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497651454196_0026 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/similarity5_5.root.20170617.070503.839752/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=19486\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=15390\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=15900\n",
      "\t\tFILE: Number of bytes written=387866\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=19832\n",
      "\t\tHDFS: Number of bytes written=15390\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=5295104\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=2376704\n",
      "\t\tTotal time spent by all map tasks (ms)=5171\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=5171\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2321\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2321\n",
      "\t\tTotal vcore-seconds taken by all map tasks=5171\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=2321\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1180\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=67\n",
      "\t\tInput split bytes=346\n",
      "\t\tMap input records=166\n",
      "\t\tMap output bytes=15559\n",
      "\t\tMap output materialized bytes=15906\n",
      "\t\tMap output records=166\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=706113536\n",
      "\t\tReduce input groups=166\n",
      "\t\tReduce input records=166\n",
      "\t\tReduce output records=166\n",
      "\t\tReduce shuffle bytes=15906\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=332\n",
      "\t\tTotal committed heap usage (bytes)=681050112\n",
      "\t\tVirtual memory (bytes) snapshot=4101160960\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/similarity5_5.root.20170617.070503.839752/output...\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/similarity5_5.root.20170617.070503.839752...\n",
      "Removing temp directory /tmp/similarity5_5.root.20170617.070503.839752...\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 8001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory `sims2': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
      "(From the entire data set)\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "           iliac - replacement |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         replacement - rupture |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           hampshire - hungary |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       greenhouse - tomography |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           grazing - livestock |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            gracious - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           gracious - pendulum |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                   genre - que |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "        precaution - resultant |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         preamble - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           preamble - sweeping |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "               plunged - slain |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            planting - players |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "             pilgrim - proudly |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            pendulum - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            offender - schemes |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "          newborn - saturation |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         sweeping - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            needful - vanished |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                 nazis - swift |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "               alpha - epsilon |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - neuropathy |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "     subordination - vengeance |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              seas - wandering |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              pious - syllable |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "       neuropathy - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           malaysian - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            mahathir - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          mahathir - malaysian |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "                lois - recueil |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            ingenuity - wretch |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           infected - infusion |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "               hers - paternal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           fossil - resembling |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          sensory - trigeminal |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "           maxillary - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "        breathed - persistence |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "            diabetic - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "                anne - prussia |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print '—'*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print '—'*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 7001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 7001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory `sims2': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
      "(From the entire data set)\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "           iliac - replacement |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         replacement - rupture |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           hampshire - hungary |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       greenhouse - tomography |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           grazing - livestock |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            gracious - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           gracious - pendulum |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                   genre - que |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "        precaution - resultant |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         preamble - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           preamble - sweeping |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "               plunged - slain |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            planting - players |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "             pilgrim - proudly |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            pendulum - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            offender - schemes |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "          newborn - saturation |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         sweeping - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            needful - vanished |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                 nazis - swift |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "               alpha - epsilon |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - neuropathy |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "     subordination - vengeance |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              seas - wandering |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              pious - syllable |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "       neuropathy - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           malaysian - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            mahathir - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          mahathir - malaysian |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "                lois - recueil |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            ingenuity - wretch |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           infected - infusion |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "               hers - paternal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           fossil - resembling |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          sensory - trigeminal |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "           maxillary - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "        breathed - persistence |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "            diabetic - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "                anne - prussia |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print '—'*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print '—'*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 6001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 6001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory `sims2': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
      "(From the entire data set)\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "           iliac - replacement |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         replacement - rupture |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           hampshire - hungary |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       greenhouse - tomography |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           grazing - livestock |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            gracious - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           gracious - pendulum |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                   genre - que |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "        precaution - resultant |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         preamble - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           preamble - sweeping |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "               plunged - slain |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            planting - players |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "             pilgrim - proudly |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            pendulum - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            offender - schemes |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "          newborn - saturation |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         sweeping - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            needful - vanished |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                 nazis - swift |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "               alpha - epsilon |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - neuropathy |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "     subordination - vengeance |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              seas - wandering |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              pious - syllable |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "       neuropathy - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           malaysian - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            mahathir - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          mahathir - malaysian |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "                lois - recueil |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            ingenuity - wretch |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           infected - infusion |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "               hers - paternal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           fossil - resembling |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          sensory - trigeminal |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "           maxillary - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "        breathed - persistence |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "            diabetic - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "                anne - prussia |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print '—'*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print '—'*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 5001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 5001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory `sims2': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
      "(From the entire data set)\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "           iliac - replacement |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         replacement - rupture |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           hampshire - hungary |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       greenhouse - tomography |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           grazing - livestock |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            gracious - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           gracious - pendulum |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                   genre - que |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "        precaution - resultant |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         preamble - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           preamble - sweeping |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "               plunged - slain |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            planting - players |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "             pilgrim - proudly |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            pendulum - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            offender - schemes |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "          newborn - saturation |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         sweeping - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            needful - vanished |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                 nazis - swift |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "               alpha - epsilon |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - neuropathy |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "     subordination - vengeance |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              seas - wandering |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              pious - syllable |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "       neuropathy - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           malaysian - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            mahathir - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          mahathir - malaysian |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "                lois - recueil |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            ingenuity - wretch |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           infected - infusion |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "               hers - paternal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           fossil - resembling |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          sensory - trigeminal |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "           maxillary - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "        breathed - persistence |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "            diabetic - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "                anne - prussia |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print '—'*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print '—'*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 4001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 4001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory `sims2': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
      "(From the entire data set)\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "           iliac - replacement |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         replacement - rupture |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           hampshire - hungary |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       greenhouse - tomography |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           grazing - livestock |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            gracious - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           gracious - pendulum |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                   genre - que |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "        precaution - resultant |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         preamble - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           preamble - sweeping |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "               plunged - slain |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            planting - players |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "             pilgrim - proudly |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            pendulum - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            offender - schemes |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "          newborn - saturation |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         sweeping - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            needful - vanished |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                 nazis - swift |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "               alpha - epsilon |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - neuropathy |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "     subordination - vengeance |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              seas - wandering |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              pious - syllable |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "       neuropathy - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           malaysian - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            mahathir - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          mahathir - malaysian |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "                lois - recueil |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            ingenuity - wretch |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           infected - infusion |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "               hers - paternal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           fossil - resembling |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          sensory - trigeminal |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "           maxillary - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "        breathed - persistence |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "            diabetic - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "                anne - prussia |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print '—'*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print '—'*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 3001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 3001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory `sims2': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
      "(From the entire data set)\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "           iliac - replacement |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         replacement - rupture |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           hampshire - hungary |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       greenhouse - tomography |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           grazing - livestock |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            gracious - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           gracious - pendulum |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                   genre - que |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "        precaution - resultant |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         preamble - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           preamble - sweeping |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "               plunged - slain |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            planting - players |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "             pilgrim - proudly |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            pendulum - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            offender - schemes |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "          newborn - saturation |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         sweeping - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            needful - vanished |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                 nazis - swift |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "               alpha - epsilon |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - neuropathy |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "     subordination - vengeance |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              seas - wandering |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              pious - syllable |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "       neuropathy - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           malaysian - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            mahathir - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          mahathir - malaysian |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "                lois - recueil |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            ingenuity - wretch |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           infected - infusion |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "               hers - paternal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           fossil - resembling |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          sensory - trigeminal |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "           maxillary - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "        breathed - persistence |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "            diabetic - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "                anne - prussia |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print '—'*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print '—'*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 2001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 2001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory `sims2': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
      "(From the entire data set)\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "           iliac - replacement |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         replacement - rupture |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           hampshire - hungary |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       greenhouse - tomography |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           grazing - livestock |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            gracious - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           gracious - pendulum |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                   genre - que |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "        precaution - resultant |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         preamble - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           preamble - sweeping |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "               plunged - slain |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            planting - players |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "             pilgrim - proudly |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            pendulum - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            offender - schemes |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "          newborn - saturation |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         sweeping - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            needful - vanished |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                 nazis - swift |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "               alpha - epsilon |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - neuropathy |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "     subordination - vengeance |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              seas - wandering |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              pious - syllable |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "       neuropathy - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           malaysian - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            mahathir - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          mahathir - malaysian |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "                lois - recueil |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            ingenuity - wretch |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           infected - infusion |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "               hers - paternal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           fossil - resembling |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          sensory - trigeminal |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "           maxillary - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "        breathed - persistence |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "            diabetic - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "                anne - prussia |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print '—'*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print '—'*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 1001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 1001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory `sims2': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
      "(From the entire data set)\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "           iliac - replacement |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         replacement - rupture |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           hampshire - hungary |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       greenhouse - tomography |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           grazing - livestock |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            gracious - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           gracious - pendulum |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                   genre - que |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "        precaution - resultant |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         preamble - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "           preamble - sweeping |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "               plunged - slain |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            planting - players |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "             pilgrim - proudly |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            pendulum - privacy |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            offender - schemes |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "          newborn - saturation |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "         sweeping - toleration |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "            needful - vanished |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "                 nazis - swift |       1.000000 |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "               alpha - epsilon |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - neuropathy |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "     subordination - vengeance |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              seas - wandering |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "              pious - syllable |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "       neuropathy - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "        maxillary - trigeminal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           malaysian - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            mahathir - mohamad |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          mahathir - malaysian |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "                lois - recueil |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "            ingenuity - wretch |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           infected - infusion |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "               hers - paternal |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "           fossil - resembling |       0.500000 |       0.333333 |       0.500000 |       0.500000 |       0.458333\n",
      "          sensory - trigeminal |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "           maxillary - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "        breathed - persistence |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "            diabetic - sensory |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n",
      "                anne - prussia |       0.408248 |       0.250000 |       0.500000 |       0.400000 |       0.389562\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print '—'*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print '—'*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.8  <a name=\"5.8\"></a> OPTIONAL: filter stopwords\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "There is also a corpus of stopwords, that is, high-frequency words like \"the\", \"to\" and \"also\" that we sometimes want to filter out of a document before further processing. Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts. Python's nltk comes with a prebuilt list of stopwords (see below). Using this stopword list filter out these tokens from your analysis and rerun the experiments in 5.5 and disucuss the results of using a stopword list and without using a stopword list.\n",
    "\n",
    "> from nltk.corpus import stopwords\n",
    ">> stopwords.words('english')\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.9 <a name=\"5.9\"></a> OPTIONAL \n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "There are many good ways to build our synonym detectors, so for this optional homework, \n",
    "measure co-occurrence by (left/right/all) consecutive words only, \n",
    "or make stripes according to word co-occurrences with the accompanying \n",
    "2-, 3-, or 4-grams (note here that your output will no longer \n",
    "be interpretable as a network) inside of the 5-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.10 <a name=\"5.10\"></a> OPTIONAL \n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Once again, benchmark your top 10,000 associations (as in 5.5), this time for your\n",
    "results from 5.6. Has your detector improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "511px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
